import "./chunk-EGRHWZRV.js";
import {
  coinWithBalance
} from "./chunk-HRYGTWLY.js";
import {
  SuiClient
} from "./chunk-U6HE4XIO.js";
import "./chunk-VSVKC33L.js";
import {
  Transaction,
  isArgument
} from "./chunk-L3XWQKSJ.js";
import {
  BcsEnum,
  BcsStruct,
  BcsTuple,
  ClientCache,
  TypeTagSerializer,
  chunk,
  deriveDynamicFieldID,
  fromBase58,
  fromBase64,
  fromHex,
  normalizeStructTag,
  normalizeSuiAddress,
  parseStructTag,
  pureBcsSchemaFromTypeName,
  suiBcs,
  toBase58,
  toBase64,
  toHex
} from "./chunk-JG6F4J5M.js";
import {
  __commonJS,
  __toESM
} from "./chunk-5WRI5ZAA.js";

// node_modules/dataloader/index.js
var require_dataloader = __commonJS({
  "node_modules/dataloader/index.js"(exports, module) {
    "use strict";
    var DataLoader2 = function() {
      function DataLoader3(batchLoadFn, options) {
        if (typeof batchLoadFn !== "function") {
          throw new TypeError("DataLoader must be constructed with a function which accepts " + ("Array<key> and returns Promise<Array<value>>, but got: " + batchLoadFn + "."));
        }
        this._batchLoadFn = batchLoadFn;
        this._maxBatchSize = getValidMaxBatchSize(options);
        this._batchScheduleFn = getValidBatchScheduleFn(options);
        this._cacheKeyFn = getValidCacheKeyFn(options);
        this._cacheMap = getValidCacheMap(options);
        this._batch = null;
        this.name = getValidName(options);
      }
      var _proto = DataLoader3.prototype;
      _proto.load = function load(key) {
        if (key === null || key === void 0) {
          throw new TypeError("The loader.load() function must be called with a value, " + ("but got: " + String(key) + "."));
        }
        var batch = getCurrentBatch(this);
        var cacheMap = this._cacheMap;
        var cacheKey;
        if (cacheMap) {
          cacheKey = this._cacheKeyFn(key);
          var cachedPromise = cacheMap.get(cacheKey);
          if (cachedPromise) {
            var cacheHits = batch.cacheHits || (batch.cacheHits = []);
            return new Promise(function(resolve) {
              cacheHits.push(function() {
                resolve(cachedPromise);
              });
            });
          }
        }
        batch.keys.push(key);
        var promise = new Promise(function(resolve, reject) {
          batch.callbacks.push({
            resolve,
            reject
          });
        });
        if (cacheMap) {
          cacheMap.set(cacheKey, promise);
        }
        return promise;
      };
      _proto.loadMany = function loadMany(keys) {
        if (!isArrayLike(keys)) {
          throw new TypeError("The loader.loadMany() function must be called with Array<key> " + ("but got: " + keys + "."));
        }
        var loadPromises = [];
        for (var i = 0; i < keys.length; i++) {
          loadPromises.push(this.load(keys[i])["catch"](function(error) {
            return error;
          }));
        }
        return Promise.all(loadPromises);
      };
      _proto.clear = function clear(key) {
        var cacheMap = this._cacheMap;
        if (cacheMap) {
          var cacheKey = this._cacheKeyFn(key);
          cacheMap["delete"](cacheKey);
        }
        return this;
      };
      _proto.clearAll = function clearAll() {
        var cacheMap = this._cacheMap;
        if (cacheMap) {
          cacheMap.clear();
        }
        return this;
      };
      _proto.prime = function prime(key, value) {
        var cacheMap = this._cacheMap;
        if (cacheMap) {
          var cacheKey = this._cacheKeyFn(key);
          if (cacheMap.get(cacheKey) === void 0) {
            var promise;
            if (value instanceof Error) {
              promise = Promise.reject(value);
              promise["catch"](function() {
              });
            } else {
              promise = Promise.resolve(value);
            }
            cacheMap.set(cacheKey, promise);
          }
        }
        return this;
      };
      return DataLoader3;
    }();
    var enqueuePostPromiseJob = typeof process === "object" && typeof process.nextTick === "function" ? function(fn) {
      if (!resolvedPromise) {
        resolvedPromise = Promise.resolve();
      }
      resolvedPromise.then(function() {
        process.nextTick(fn);
      });
    } : typeof setImmediate === "function" ? function(fn) {
      setImmediate(fn);
    } : function(fn) {
      setTimeout(fn);
    };
    var resolvedPromise;
    function getCurrentBatch(loader) {
      var existingBatch = loader._batch;
      if (existingBatch !== null && !existingBatch.hasDispatched && existingBatch.keys.length < loader._maxBatchSize) {
        return existingBatch;
      }
      var newBatch = {
        hasDispatched: false,
        keys: [],
        callbacks: []
      };
      loader._batch = newBatch;
      loader._batchScheduleFn(function() {
        dispatchBatch(loader, newBatch);
      });
      return newBatch;
    }
    function dispatchBatch(loader, batch) {
      batch.hasDispatched = true;
      if (batch.keys.length === 0) {
        resolveCacheHits(batch);
        return;
      }
      var batchPromise;
      try {
        batchPromise = loader._batchLoadFn(batch.keys);
      } catch (e) {
        return failedDispatch(loader, batch, new TypeError("DataLoader must be constructed with a function which accepts Array<key> and returns Promise<Array<value>>, but the function " + ("errored synchronously: " + String(e) + ".")));
      }
      if (!batchPromise || typeof batchPromise.then !== "function") {
        return failedDispatch(loader, batch, new TypeError("DataLoader must be constructed with a function which accepts Array<key> and returns Promise<Array<value>>, but the function did " + ("not return a Promise: " + String(batchPromise) + ".")));
      }
      batchPromise.then(function(values) {
        if (!isArrayLike(values)) {
          throw new TypeError("DataLoader must be constructed with a function which accepts Array<key> and returns Promise<Array<value>>, but the function did " + ("not return a Promise of an Array: " + String(values) + "."));
        }
        if (values.length !== batch.keys.length) {
          throw new TypeError("DataLoader must be constructed with a function which accepts Array<key> and returns Promise<Array<value>>, but the function did not return a Promise of an Array of the same length as the Array of keys." + ("\n\nKeys:\n" + String(batch.keys)) + ("\n\nValues:\n" + String(values)));
        }
        resolveCacheHits(batch);
        for (var i = 0; i < batch.callbacks.length; i++) {
          var _value = values[i];
          if (_value instanceof Error) {
            batch.callbacks[i].reject(_value);
          } else {
            batch.callbacks[i].resolve(_value);
          }
        }
      })["catch"](function(error) {
        failedDispatch(loader, batch, error);
      });
    }
    function failedDispatch(loader, batch, error) {
      resolveCacheHits(batch);
      for (var i = 0; i < batch.keys.length; i++) {
        loader.clear(batch.keys[i]);
        batch.callbacks[i].reject(error);
      }
    }
    function resolveCacheHits(batch) {
      if (batch.cacheHits) {
        for (var i = 0; i < batch.cacheHits.length; i++) {
          batch.cacheHits[i]();
        }
      }
    }
    function getValidMaxBatchSize(options) {
      var shouldBatch = !options || options.batch !== false;
      if (!shouldBatch) {
        return 1;
      }
      var maxBatchSize = options && options.maxBatchSize;
      if (maxBatchSize === void 0) {
        return Infinity;
      }
      if (typeof maxBatchSize !== "number" || maxBatchSize < 1) {
        throw new TypeError("maxBatchSize must be a positive number: " + maxBatchSize);
      }
      return maxBatchSize;
    }
    function getValidBatchScheduleFn(options) {
      var batchScheduleFn = options && options.batchScheduleFn;
      if (batchScheduleFn === void 0) {
        return enqueuePostPromiseJob;
      }
      if (typeof batchScheduleFn !== "function") {
        throw new TypeError("batchScheduleFn must be a function: " + batchScheduleFn);
      }
      return batchScheduleFn;
    }
    function getValidCacheKeyFn(options) {
      var cacheKeyFn = options && options.cacheKeyFn;
      if (cacheKeyFn === void 0) {
        return function(key) {
          return key;
        };
      }
      if (typeof cacheKeyFn !== "function") {
        throw new TypeError("cacheKeyFn must be a function: " + cacheKeyFn);
      }
      return cacheKeyFn;
    }
    function getValidCacheMap(options) {
      var shouldCache = !options || options.cache !== false;
      if (!shouldCache) {
        return null;
      }
      var cacheMap = options && options.cacheMap;
      if (cacheMap === void 0) {
        return /* @__PURE__ */ new Map();
      }
      if (cacheMap !== null) {
        var cacheFunctions = ["get", "set", "delete", "clear"];
        var missingFunctions = cacheFunctions.filter(function(fnName) {
          return cacheMap && typeof cacheMap[fnName] !== "function";
        });
        if (missingFunctions.length !== 0) {
          throw new TypeError("Custom cacheMap missing methods: " + missingFunctions.join(", "));
        }
      }
      return cacheMap;
    }
    function getValidName(options) {
      if (options && options.name) {
        return options.name;
      }
      return null;
    }
    function isArrayLike(x) {
      return typeof x === "object" && x !== null && typeof x.length === "number" && (x.length === 0 || x.length > 0 && Object.prototype.hasOwnProperty.call(x, x.length - 1));
    }
    module.exports = DataLoader2;
  }
});

// node_modules/@mysten/walrus/node_modules/@mysten/bcs/dist/esm/uleb.js
function ulebEncode(num) {
  const arr = [];
  let len = 0;
  if (num === 0) {
    return [0];
  }
  while (num > 0) {
    arr[len] = num & 127;
    if (num >>= 7) {
      arr[len] |= 128;
    }
    len += 1;
  }
  return arr;
}
function ulebDecode(arr) {
  let total = 0;
  let shift = 0;
  let len = 0;
  while (true) {
    const byte = arr[len];
    len += 1;
    total |= (byte & 127) << shift;
    if ((byte & 128) === 0) {
      break;
    }
    shift += 7;
  }
  return {
    value: total,
    length: len
  };
}

// node_modules/@mysten/walrus/node_modules/@mysten/bcs/dist/esm/reader.js
var BcsReader = class {
  /**
   * @param {Uint8Array} data Data to use as a buffer.
   */
  constructor(data) {
    this.bytePosition = 0;
    this.dataView = new DataView(data.buffer, data.byteOffset, data.byteLength);
  }
  /**
   * Shift current cursor position by `bytes`.
   *
   * @param {Number} bytes Number of bytes to
   * @returns {this} Self for possible chaining.
   */
  shift(bytes) {
    this.bytePosition += bytes;
    return this;
  }
  /**
   * Read U8 value from the buffer and shift cursor by 1.
   * @returns
   */
  read8() {
    const value = this.dataView.getUint8(this.bytePosition);
    this.shift(1);
    return value;
  }
  /**
   * Read U16 value from the buffer and shift cursor by 2.
   * @returns
   */
  read16() {
    const value = this.dataView.getUint16(this.bytePosition, true);
    this.shift(2);
    return value;
  }
  /**
   * Read U32 value from the buffer and shift cursor by 4.
   * @returns
   */
  read32() {
    const value = this.dataView.getUint32(this.bytePosition, true);
    this.shift(4);
    return value;
  }
  /**
   * Read U64 value from the buffer and shift cursor by 8.
   * @returns
   */
  read64() {
    const value1 = this.read32();
    const value2 = this.read32();
    const result = value2.toString(16) + value1.toString(16).padStart(8, "0");
    return BigInt("0x" + result).toString(10);
  }
  /**
   * Read U128 value from the buffer and shift cursor by 16.
   */
  read128() {
    const value1 = BigInt(this.read64());
    const value2 = BigInt(this.read64());
    const result = value2.toString(16) + value1.toString(16).padStart(16, "0");
    return BigInt("0x" + result).toString(10);
  }
  /**
   * Read U128 value from the buffer and shift cursor by 32.
   * @returns
   */
  read256() {
    const value1 = BigInt(this.read128());
    const value2 = BigInt(this.read128());
    const result = value2.toString(16) + value1.toString(16).padStart(32, "0");
    return BigInt("0x" + result).toString(10);
  }
  /**
   * Read `num` number of bytes from the buffer and shift cursor by `num`.
   * @param num Number of bytes to read.
   */
  readBytes(num) {
    const start = this.bytePosition + this.dataView.byteOffset;
    const value = new Uint8Array(this.dataView.buffer, start, num);
    this.shift(num);
    return value;
  }
  /**
   * Read ULEB value - an integer of varying size. Used for enum indexes and
   * vector lengths.
   * @returns {Number} The ULEB value.
   */
  readULEB() {
    const start = this.bytePosition + this.dataView.byteOffset;
    const buffer = new Uint8Array(this.dataView.buffer, start);
    const { value, length } = ulebDecode(buffer);
    this.shift(length);
    return value;
  }
  /**
   * Read a BCS vector: read a length and then apply function `cb` X times
   * where X is the length of the vector, defined as ULEB in BCS bytes.
   * @param cb Callback to process elements of vector.
   * @returns {Array<Any>} Array of the resulting values, returned by callback.
   */
  readVec(cb) {
    const length = this.readULEB();
    const result = [];
    for (let i = 0; i < length; i++) {
      result.push(cb(this, i, length));
    }
    return result;
  }
};

// node_modules/@mysten/walrus/node_modules/@mysten/bcs/dist/esm/utils.js
function encodeStr(data, encoding) {
  switch (encoding) {
    case "base58":
      return toBase58(data);
    case "base64":
      return toBase64(data);
    case "hex":
      return toHex(data);
    default:
      throw new Error("Unsupported encoding, supported values are: base64, hex");
  }
}

// node_modules/@mysten/walrus/node_modules/@mysten/bcs/dist/esm/writer.js
var BcsWriter = class {
  constructor({
    initialSize = 1024,
    maxSize = Infinity,
    allocateSize = 1024
  } = {}) {
    this.bytePosition = 0;
    this.size = initialSize;
    this.maxSize = maxSize;
    this.allocateSize = allocateSize;
    this.dataView = new DataView(new ArrayBuffer(initialSize));
  }
  ensureSizeOrGrow(bytes) {
    const requiredSize = this.bytePosition + bytes;
    if (requiredSize > this.size) {
      const nextSize = Math.min(this.maxSize, this.size + this.allocateSize);
      if (requiredSize > nextSize) {
        throw new Error(
          `Attempting to serialize to BCS, but buffer does not have enough size. Allocated size: ${this.size}, Max size: ${this.maxSize}, Required size: ${requiredSize}`
        );
      }
      this.size = nextSize;
      const nextBuffer = new ArrayBuffer(this.size);
      new Uint8Array(nextBuffer).set(new Uint8Array(this.dataView.buffer));
      this.dataView = new DataView(nextBuffer);
    }
  }
  /**
   * Shift current cursor position by `bytes`.
   *
   * @param {Number} bytes Number of bytes to
   * @returns {this} Self for possible chaining.
   */
  shift(bytes) {
    this.bytePosition += bytes;
    return this;
  }
  /**
   * Write a U8 value into a buffer and shift cursor position by 1.
   * @param {Number} value Value to write.
   * @returns {this}
   */
  write8(value) {
    this.ensureSizeOrGrow(1);
    this.dataView.setUint8(this.bytePosition, Number(value));
    return this.shift(1);
  }
  /**
   * Write a U16 value into a buffer and shift cursor position by 2.
   * @param {Number} value Value to write.
   * @returns {this}
   */
  write16(value) {
    this.ensureSizeOrGrow(2);
    this.dataView.setUint16(this.bytePosition, Number(value), true);
    return this.shift(2);
  }
  /**
   * Write a U32 value into a buffer and shift cursor position by 4.
   * @param {Number} value Value to write.
   * @returns {this}
   */
  write32(value) {
    this.ensureSizeOrGrow(4);
    this.dataView.setUint32(this.bytePosition, Number(value), true);
    return this.shift(4);
  }
  /**
   * Write a U64 value into a buffer and shift cursor position by 8.
   * @param {bigint} value Value to write.
   * @returns {this}
   */
  write64(value) {
    toLittleEndian(BigInt(value), 8).forEach((el) => this.write8(el));
    return this;
  }
  /**
   * Write a U128 value into a buffer and shift cursor position by 16.
   *
   * @param {bigint} value Value to write.
   * @returns {this}
   */
  write128(value) {
    toLittleEndian(BigInt(value), 16).forEach((el) => this.write8(el));
    return this;
  }
  /**
   * Write a U256 value into a buffer and shift cursor position by 16.
   *
   * @param {bigint} value Value to write.
   * @returns {this}
   */
  write256(value) {
    toLittleEndian(BigInt(value), 32).forEach((el) => this.write8(el));
    return this;
  }
  /**
   * Write a ULEB value into a buffer and shift cursor position by number of bytes
   * written.
   * @param {Number} value Value to write.
   * @returns {this}
   */
  writeULEB(value) {
    ulebEncode(value).forEach((el) => this.write8(el));
    return this;
  }
  /**
   * Write a vector into a buffer by first writing the vector length and then calling
   * a callback on each passed value.
   *
   * @param {Array<Any>} vector Array of elements to write.
   * @param {WriteVecCb} cb Callback to call on each element of the vector.
   * @returns {this}
   */
  writeVec(vector2, cb) {
    this.writeULEB(vector2.length);
    Array.from(vector2).forEach((el, i) => cb(this, el, i, vector2.length));
    return this;
  }
  /**
   * Adds support for iterations over the object.
   * @returns {Uint8Array}
   */
  *[Symbol.iterator]() {
    for (let i = 0; i < this.bytePosition; i++) {
      yield this.dataView.getUint8(i);
    }
    return this.toBytes();
  }
  /**
   * Get underlying buffer taking only value bytes (in case initial buffer size was bigger).
   * @returns {Uint8Array} Resulting bcs.
   */
  toBytes() {
    return new Uint8Array(this.dataView.buffer.slice(0, this.bytePosition));
  }
  /**
   * Represent data as 'hex' or 'base64'
   * @param encoding Encoding to use: 'base64' or 'hex'
   */
  toString(encoding) {
    return encodeStr(this.toBytes(), encoding);
  }
};
function toLittleEndian(bigint, size) {
  const result = new Uint8Array(size);
  let i = 0;
  while (bigint > 0) {
    result[i] = Number(bigint % BigInt(256));
    bigint = bigint / BigInt(256);
    i += 1;
  }
  return result;
}

// node_modules/@mysten/walrus/node_modules/@mysten/bcs/dist/esm/bcs-type.js
var __typeError = (msg) => {
  throw TypeError(msg);
};
var __accessCheck = (obj, member, msg) => member.has(obj) || __typeError("Cannot " + msg);
var __privateGet = (obj, member, getter) => (__accessCheck(obj, member, "read from private field"), getter ? getter.call(obj) : member.get(obj));
var __privateAdd = (obj, member, value) => member.has(obj) ? __typeError("Cannot add the same private member more than once") : member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
var __privateSet = (obj, member, value, setter) => (__accessCheck(obj, member, "write to private field"), setter ? setter.call(obj, value) : member.set(obj, value), value);
var _write;
var _serialize;
var _schema;
var _bytes;
var _BcsType = class _BcsType2 {
  constructor(options) {
    __privateAdd(this, _write);
    __privateAdd(this, _serialize);
    this.name = options.name;
    this.read = options.read;
    this.serializedSize = options.serializedSize ?? (() => null);
    __privateSet(this, _write, options.write);
    __privateSet(this, _serialize, options.serialize ?? ((value, options2) => {
      const writer = new BcsWriter({
        initialSize: this.serializedSize(value) ?? void 0,
        ...options2
      });
      __privateGet(this, _write).call(this, value, writer);
      return writer.toBytes();
    }));
    this.validate = options.validate ?? (() => {
    });
  }
  write(value, writer) {
    this.validate(value);
    __privateGet(this, _write).call(this, value, writer);
  }
  serialize(value, options) {
    this.validate(value);
    return new SerializedBcs(this, __privateGet(this, _serialize).call(this, value, options));
  }
  parse(bytes) {
    const reader = new BcsReader(bytes);
    return this.read(reader);
  }
  fromHex(hex) {
    return this.parse(fromHex(hex));
  }
  fromBase58(b64) {
    return this.parse(fromBase58(b64));
  }
  fromBase64(b64) {
    return this.parse(fromBase64(b64));
  }
  transform({
    name: name2,
    input,
    output,
    validate
  }) {
    return new _BcsType2({
      name: name2 ?? this.name,
      read: (reader) => output ? output(this.read(reader)) : this.read(reader),
      write: (value, writer) => __privateGet(this, _write).call(this, input ? input(value) : value, writer),
      serializedSize: (value) => this.serializedSize(input ? input(value) : value),
      serialize: (value, options) => __privateGet(this, _serialize).call(this, input ? input(value) : value, options),
      validate: (value) => {
        validate?.(value);
        this.validate(input ? input(value) : value);
      }
    });
  }
};
_write = /* @__PURE__ */ new WeakMap();
_serialize = /* @__PURE__ */ new WeakMap();
var BcsType = _BcsType;
var SERIALIZED_BCS_BRAND = Symbol.for("@mysten/serialized-bcs");
var SerializedBcs = class {
  constructor(type, schema) {
    __privateAdd(this, _schema);
    __privateAdd(this, _bytes);
    __privateSet(this, _schema, type);
    __privateSet(this, _bytes, schema);
  }
  // Used to brand SerializedBcs so that they can be identified, even between multiple copies
  // of the @mysten/bcs package are installed
  get [SERIALIZED_BCS_BRAND]() {
    return true;
  }
  toBytes() {
    return __privateGet(this, _bytes);
  }
  toHex() {
    return toHex(__privateGet(this, _bytes));
  }
  toBase64() {
    return toBase64(__privateGet(this, _bytes));
  }
  toBase58() {
    return toBase58(__privateGet(this, _bytes));
  }
  parse() {
    return __privateGet(this, _schema).parse(__privateGet(this, _bytes));
  }
};
_schema = /* @__PURE__ */ new WeakMap();
_bytes = /* @__PURE__ */ new WeakMap();
function fixedSizeBcsType({
  size,
  ...options
}) {
  return new BcsType({
    ...options,
    serializedSize: () => size
  });
}
function uIntBcsType({
  readMethod,
  writeMethod,
  ...options
}) {
  return fixedSizeBcsType({
    ...options,
    read: (reader) => reader[readMethod](),
    write: (value, writer) => writer[writeMethod](value),
    validate: (value) => {
      if (value < 0 || value > options.maxValue) {
        throw new TypeError(
          `Invalid ${options.name} value: ${value}. Expected value in range 0-${options.maxValue}`
        );
      }
      options.validate?.(value);
    }
  });
}
function bigUIntBcsType({
  readMethod,
  writeMethod,
  ...options
}) {
  return fixedSizeBcsType({
    ...options,
    read: (reader) => reader[readMethod](),
    write: (value, writer) => writer[writeMethod](BigInt(value)),
    validate: (val) => {
      const value = BigInt(val);
      if (value < 0 || value > options.maxValue) {
        throw new TypeError(
          `Invalid ${options.name} value: ${value}. Expected value in range 0-${options.maxValue}`
        );
      }
      options.validate?.(value);
    }
  });
}
function dynamicSizeBcsType({
  serialize,
  ...options
}) {
  const type = new BcsType({
    ...options,
    serialize,
    write: (value, writer) => {
      for (const byte of type.serialize(value).toBytes()) {
        writer.write8(byte);
      }
    }
  });
  return type;
}
function stringLikeBcsType({
  toBytes,
  fromBytes,
  ...options
}) {
  return new BcsType({
    ...options,
    read: (reader) => {
      const length = reader.readULEB();
      const bytes = reader.readBytes(length);
      return fromBytes(bytes);
    },
    write: (hex, writer) => {
      const bytes = toBytes(hex);
      writer.writeULEB(bytes.length);
      for (let i = 0; i < bytes.length; i++) {
        writer.write8(bytes[i]);
      }
    },
    serialize: (value) => {
      const bytes = toBytes(value);
      const size = ulebEncode(bytes.length);
      const result = new Uint8Array(size.length + bytes.length);
      result.set(size, 0);
      result.set(bytes, size.length);
      return result;
    },
    validate: (value) => {
      if (typeof value !== "string") {
        throw new TypeError(`Invalid ${options.name} value: ${value}. Expected string`);
      }
      options.validate?.(value);
    }
  });
}
function lazyBcsType(cb) {
  let lazyType = null;
  function getType() {
    if (!lazyType) {
      lazyType = cb();
    }
    return lazyType;
  }
  return new BcsType({
    name: "lazy",
    read: (data) => getType().read(data),
    serializedSize: (value) => getType().serializedSize(value),
    write: (value, writer) => getType().write(value, writer),
    serialize: (value, options) => getType().serialize(value, options).toBytes()
  });
}
var BcsStruct2 = class extends BcsType {
  constructor({ name: name2, fields, ...options }) {
    const canonicalOrder = Object.entries(fields);
    super({
      name: name2,
      serializedSize: (values) => {
        let total = 0;
        for (const [field, type] of canonicalOrder) {
          const size = type.serializedSize(values[field]);
          if (size == null) {
            return null;
          }
          total += size;
        }
        return total;
      },
      read: (reader) => {
        const result = {};
        for (const [field, type] of canonicalOrder) {
          result[field] = type.read(reader);
        }
        return result;
      },
      write: (value, writer) => {
        for (const [field, type] of canonicalOrder) {
          type.write(value[field], writer);
        }
      },
      ...options,
      validate: (value) => {
        options?.validate?.(value);
        if (typeof value !== "object" || value == null) {
          throw new TypeError(`Expected object, found ${typeof value}`);
        }
      }
    });
  }
};
var BcsEnum2 = class extends BcsType {
  constructor({ fields, ...options }) {
    const canonicalOrder = Object.entries(fields);
    super({
      read: (reader) => {
        const index = reader.readULEB();
        const enumEntry = canonicalOrder[index];
        if (!enumEntry) {
          throw new TypeError(`Unknown value ${index} for enum ${name}`);
        }
        const [kind, type] = enumEntry;
        return {
          [kind]: type?.read(reader) ?? true,
          $kind: kind
        };
      },
      write: (value, writer) => {
        const [name2, val] = Object.entries(value).filter(
          ([name3]) => Object.hasOwn(fields, name3)
        )[0];
        for (let i = 0; i < canonicalOrder.length; i++) {
          const [optionName, optionType] = canonicalOrder[i];
          if (optionName === name2) {
            writer.writeULEB(i);
            optionType?.write(val, writer);
            return;
          }
        }
      },
      ...options,
      validate: (value) => {
        options?.validate?.(value);
        if (typeof value !== "object" || value == null) {
          throw new TypeError(`Expected object, found ${typeof value}`);
        }
        const keys = Object.keys(value).filter(
          (k) => value[k] !== void 0 && Object.hasOwn(fields, k)
        );
        if (keys.length !== 1) {
          throw new TypeError(
            `Expected object with one key, but found ${keys.length} for type ${name}}`
          );
        }
        const [variant] = keys;
        if (!Object.hasOwn(fields, variant)) {
          throw new TypeError(`Invalid enum variant ${variant}`);
        }
      }
    });
  }
};
var BcsTuple2 = class extends BcsType {
  constructor({ fields, name: name2, ...options }) {
    super({
      name: name2 ?? `(${fields.map((t) => t.name).join(", ")})`,
      serializedSize: (values) => {
        let total = 0;
        for (let i = 0; i < fields.length; i++) {
          const size = fields[i].serializedSize(values[i]);
          if (size == null) {
            return null;
          }
          total += size;
        }
        return total;
      },
      read: (reader) => {
        const result = [];
        for (const field of fields) {
          result.push(field.read(reader));
        }
        return result;
      },
      write: (value, writer) => {
        for (let i = 0; i < fields.length; i++) {
          fields[i].write(value[i], writer);
        }
      },
      ...options,
      validate: (value) => {
        options?.validate?.(value);
        if (!Array.isArray(value)) {
          throw new TypeError(`Expected array, found ${typeof value}`);
        }
        if (value.length !== fields.length) {
          throw new TypeError(`Expected array of length ${fields.length}, found ${value.length}`);
        }
      }
    });
  }
};

// node_modules/@mysten/walrus/node_modules/@mysten/bcs/dist/esm/bcs.js
function fixedArray(size, type, options) {
  return new BcsType({
    read: (reader) => {
      const result = new Array(size);
      for (let i = 0; i < size; i++) {
        result[i] = type.read(reader);
      }
      return result;
    },
    write: (value, writer) => {
      for (const item of value) {
        type.write(item, writer);
      }
    },
    ...options,
    name: options?.name ?? `${type.name}[${size}]`,
    validate: (value) => {
      options?.validate?.(value);
      if (!value || typeof value !== "object" || !("length" in value)) {
        throw new TypeError(`Expected array, found ${typeof value}`);
      }
      if (value.length !== size) {
        throw new TypeError(`Expected array of length ${size}, found ${value.length}`);
      }
    }
  });
}
function option(type) {
  return bcs.enum(`Option<${type.name}>`, {
    None: null,
    Some: type
  }).transform({
    input: (value) => {
      if (value == null) {
        return { None: true };
      }
      return { Some: value };
    },
    output: (value) => {
      if (value.$kind === "Some") {
        return value.Some;
      }
      return null;
    }
  });
}
function vector(type, options) {
  return new BcsType({
    read: (reader) => {
      const length = reader.readULEB();
      const result = new Array(length);
      for (let i = 0; i < length; i++) {
        result[i] = type.read(reader);
      }
      return result;
    },
    write: (value, writer) => {
      writer.writeULEB(value.length);
      for (const item of value) {
        type.write(item, writer);
      }
    },
    ...options,
    name: options?.name ?? `vector<${type.name}>`,
    validate: (value) => {
      options?.validate?.(value);
      if (!value || typeof value !== "object" || !("length" in value)) {
        throw new TypeError(`Expected array, found ${typeof value}`);
      }
    }
  });
}
function map(keyType, valueType) {
  return bcs.vector(bcs.tuple([keyType, valueType])).transform({
    name: `Map<${keyType.name}, ${valueType.name}>`,
    input: (value) => {
      return [...value.entries()];
    },
    output: (value) => {
      const result = /* @__PURE__ */ new Map();
      for (const [key, val] of value) {
        result.set(key, val);
      }
      return result;
    }
  });
}
var bcs = {
  /**
   * Creates a BcsType that can be used to read and write an 8-bit unsigned integer.
   * @example
   * bcs.u8().serialize(255).toBytes() // Uint8Array [ 255 ]
   */
  u8(options) {
    return uIntBcsType({
      readMethod: "read8",
      writeMethod: "write8",
      size: 1,
      maxValue: 2 ** 8 - 1,
      ...options,
      name: options?.name ?? "u8"
    });
  },
  /**
   * Creates a BcsType that can be used to read and write a 16-bit unsigned integer.
   * @example
   * bcs.u16().serialize(65535).toBytes() // Uint8Array [ 255, 255 ]
   */
  u16(options) {
    return uIntBcsType({
      readMethod: "read16",
      writeMethod: "write16",
      size: 2,
      maxValue: 2 ** 16 - 1,
      ...options,
      name: options?.name ?? "u16"
    });
  },
  /**
   * Creates a BcsType that can be used to read and write a 32-bit unsigned integer.
   * @example
   * bcs.u32().serialize(4294967295).toBytes() // Uint8Array [ 255, 255, 255, 255 ]
   */
  u32(options) {
    return uIntBcsType({
      readMethod: "read32",
      writeMethod: "write32",
      size: 4,
      maxValue: 2 ** 32 - 1,
      ...options,
      name: options?.name ?? "u32"
    });
  },
  /**
   * Creates a BcsType that can be used to read and write a 64-bit unsigned integer.
   * @example
   * bcs.u64().serialize(1).toBytes() // Uint8Array [ 1, 0, 0, 0, 0, 0, 0, 0 ]
   */
  u64(options) {
    return bigUIntBcsType({
      readMethod: "read64",
      writeMethod: "write64",
      size: 8,
      maxValue: 2n ** 64n - 1n,
      ...options,
      name: options?.name ?? "u64"
    });
  },
  /**
   * Creates a BcsType that can be used to read and write a 128-bit unsigned integer.
   * @example
   * bcs.u128().serialize(1).toBytes() // Uint8Array [ 1, ..., 0 ]
   */
  u128(options) {
    return bigUIntBcsType({
      readMethod: "read128",
      writeMethod: "write128",
      size: 16,
      maxValue: 2n ** 128n - 1n,
      ...options,
      name: options?.name ?? "u128"
    });
  },
  /**
   * Creates a BcsType that can be used to read and write a 256-bit unsigned integer.
   * @example
   * bcs.u256().serialize(1).toBytes() // Uint8Array [ 1, ..., 0 ]
   */
  u256(options) {
    return bigUIntBcsType({
      readMethod: "read256",
      writeMethod: "write256",
      size: 32,
      maxValue: 2n ** 256n - 1n,
      ...options,
      name: options?.name ?? "u256"
    });
  },
  /**
   * Creates a BcsType that can be used to read and write boolean values.
   * @example
   * bcs.bool().serialize(true).toBytes() // Uint8Array [ 1 ]
   */
  bool(options) {
    return fixedSizeBcsType({
      size: 1,
      read: (reader) => reader.read8() === 1,
      write: (value, writer) => writer.write8(value ? 1 : 0),
      ...options,
      name: options?.name ?? "bool",
      validate: (value) => {
        options?.validate?.(value);
        if (typeof value !== "boolean") {
          throw new TypeError(`Expected boolean, found ${typeof value}`);
        }
      }
    });
  },
  /**
   * Creates a BcsType that can be used to read and write unsigned LEB encoded integers
   * @example
   *
   */
  uleb128(options) {
    return dynamicSizeBcsType({
      read: (reader) => reader.readULEB(),
      serialize: (value) => {
        return Uint8Array.from(ulebEncode(value));
      },
      ...options,
      name: options?.name ?? "uleb128"
    });
  },
  /**
   * Creates a BcsType representing a fixed length byte array
   * @param size The number of bytes this types represents
   * @example
   * bcs.bytes(3).serialize(new Uint8Array([1, 2, 3])).toBytes() // Uint8Array [1, 2, 3]
   */
  bytes(size, options) {
    return fixedSizeBcsType({
      size,
      read: (reader) => reader.readBytes(size),
      write: (value, writer) => {
        const array = new Uint8Array(value);
        for (let i = 0; i < size; i++) {
          writer.write8(array[i] ?? 0);
        }
      },
      ...options,
      name: options?.name ?? `bytes[${size}]`,
      validate: (value) => {
        options?.validate?.(value);
        if (!value || typeof value !== "object" || !("length" in value)) {
          throw new TypeError(`Expected array, found ${typeof value}`);
        }
        if (value.length !== size) {
          throw new TypeError(`Expected array of length ${size}, found ${value.length}`);
        }
      }
    });
  },
  /**
   * Creates a BcsType representing a variable length byte array
   *
   * @example
   * bcs.byteVector().serialize([1, 2, 3]).toBytes() // Uint8Array [3, 1, 2, 3]
   */
  byteVector(options) {
    return new BcsType({
      read: (reader) => {
        const length = reader.readULEB();
        return reader.readBytes(length);
      },
      write: (value, writer) => {
        const array = new Uint8Array(value);
        writer.writeULEB(array.length);
        for (let i = 0; i < array.length; i++) {
          writer.write8(array[i] ?? 0);
        }
      },
      ...options,
      name: options?.name ?? "vector<u8>",
      serializedSize: (value) => {
        const length = "length" in value ? value.length : null;
        return length == null ? null : ulebEncode(length).length + length;
      },
      validate: (value) => {
        options?.validate?.(value);
        if (!value || typeof value !== "object" || !("length" in value)) {
          throw new TypeError(`Expected array, found ${typeof value}`);
        }
      }
    });
  },
  /**
   * Creates a BcsType that can ser/de string values.  Strings will be UTF-8 encoded
   * @example
   * bcs.string().serialize('a').toBytes() // Uint8Array [ 1, 97 ]
   */
  string(options) {
    return stringLikeBcsType({
      toBytes: (value) => new TextEncoder().encode(value),
      fromBytes: (bytes) => new TextDecoder().decode(bytes),
      ...options,
      name: options?.name ?? "string"
    });
  },
  /**
   * Creates a BcsType that represents a fixed length array of a given type
   * @param size The number of elements in the array
   * @param type The BcsType of each element in the array
   * @example
   * bcs.fixedArray(3, bcs.u8()).serialize([1, 2, 3]).toBytes() // Uint8Array [ 1, 2, 3 ]
   */
  fixedArray,
  /**
   * Creates a BcsType representing an optional value
   * @param type The BcsType of the optional value
   * @example
   * bcs.option(bcs.u8()).serialize(null).toBytes() // Uint8Array [ 0 ]
   * bcs.option(bcs.u8()).serialize(1).toBytes() // Uint8Array [ 1, 1 ]
   */
  option,
  /**
   * Creates a BcsType representing a variable length vector of a given type
   * @param type The BcsType of each element in the vector
   *
   * @example
   * bcs.vector(bcs.u8()).toBytes([1, 2, 3]) // Uint8Array [ 3, 1, 2, 3 ]
   */
  vector,
  /**
   * Creates a BcsType representing a tuple of a given set of types
   * @param types The BcsTypes for each element in the tuple
   *
   * @example
   * const tuple = bcs.tuple([bcs.u8(), bcs.string(), bcs.bool()])
   * tuple.serialize([1, 'a', true]).toBytes() // Uint8Array [ 1, 1, 97, 1 ]
   */
  tuple(fields, options) {
    return new BcsTuple2({
      fields,
      ...options
    });
  },
  /**
   * Creates a BcsType representing a struct of a given set of fields
   * @param name The name of the struct
   * @param fields The fields of the struct. The order of the fields affects how data is serialized and deserialized
   *
   * @example
   * const struct = bcs.struct('MyStruct', {
   *  a: bcs.u8(),
   *  b: bcs.string(),
   * })
   * struct.serialize({ a: 1, b: 'a' }).toBytes() // Uint8Array [ 1, 1, 97 ]
   */
  struct(name2, fields, options) {
    return new BcsStruct2({
      name: name2,
      fields,
      ...options
    });
  },
  /**
   * Creates a BcsType representing an enum of a given set of options
   * @param name The name of the enum
   * @param values The values of the enum. The order of the values affects how data is serialized and deserialized.
   * null can be used to represent a variant with no data.
   *
   * @example
   * const enum = bcs.enum('MyEnum', {
   *   A: bcs.u8(),
   *   B: bcs.string(),
   *   C: null,
   * })
   * enum.serialize({ A: 1 }).toBytes() // Uint8Array [ 0, 1 ]
   * enum.serialize({ B: 'a' }).toBytes() // Uint8Array [ 1, 1, 97 ]
   * enum.serialize({ C: true }).toBytes() // Uint8Array [ 2 ]
   */
  enum(name2, fields, options) {
    return new BcsEnum2({
      name: name2,
      fields,
      ...options
    });
  },
  /**
   * Creates a BcsType representing a map of a given key and value type
   * @param keyType The BcsType of the key
   * @param valueType The BcsType of the value
   * @example
   * const map = bcs.map(bcs.u8(), bcs.string())
   * map.serialize(new Map([[2, 'a']])).toBytes() // Uint8Array [ 1, 2, 1, 97 ]
   */
  map,
  /**
   * Creates a BcsType that wraps another BcsType which is lazily evaluated. This is useful for creating recursive types.
   * @param cb A callback that returns the BcsType
   */
  lazy(cb) {
    return lazyBcsType(cb);
  }
};

// node_modules/@mysten/walrus/dist/esm/constants.js
var TESTNET_WALRUS_PACKAGE_CONFIG = {
  systemObjectId: "0x6c2547cbbc38025cf3adac45f63cb0a8d12ecf777cdc75a4971612bf97fdf6af",
  stakingPoolId: "0xbe46180321c30aab2f8b3501e24048377287fa708018a5b7c2792b35fe339ee3",
  exchangeIds: [
    "0xf4d164ea2def5fe07dc573992a029e010dba09b1a8dcbc44c5c2e79567f39073",
    "0x19825121c52080bb1073662231cfea5c0e4d905fd13e95f21e9a018f2ef41862",
    "0x83b454e524c71f30803f4d6c302a86fb6a39e96cdfb873c2d1e93bc1c26a3bc5",
    "0x8d63209cf8589ce7aef8f262437163c67577ed09f3e636a9d8e0813843fb8bf1"
  ]
};
var MAINNET_WALRUS_PACKAGE_CONFIG = {
  systemObjectId: "0x2134d52768ea07e8c43570ef975eb3e4c27a39fa6396bef985b5abc58d03ddd2",
  stakingPoolId: "0x10b9d30c28448939ce6c4d6c6e0ffce4a7f8a4ada8248bdad09ef8b70e4a3904"
};
var statusLifecycleRank = {
  nonexistent: 0,
  deletable: 1,
  permanent: 2,
  invalid: 3
};

// node_modules/@mysten/walrus/dist/esm/contracts/utils/index.js
var MOVE_STDLIB_ADDRESS = normalizeSuiAddress("0x1");
var SUI_FRAMEWORK_ADDRESS = normalizeSuiAddress("0x2");
var SUI_SYSTEM_ADDRESS = normalizeSuiAddress("0x3");
function getPureBcsSchema(typeTag) {
  const parsedTag = typeof typeTag === "string" ? TypeTagSerializer.parseFromStr(typeTag) : typeTag;
  if ("u8" in parsedTag) {
    return suiBcs.U8;
  } else if ("u16" in parsedTag) {
    return suiBcs.U16;
  } else if ("u32" in parsedTag) {
    return suiBcs.U32;
  } else if ("u64" in parsedTag) {
    return suiBcs.U64;
  } else if ("u128" in parsedTag) {
    return suiBcs.U128;
  } else if ("u256" in parsedTag) {
    return suiBcs.U256;
  } else if ("address" in parsedTag) {
    return suiBcs.Address;
  } else if ("bool" in parsedTag) {
    return suiBcs.Bool;
  } else if ("vector" in parsedTag) {
    const type = getPureBcsSchema(parsedTag.vector);
    return type ? suiBcs.vector(type) : null;
  } else if ("struct" in parsedTag) {
    const structTag = parsedTag.struct;
    const pkg = normalizeSuiAddress(parsedTag.struct.address);
    if (pkg === MOVE_STDLIB_ADDRESS) {
      if ((structTag.module === "ascii" || structTag.module === "string") && structTag.name === "String") {
        return suiBcs.String;
      }
      if (structTag.module === "option" && structTag.name === "Option") {
        const type = getPureBcsSchema(structTag.typeParams[0]);
        return type ? suiBcs.vector(type) : null;
      }
    }
    if (pkg === SUI_FRAMEWORK_ADDRESS && structTag.module === "Object" && structTag.name === "ID") {
      return suiBcs.Address;
    }
  }
  return null;
}
function normalizeMoveArguments(args, argTypes, parameterNames) {
  if (parameterNames && argTypes.length !== parameterNames.length) {
    throw new Error(
      `Invalid number of parameterNames, expected ${argTypes.length}, got ${parameterNames.length}`
    );
  }
  const normalizedArgs = [];
  let index = 0;
  for (const [i, argType] of argTypes.entries()) {
    if (argType === `${SUI_FRAMEWORK_ADDRESS}::deny_list::DenyList`) {
      normalizedArgs.push((tx) => tx.object.denyList());
      continue;
    }
    if (argType === `${SUI_FRAMEWORK_ADDRESS}::random::Random`) {
      normalizedArgs.push((tx) => tx.object.random());
      continue;
    }
    if (argType === `${SUI_FRAMEWORK_ADDRESS}::clock::Clock`) {
      normalizedArgs.push((tx) => tx.object.clock());
      continue;
    }
    if (argType === `${SUI_SYSTEM_ADDRESS}::sui_system::SuiSystemState`) {
      normalizedArgs.push((tx) => tx.object.system());
      continue;
    }
    let arg;
    if (Array.isArray(args)) {
      if (index >= args.length) {
        throw new Error(
          `Invalid number of arguments, expected at least ${index + 1}, got ${args.length}`
        );
      }
      arg = args[index];
    } else {
      if (!parameterNames) {
        throw new Error(`Expected arguments to be passed as an array`);
      }
      const name2 = parameterNames[index];
      arg = args[name2];
      if (arg == null) {
        throw new Error(`Parameter ${name2} is required`);
      }
    }
    index += 1;
    if (typeof arg === "function" || isArgument(arg)) {
      normalizedArgs.push(arg);
      continue;
    }
    const type = argTypes[i];
    const bcsType = getPureBcsSchema(type);
    if (bcsType) {
      const bytes = bcsType.serialize(arg);
      normalizedArgs.push((tx) => tx.pure(bytes));
      continue;
    } else if (typeof arg === "string") {
      normalizedArgs.push((tx) => tx.object(arg));
      continue;
    }
    throw new Error(`Invalid argument ${stringify(arg)} for type ${type}`);
  }
  return normalizedArgs;
}
var MoveStruct = class extends BcsStruct {
};
var MoveEnum = class extends BcsEnum {
};
var MoveTuple = class extends BcsTuple {
};
function stringify(val) {
  if (typeof val === "object") {
    return JSON.stringify(val, (val2) => val2);
  }
  if (typeof val === "bigint") {
    return val.toString();
  }
  return val;
}

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/deps/sui/object.js
var $moduleName = "0x2::object";
var UID = new MoveStruct({
  name: `${$moduleName}::UID`,
  fields: {
    id: suiBcs.Address
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/storage_resource.js
var $moduleName2 = "@local-pkg/walrus::storage_resource";
var Storage = new MoveStruct({
  name: `${$moduleName2}::Storage`,
  fields: {
    id: UID,
    start_epoch: suiBcs.u32(),
    end_epoch: suiBcs.u32(),
    storage_size: suiBcs.u64()
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/blob.js
var $moduleName3 = "@local-pkg/walrus::blob";
var Blob = new MoveStruct({
  name: `${$moduleName3}::Blob`,
  fields: {
    id: UID,
    registered_epoch: suiBcs.u32(),
    blob_id: suiBcs.u256(),
    size: suiBcs.u64(),
    encoding_type: suiBcs.u8(),
    certified_epoch: suiBcs.option(suiBcs.u32()),
    storage: Storage,
    deletable: suiBcs.bool()
  }
});
var BlobIdDerivation = new MoveStruct({
  name: `${$moduleName3}::BlobIdDerivation`,
  fields: {
    encoding_type: suiBcs.u8(),
    size: suiBcs.u64(),
    root_hash: suiBcs.u256()
  }
});
function addMetadata(options) {
  const packageAddress = options.package ?? "@local-pkg/walrus";
  const argumentsTypes = [
    `${packageAddress}::blob::Blob`,
    `${packageAddress}::metadata::Metadata`
  ];
  const parameterNames = ["self", "metadata"];
  return (tx) => tx.moveCall({
    package: packageAddress,
    module: "blob",
    function: "add_metadata",
    arguments: normalizeMoveArguments(options.arguments, argumentsTypes, parameterNames)
  });
}
function insertOrUpdateMetadataPair(options) {
  const packageAddress = options.package ?? "@local-pkg/walrus";
  const argumentsTypes = [
    `${packageAddress}::blob::Blob`,
    "0x0000000000000000000000000000000000000000000000000000000000000001::string::String",
    "0x0000000000000000000000000000000000000000000000000000000000000001::string::String"
  ];
  const parameterNames = ["self", "key", "value"];
  return (tx) => tx.moveCall({
    package: packageAddress,
    module: "blob",
    function: "insert_or_update_metadata_pair",
    arguments: normalizeMoveArguments(options.arguments, argumentsTypes, parameterNames)
  });
}
function removeMetadataPair(options) {
  const packageAddress = options.package ?? "@local-pkg/walrus";
  const argumentsTypes = [
    `${packageAddress}::blob::Blob`,
    "0x0000000000000000000000000000000000000000000000000000000000000001::string::String"
  ];
  const parameterNames = ["self", "key"];
  return (tx) => tx.moveCall({
    package: packageAddress,
    module: "blob",
    function: "remove_metadata_pair",
    arguments: normalizeMoveArguments(options.arguments, argumentsTypes, parameterNames)
  });
}

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/deps/sui/vec_map.js
var $moduleName4 = "0x2::vec_map";
function Entry(...typeParameters) {
  return new MoveStruct({
    name: `${$moduleName4}::Entry<${typeParameters[0].name}, ${typeParameters[1].name}>`,
    fields: {
      key: typeParameters[0],
      value: typeParameters[1]
    }
  });
}
function VecMap(...typeParameters) {
  return new MoveStruct({
    name: `${$moduleName4}::VecMap<${typeParameters[0].name}, ${typeParameters[1].name}>`,
    fields: {
      contents: suiBcs.vector(Entry(typeParameters[0], typeParameters[1]))
    }
  });
}

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/metadata.js
var $moduleName5 = "@local-pkg/walrus::metadata";
var Metadata = new MoveStruct({
  name: `${$moduleName5}::Metadata`,
  fields: {
    metadata: VecMap(suiBcs.string(), suiBcs.string())
  }
});
function _new(options = {}) {
  const packageAddress = options.package ?? "@local-pkg/walrus";
  return (tx) => tx.moveCall({
    package: packageAddress,
    module: "metadata",
    function: "new"
  });
}

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/deps/sui/object_table.js
var $moduleName6 = "0x2::object_table";
var ObjectTable = new MoveStruct({
  name: `${$moduleName6}::ObjectTable`,
  fields: {
    /** the ID of this table */
    id: UID,
    /** the number of key-value pairs in the table */
    size: suiBcs.u64()
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/extended_field.js
var $moduleName7 = "@local-pkg/walrus::extended_field";
var ExtendedField = new MoveStruct({
  name: `${$moduleName7}::ExtendedField`,
  fields: {
    id: UID
  }
});
var Key = new MoveTuple({ name: `${$moduleName7}::Key`, fields: [suiBcs.bool()] });

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/committee.js
var $moduleName8 = "@local-pkg/walrus::committee";
var Committee = new MoveTuple({
  name: `${$moduleName8}::Committee`,
  fields: [VecMap(suiBcs.Address, suiBcs.vector(suiBcs.u16()))]
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/epoch_parameters.js
var $moduleName9 = "@local-pkg/walrus::epoch_parameters";
var EpochParams = new MoveStruct({
  name: `${$moduleName9}::EpochParams`,
  fields: {
    /** The storage capacity of the system. */
    total_capacity_size: suiBcs.u64(),
    /** The price per unit size of storage. */
    storage_price_per_unit_size: suiBcs.u64(),
    /** The write price per unit size. */
    write_price_per_unit_size: suiBcs.u64()
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/staking_inner.js
var $moduleName10 = "@local-pkg/walrus::staking_inner";
var EpochState = new MoveEnum({
  name: `${$moduleName10}::EpochState`,
  fields: {
    EpochChangeSync: suiBcs.u16(),
    EpochChangeDone: suiBcs.u64(),
    NextParamsSelected: suiBcs.u64()
  }
});
var StakingInnerV1 = new MoveStruct({
  name: `${$moduleName10}::StakingInnerV1`,
  fields: {
    /** The number of shards in the system. */
    n_shards: suiBcs.u16(),
    /** The duration of an epoch in ms. Does not affect the first (zero) epoch. */
    epoch_duration: suiBcs.u64(),
    /**
     * Special parameter, used only for the first epoch. The timestamp when the first
     * epoch can be started.
     */
    first_epoch_start: suiBcs.u64(),
    /**
     * Stored staking pools, each identified by a unique `ID` and contains the
     * `StakingPool` object. Uses `ObjectTable` to make the pool discovery easier by
     * avoiding wrapping.
     *
     * The key is the ID of the staking pool.
     */
    pools: ObjectTable,
    /**
     * The current epoch of the Walrus system. The epochs are not the same as the Sui
     * epochs, not to be mistaken with `ctx.epoch()`.
     */
    epoch: suiBcs.u32(),
    /** Stores the active set of storage nodes. Tracks the total amount of staked WAL. */
    active_set: ExtendedField,
    /** The next committee in the system. */
    next_committee: suiBcs.option(Committee),
    /** The current committee in the system. */
    committee: Committee,
    /** The previous committee in the system. */
    previous_committee: Committee,
    /** The next epoch parameters. */
    next_epoch_params: suiBcs.option(EpochParams),
    /** The state of the current epoch. */
    epoch_state: EpochState,
    /**
     * The public keys for the next epoch. The keys are stored in a sorted `VecMap`,
     * and mirror the order of the nodes in the `next_committee`. The value is set in
     * the `select_committee` function and consumed in the `next_bls_committee`
     * function.
     */
    next_epoch_public_keys: ExtendedField
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/deps/sui/group_ops.js
var $moduleName11 = "0x2::group_ops";
var Element = new MoveStruct({
  name: `${$moduleName11}::Element`,
  fields: {
    bytes: suiBcs.vector(suiBcs.u8())
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/event_blob.js
var $moduleName12 = "@local-pkg/walrus::event_blob";
var EventBlobAttestation = new MoveStruct({
  name: `${$moduleName12}::EventBlobAttestation`,
  fields: {
    checkpoint_sequence_num: suiBcs.u64(),
    epoch: suiBcs.u32()
  }
});
var EventBlob = new MoveStruct({
  name: `${$moduleName12}::EventBlob`,
  fields: {
    /** Blob id of the certified event blob. */
    blob_id: suiBcs.u256(),
    /** Ending sui checkpoint of the certified event blob. */
    ending_checkpoint_sequence_number: suiBcs.u64()
  }
});
var EventBlobCertificationState = new MoveStruct({
  name: `${$moduleName12}::EventBlobCertificationState`,
  fields: {
    /** Latest certified event blob. */
    latest_certified_blob: suiBcs.option(EventBlob),
    /** Current event blob being attested. */
    aggregate_weight_per_blob: VecMap(EventBlob, suiBcs.u16())
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/storage_node.js
var $moduleName13 = "@local-pkg/walrus::storage_node";
var StorageNodeInfo = new MoveStruct({
  name: `${$moduleName13}::StorageNodeInfo`,
  fields: {
    name: suiBcs.string(),
    node_id: suiBcs.Address,
    network_address: suiBcs.string(),
    public_key: Element,
    next_epoch_public_key: suiBcs.option(Element),
    network_public_key: suiBcs.vector(suiBcs.u8()),
    metadata: ExtendedField
  }
});
var StorageNodeCap = new MoveStruct({
  name: `${$moduleName13}::StorageNodeCap`,
  fields: {
    id: UID,
    node_id: suiBcs.Address,
    last_epoch_sync_done: suiBcs.u32(),
    last_event_blob_attestation: suiBcs.option(EventBlobAttestation),
    /** Stores the Merkle root of the deny list for the storage node. */
    deny_list_root: suiBcs.u256(),
    /** Stores the sequence number of the deny list for the storage node. */
    deny_list_sequence: suiBcs.u64(),
    /** Stores the size of the deny list for the storage node. */
    deny_list_size: suiBcs.u64()
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/pending_values.js
var $moduleName14 = "@local-pkg/walrus::pending_values";
var PendingValues = new MoveTuple({
  name: `${$moduleName14}::PendingValues`,
  fields: [VecMap(suiBcs.u32(), suiBcs.u64())]
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/deps/sui/table.js
var $moduleName15 = "0x2::table";
var Table = new MoveStruct({
  name: `${$moduleName15}::Table`,
  fields: {
    /** the ID of this table */
    id: UID,
    /** the number of key-value pairs in the table */
    size: suiBcs.u64()
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/deps/sui/balance.js
var $moduleName16 = "0x2::balance";
var Balance = new MoveStruct({
  name: `${$moduleName16}::Balance`,
  fields: {
    value: suiBcs.u64()
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/auth.js
var $moduleName17 = "@local-pkg/walrus::auth";
var Authenticated = new MoveEnum({
  name: `${$moduleName17}::Authenticated`,
  fields: {
    Sender: suiBcs.Address,
    Object: suiBcs.Address
  }
});
var Authorized = new MoveEnum({
  name: `${$moduleName17}::Authorized`,
  fields: {
    Address: suiBcs.Address,
    ObjectID: suiBcs.Address
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/deps/sui/bag.js
var $moduleName18 = "0x2::bag";
var Bag = new MoveStruct({
  name: `${$moduleName18}::Bag`,
  fields: {
    /** the ID of this bag */
    id: UID,
    /** the number of key-value pairs in the bag */
    size: suiBcs.u64()
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/staking_pool.js
var $moduleName19 = "@local-pkg/walrus::staking_pool";
var VotingParams = new MoveStruct({
  name: `${$moduleName19}::VotingParams`,
  fields: {
    /** Voting: storage price for the next epoch. */
    storage_price: suiBcs.u64(),
    /** Voting: write price for the next epoch. */
    write_price: suiBcs.u64(),
    /** Voting: node capacity for the next epoch. */
    node_capacity: suiBcs.u64()
  }
});
var PoolState = new MoveEnum({
  name: `${$moduleName19}::PoolState`,
  fields: {
    Active: null,
    Withdrawing: suiBcs.u32(),
    Withdrawn: null
  }
});
var StakingPool = new MoveStruct({
  name: `${$moduleName19}::StakingPool`,
  fields: {
    id: UID,
    /** The current state of the pool. */
    state: PoolState,
    /** Current epoch's pool parameters. */
    voting_params: VotingParams,
    /** The storage node info for the pool. */
    node_info: StorageNodeInfo,
    /**
     * The epoch when the pool is / will be activated. Serves information purposes
     * only, the checks are performed in the `state` property.
     */
    activation_epoch: suiBcs.u32(),
    /** Epoch when the pool was last updated. */
    latest_epoch: suiBcs.u32(),
    /** Currently staked WAL in the pool + rewards pool. */
    wal_balance: suiBcs.u64(),
    /** The total number of shares in the current epoch. */
    num_shares: suiBcs.u64(),
    /**
     * The amount of the shares that will be withdrawn in E+1 or E+2. We use this
     * amount to calculate the WAL withdrawal in the `process_pending_stake`.
     */
    pending_shares_withdraw: PendingValues,
    /**
     * The amount of the stake requested for withdrawal for a node that may part of the
     * next committee. Stores principals of not yet active stakes. In practice, those
     * tokens are staked for exactly one epoch.
     */
    pre_active_withdrawals: PendingValues,
    /**
     * The pending commission rate for the pool. Commission rate is applied in E+2, so
     * we store the value for the matching epoch and apply it in the `advance_epoch`
     * function.
     */
    pending_commission_rate: PendingValues,
    /** The commission rate for the pool, in basis points. */
    commission_rate: suiBcs.u16(),
    /**
     * Historical exchange rates for the pool. The key is the epoch when the exchange
     * rate was set, and the value is the exchange rate (the ratio of the amount of WAL
     * tokens for the pool shares).
     */
    exchange_rates: Table,
    /**
     * The amount of stake that will be added to the `wal_balance`. Can hold up to two
     * keys: E+1 and E+2, due to the differences in the activation epoch.
     *
     * ```
     * E+1 -> Balance
     * E+2 -> Balance
     * ```
     *
     * Single key is cleared in the `advance_epoch` function, leaving only the next
     * epoch's stake.
     */
    pending_stake: PendingValues,
    /** The rewards that the pool has received from being in the committee. */
    rewards_pool: Balance,
    /** The commission that the pool has received from the rewards. */
    commission: Balance,
    /** An Object or an address which can claim the commission. */
    commission_receiver: Authorized,
    /** An Object or address that can authorize governance actions, such as upgrades. */
    governance_authorized: Authorized,
    /** Reserved for future use and migrations. */
    extra_fields: Bag
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/staking.js
var $moduleName20 = "@local-pkg/walrus::staking";
var Staking = new MoveStruct({
  name: `${$moduleName20}::Staking`,
  fields: {
    id: UID,
    version: suiBcs.u64(),
    package_id: suiBcs.Address,
    new_package_id: suiBcs.option(suiBcs.Address)
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/bls_aggregate.js
var $moduleName21 = "@local-pkg/walrus::bls_aggregate";
var BlsCommitteeMember = new MoveStruct({
  name: `${$moduleName21}::BlsCommitteeMember`,
  fields: {
    public_key: Element,
    weight: suiBcs.u16(),
    node_id: suiBcs.Address
  }
});
var BlsCommittee = new MoveStruct({
  name: `${$moduleName21}::BlsCommittee`,
  fields: {
    /** A vector of committee members */
    members: suiBcs.vector(BlsCommitteeMember),
    /** The total number of shards held by the committee */
    n_shards: suiBcs.u16(),
    /** The epoch in which the committee is active. */
    epoch: suiBcs.u32(),
    /** The aggregation of public keys for all members of the committee */
    total_aggregated_key: Element
  }
});
var RequiredWeight = new MoveEnum({
  name: `${$moduleName21}::RequiredWeight`,
  fields: {
    /** Verify that the signers form a quorum. */
    Quorum: null,
    /** Verify that the signers include at least one correct node. */
    OneCorrectNode: null
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/storage_accounting.js
var $moduleName22 = "@local-pkg/walrus::storage_accounting";
var FutureAccounting = new MoveStruct({
  name: `${$moduleName22}::FutureAccounting`,
  fields: {
    epoch: suiBcs.u32(),
    /**
     * This field stores `used_capacity` for the epoch. Currently, impossible to rename
     * due to package upgrade limitations.
     */
    used_capacity: suiBcs.u64(),
    rewards_to_distribute: Balance
  }
});
var FutureAccountingRingBuffer = new MoveStruct({
  name: `${$moduleName22}::FutureAccountingRingBuffer`,
  fields: {
    current_index: suiBcs.u32(),
    length: suiBcs.u32(),
    ring_buffer: suiBcs.vector(FutureAccounting)
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/system_state_inner.js
var $moduleName23 = "@local-pkg/walrus::system_state_inner";
var SystemStateInnerV1 = new MoveStruct({
  name: `${$moduleName23}::SystemStateInnerV1`,
  fields: {
    /** The current committee, with the current epoch. */
    committee: BlsCommittee,
    /**
     * Maximum capacity size for the current and future epochs. Changed by voting on
     * the epoch parameters.
     */
    total_capacity_size: suiBcs.u64(),
    /** Contains the used capacity size for the current epoch. */
    used_capacity_size: suiBcs.u64(),
    /** The price per unit size of storage. */
    storage_price_per_unit_size: suiBcs.u64(),
    /** The write price per unit size. */
    write_price_per_unit_size: suiBcs.u64(),
    /** Accounting ring buffer for future epochs. */
    future_accounting: FutureAccountingRingBuffer,
    /** Event blob certification state */
    event_blob_certification_state: EventBlobCertificationState,
    /**
     * Sizes of deny lists for storage nodes. Only current committee members can
     * register their updates in this map. Hence, we don't expect it to bloat.
     *
     * Max number of stored entries is ~6500. If there's any concern about the
     * performance of the map, it can be cleaned up as a side effect of the updates /
     * registrations.
     */
    deny_list_sizes: ExtendedField
  }
});

// node_modules/@mysten/walrus/dist/esm/contracts/walrus/system.js
var $moduleName24 = "@local-pkg/walrus::system";
var System = new MoveStruct({
  name: `${$moduleName24}::System`,
  fields: {
    id: UID,
    version: suiBcs.u64(),
    package_id: suiBcs.Address,
    new_package_id: suiBcs.option(suiBcs.Address)
  }
});
function reserveSpace(options) {
  const packageAddress = options.package ?? "@local-pkg/walrus";
  const argumentsTypes = [
    `${packageAddress}::system::System`,
    "u64",
    "u32",
    `0x0000000000000000000000000000000000000000000000000000000000000002::coin::Coin<${packageAddress}::wal::WAL>`
  ];
  const parameterNames = ["self", "storageAmount", "epochsAhead", "payment"];
  return (tx) => tx.moveCall({
    package: packageAddress,
    module: "system",
    function: "reserve_space",
    arguments: normalizeMoveArguments(options.arguments, argumentsTypes, parameterNames)
  });
}
function registerBlob(options) {
  const packageAddress = options.package ?? "@local-pkg/walrus";
  const argumentsTypes = [
    `${packageAddress}::system::System`,
    `${packageAddress}::storage_resource::Storage`,
    "u256",
    "u256",
    "u64",
    "u8",
    "bool",
    `0x0000000000000000000000000000000000000000000000000000000000000002::coin::Coin<${packageAddress}::wal::WAL>`
  ];
  const parameterNames = [
    "self",
    "storage",
    "blobId",
    "rootHash",
    "size",
    "encodingType",
    "deletable",
    "writePayment"
  ];
  return (tx) => tx.moveCall({
    package: packageAddress,
    module: "system",
    function: "register_blob",
    arguments: normalizeMoveArguments(options.arguments, argumentsTypes, parameterNames)
  });
}
function certifyBlob(options) {
  const packageAddress = options.package ?? "@local-pkg/walrus";
  const argumentsTypes = [
    `${packageAddress}::system::System`,
    `${packageAddress}::blob::Blob`,
    "vector<u8>",
    "vector<u8>",
    "vector<u8>"
  ];
  const parameterNames = ["self", "blob", "signature", "signersBitmap", "message"];
  return (tx) => tx.moveCall({
    package: packageAddress,
    module: "system",
    function: "certify_blob",
    arguments: normalizeMoveArguments(options.arguments, argumentsTypes, parameterNames)
  });
}
function deleteBlob(options) {
  const packageAddress = options.package ?? "@local-pkg/walrus";
  const argumentsTypes = [
    `${packageAddress}::system::System`,
    `${packageAddress}::blob::Blob`
  ];
  const parameterNames = ["self", "blob"];
  return (tx) => tx.moveCall({
    package: packageAddress,
    module: "system",
    function: "delete_blob",
    arguments: normalizeMoveArguments(options.arguments, argumentsTypes, parameterNames)
  });
}
function extendBlob(options) {
  const packageAddress = options.package ?? "@local-pkg/walrus";
  const argumentsTypes = [
    `${packageAddress}::system::System`,
    `${packageAddress}::blob::Blob`,
    "u32",
    `0x0000000000000000000000000000000000000000000000000000000000000002::coin::Coin<${packageAddress}::wal::WAL>`
  ];
  const parameterNames = ["self", "blob", "extendedEpochs", "payment"];
  return (tx) => tx.moveCall({
    package: packageAddress,
    module: "system",
    function: "extend_blob",
    arguments: normalizeMoveArguments(options.arguments, argumentsTypes, parameterNames)
  });
}

// node_modules/@mysten/walrus/dist/esm/error.js
var WalrusClientError = class extends Error {
};
var RetryableWalrusClientError = class extends WalrusClientError {
};
var NoBlobStatusReceivedError = class extends WalrusClientError {
};
var NoVerifiedBlobStatusReceivedError = class extends WalrusClientError {
};
var NoBlobMetadataReceivedError = class extends RetryableWalrusClientError {
};
var NotEnoughSliversReceivedError = class extends RetryableWalrusClientError {
};
var NotEnoughBlobConfirmationsError = class extends RetryableWalrusClientError {
};
var BehindCurrentEpochError = class extends RetryableWalrusClientError {
};
var BlobNotCertifiedError = class extends RetryableWalrusClientError {
};
var InconsistentBlobError = class extends WalrusClientError {
};
var BlobBlockedError = class extends Error {
};

// node_modules/@mysten/walrus/dist/esm/utils/bcs.js
var MerkleNode = suiBcs.enum("MerkleNode", {
  Empty: null,
  Digest: suiBcs.bytes(32)
});
var SliverPairMetadata = suiBcs.struct("SliverPairMetadata", {
  primary_hash: MerkleNode,
  secondary_hash: MerkleNode
});
var EncodingType = suiBcs.enum("EncodingType", {
  RedStuff: null,
  RS2: null
}).transform({
  input: (encodingType) => typeof encodingType === "string" ? { [encodingType]: null } : encodingType,
  output: (encodingType) => encodingType
});
var BlobMetadataV1 = suiBcs.struct("BlobMetadataV1", {
  encoding_type: EncodingType,
  unencoded_length: suiBcs.u64(),
  hashes: suiBcs.vector(SliverPairMetadata)
});
var BlobMetadata = suiBcs.enum("BlobMetadata", {
  V1: BlobMetadataV1
});
var BlobId = suiBcs.u256().transform({
  input: (blobId) => typeof blobId === "string" ? blobIdToInt(blobId) : blobId,
  output: (id) => blobIdFromInt(id)
});
function blobIdFromInt(blobId) {
  return suiBcs.u256().serialize(blobId).toBase64().replace(/=*$/, "").replaceAll("+", "-").replaceAll("/", "_");
}
function blobIdFromBytes(blobId) {
  return blobIdFromInt(suiBcs.u256().parse(blobId));
}
function blobIdToInt(blobId) {
  return BigInt(suiBcs.u256().fromBase64(blobId.replaceAll("-", "+").replaceAll("_", "/")));
}
var BlobMetadataWithId = suiBcs.struct("BlobMetadataWithId", {
  blobId: BlobId,
  metadata: BlobMetadata
});
var Symbols = suiBcs.struct("Symbols", {
  data: suiBcs.vector(suiBcs.u8()),
  symbol_size: suiBcs.u16()
});
var SliverData = suiBcs.struct("SliverData", {
  symbols: Symbols,
  index: suiBcs.u16()
});
var Sliver = suiBcs.enum("Sliver", {
  Primary: SliverData,
  Secondary: SliverData
});
var SliverPair = suiBcs.struct("SliverPair", {
  primary: SliverData,
  secondary: SliverData
});
var IntentType = ((IntentType2) => {
  IntentType2[IntentType2["PROOF_OF_POSSESSION_MSG"] = 0] = "PROOF_OF_POSSESSION_MSG";
  IntentType2[IntentType2["BLOB_CERT_MSG"] = 1] = "BLOB_CERT_MSG";
  IntentType2[IntentType2["INVALID_BLOB_ID_MSG"] = 2] = "INVALID_BLOB_ID_MSG";
  IntentType2[IntentType2["SYNC_SHARD_MSG"] = 3] = "SYNC_SHARD_MSG";
  return IntentType2;
})(IntentType || {});
var Intent = suiBcs.struct("Intent", {
  type: suiBcs.u8().transform({
    input: (type) => type,
    output: (type) => type
  }),
  version: suiBcs.u8(),
  appId: suiBcs.u8()
}).transform({
  input: (intent) => ({
    type: intent,
    version: 0,
    appId: 3
  }),
  output: (intent) => intent.type
});
function ProtocolMessage(messageContents) {
  return suiBcs.struct(`ProtocolMessage<${messageContents.name}>`, {
    intent: Intent,
    epoch: suiBcs.u32(),
    messageContents
  });
}
var BlobPersistenceType = suiBcs.enum("BlobPersistenceType", {
  Permanent: null,
  Deletable: suiBcs.struct("Deletable", {
    objectId: suiBcs.Address
  })
});
var StorageConfirmationBody = suiBcs.struct("StorageConfirmationBody", {
  blobId: BlobId,
  blobType: BlobPersistenceType
});
var StorageConfirmation = ProtocolMessage(StorageConfirmationBody);
function Field(...typeParameters) {
  return suiBcs.struct("Field", {
    id: suiBcs.Address,
    name: typeParameters[0],
    value: typeParameters[1]
  });
}
var QuiltPatchTags = suiBcs.map(suiBcs.string(), suiBcs.string()).transform({
  // tags is a BTreeMap, so we need to sort entries before serializing
  input: (tags) => new Map(
    [...tags instanceof Map ? tags : Object.entries(tags)].sort(
      ([a], [b]) => (
        // TODO: sorting for map keys should be moved into @mysten/bcs
        compareBcsBytes(suiBcs.string().serialize(a).toBytes(), suiBcs.string().serialize(b).toBytes())
      )
    )
  ),
  output: (tags) => Object.fromEntries(tags)
});
var QuiltPatchV1 = suiBcs.struct("QuiltPatchV1", {
  endIndex: suiBcs.u16(),
  identifier: suiBcs.string(),
  tags: QuiltPatchTags
});
function compareBcsBytes(a, b) {
  if (a.length !== b.length) {
    return a.length - b.length;
  }
  for (let i = 0; i < a.length; i++) {
    if (a[i] !== b[i]) {
      return a[i] - b[i];
    }
  }
  return 0;
}
var QuiltIndexV1 = suiBcs.struct("QuiltIndexV1", {
  patches: suiBcs.vector(QuiltPatchV1)
});
var QuiltPatchId = suiBcs.struct("QuiltPatchId", {
  quiltId: BlobId,
  patchId: suiBcs.struct("InternalQuiltPatchId", {
    version: suiBcs.u8(),
    startIndex: suiBcs.u16(),
    endIndex: suiBcs.u16()
  })
});
var QuiltPatchBlobHeader = suiBcs.struct("QuiltPatchBlobHeader", {
  version: suiBcs.u8(),
  length: suiBcs.u32(),
  mask: suiBcs.u8()
});

// node_modules/@mysten/walrus/dist/esm/storage-node/error.js
var __typeError2 = (msg) => {
  throw TypeError(msg);
};
var __accessCheck2 = (obj, member, msg) => member.has(obj) || __typeError2("Cannot " + msg);
var __privateAdd2 = (obj, member, value) => member.has(obj) ? __typeError2("Cannot add the same private member more than once") : member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
var __privateMethod = (obj, member, method) => (__accessCheck2(obj, member, "access private method"), method);
var _StorageNodeAPIError_static;
var makeMessage_fn;
var StorageNodeError = class extends Error {
};
var _StorageNodeAPIError = class _StorageNodeAPIError2 extends StorageNodeError {
  constructor(status, error, message) {
    var _a;
    super(__privateMethod(_a = _StorageNodeAPIError2, _StorageNodeAPIError_static, makeMessage_fn).call(_a, status, error, message));
    this.status = status;
    this.error = error;
  }
  static generate(status, errorResponse, message) {
    if (!status) {
      return new ConnectionError({ message });
    }
    if (status === 400) {
      return BadRequestError.generate(status, errorResponse, message);
    }
    if (status === 401) {
      return new AuthenticationError(status, errorResponse, message);
    }
    if (status === 403) {
      return new PermissionDeniedError(status, errorResponse, message);
    }
    if (status === 404) {
      return new NotFoundError(status, errorResponse, message);
    }
    if (status === 409) {
      return new ConflictError(status, errorResponse, message);
    }
    if (status === 422) {
      return new UnprocessableEntityError(status, errorResponse, message);
    }
    if (status === 429) {
      return new RateLimitError(status, errorResponse, message);
    }
    if (status === 451) {
      return new LegallyUnavailableError(status, errorResponse, message);
    }
    if (status >= 500) {
      return new InternalServerError(status, errorResponse, message);
    }
    return new _StorageNodeAPIError2(status, errorResponse, message);
  }
};
_StorageNodeAPIError_static = /* @__PURE__ */ new WeakSet();
makeMessage_fn = function(status, error, message) {
  function hasErrorMessage(error2) {
    return typeof error2?.error?.message === "string";
  }
  const inferredMessage = hasErrorMessage(error) ? error.error.message : message;
  const finalMessage = inferredMessage ? inferredMessage : JSON.stringify(error);
  if (status && finalMessage) {
    return `${status} ${finalMessage}`;
  } else if (finalMessage) {
    return finalMessage;
  } else if (status) {
    return `${status} status code (no body)`;
  }
  return "(no status code or body)";
};
__privateAdd2(_StorageNodeAPIError, _StorageNodeAPIError_static);
var StorageNodeAPIError = _StorageNodeAPIError;
var UserAbortError = class extends StorageNodeAPIError {
  constructor({ message } = {}) {
    super(void 0, void 0, message || "Request was aborted.");
  }
};
var ConnectionError = class extends StorageNodeAPIError {
  constructor({ message }) {
    super(void 0, void 0, message || "Connection error.");
  }
};
var ConnectionTimeoutError = class extends StorageNodeAPIError {
  constructor({ message } = {}) {
    super(void 0, void 0, message ?? "Request timed out.");
  }
};
var BadRequestError = class _BadRequestError extends StorageNodeAPIError {
  static generate(status, errorResponse, message) {
    if (errorResponse && typeof errorResponse === "object" && "error" in errorResponse) {
      const error = errorResponse.error;
      if (error.details?.[0]?.reason === "NOT_REGISTERED") {
        return new BlobNotRegisteredError(errorResponse, message);
      }
    }
    return new _BadRequestError(status, errorResponse, message);
  }
};
var BlobNotRegisteredError = class extends StorageNodeAPIError {
  constructor(error, message) {
    super(400, error, message);
  }
};
var AuthenticationError = class extends StorageNodeAPIError {
};
var PermissionDeniedError = class extends StorageNodeAPIError {
};
var NotFoundError = class extends StorageNodeAPIError {
};
var ConflictError = class extends StorageNodeAPIError {
};
var UnprocessableEntityError = class extends StorageNodeAPIError {
};
var RateLimitError = class extends StorageNodeAPIError {
};
var LegallyUnavailableError = class extends StorageNodeAPIError {
};
var InternalServerError = class extends StorageNodeAPIError {
};

// node_modules/@mysten/walrus/dist/esm/storage-node/utils.js
function mergeHeaders(...headers) {
  const mergedHeaders = new Headers();
  for (const header of headers) {
    if (!header || typeof header !== "object") {
      continue;
    }
    for (const [key, value] of Object.entries(header)) {
      if (value === null) {
        mergedHeaders.delete(key);
      } else if (Array.isArray(value)) {
        for (const v of value) {
          mergedHeaders.append(key, v);
        }
      } else if (value !== void 0) {
        mergedHeaders.set(key, value);
      }
    }
  }
  return mergedHeaders;
}

// node_modules/@mysten/walrus/dist/esm/storage-node/client.js
var __typeError3 = (msg) => {
  throw TypeError(msg);
};
var __accessCheck3 = (obj, member, msg) => member.has(obj) || __typeError3("Cannot " + msg);
var __privateGet2 = (obj, member, getter) => (__accessCheck3(obj, member, "read from private field"), getter ? getter.call(obj) : member.get(obj));
var __privateAdd3 = (obj, member, value) => member.has(obj) ? __typeError3("Cannot add the same private member more than once") : member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
var __privateSet2 = (obj, member, value, setter) => (__accessCheck3(obj, member, "write to private field"), setter ? setter.call(obj, value) : member.set(obj, value), value);
var __privateMethod2 = (obj, member, method) => (__accessCheck3(obj, member, "access private method"), method);
var _fetch;
var _timeout;
var _onError;
var _StorageNodeClient_instances;
var request_fn;
var StorageNodeClient = class {
  constructor({ fetch: overriddenFetch, timeout, onError } = {}) {
    __privateAdd3(this, _StorageNodeClient_instances);
    __privateAdd3(this, _fetch);
    __privateAdd3(this, _timeout);
    __privateAdd3(this, _onError);
    __privateSet2(this, _fetch, overriddenFetch ?? globalThis.fetch);
    __privateSet2(this, _timeout, timeout ?? 3e4);
    __privateSet2(this, _onError, onError);
  }
  /**
   * Gets the metadata associated with a Walrus blob.
   */
  async getBlobMetadata({ blobId }, options) {
    const response = await __privateMethod2(this, _StorageNodeClient_instances, request_fn).call(this, `/v1/blobs/${blobId}/metadata`, {
      ...options,
      headers: mergeHeaders({ Accept: "application/octet-stream" }, options.headers)
    });
    const bcsBytes = await response.arrayBuffer();
    return BlobMetadataWithId.parse(new Uint8Array(bcsBytes));
  }
  /**
   * Gets the status associated with a Walrus blob.
   */
  async getBlobStatus({ blobId }, options) {
    const response = await __privateMethod2(this, _StorageNodeClient_instances, request_fn).call(this, `/v1/blobs/${blobId}/status`, options);
    const json = await response.json();
    const blobStatus = json.success.data;
    if (blobStatus === "nonexistent") {
      return { type: "nonexistent" };
    }
    if ("invalid" in blobStatus) {
      return {
        type: "invalid",
        ...blobStatus.invalid
      };
    }
    if ("permanent" in blobStatus) {
      return {
        type: "permanent",
        ...blobStatus.permanent
      };
    }
    if ("deletable" in blobStatus) {
      return {
        type: "deletable",
        ...blobStatus.deletable
      };
    }
    throw new StorageNodeError(`Unknown blob status received: ${blobStatus}`);
  }
  /**
   * Stores the metadata associated with a registered Walrus blob at this storage
   * node. This is a pre-requisite for storing the encoded slivers of the blob. The
   * ID of the blob must first be registered on Sui, after which storing the metadata
   * becomes possible.
   *
   * This endpoint may return an error if the node has not yet received the
   * registration event from the chain.
   */
  async storeBlobMetadata({ blobId, metadata }, options) {
    const isBcsInput = typeof metadata === "object" && "V1" in metadata;
    const body = isBcsInput ? BlobMetadata.serialize(metadata).toBytes() : metadata;
    const response = await __privateMethod2(this, _StorageNodeClient_instances, request_fn).call(this, `/v1/blobs/${blobId}/metadata`, {
      ...options,
      method: "PUT",
      body,
      headers: mergeHeaders({ "Content-Type": "application/octet-stream" }, options.headers)
    });
    const json = await response.json();
    return json;
  }
  /**
   * Gets the primary or secondary sliver identified by the specified blob ID and
   * index. The index should represent a sliver that is assigned to be stored at one
   * of the shards managed by this storage node during this epoch.
   */
  async getSliver({ blobId, sliverPairIndex, sliverType }, options) {
    const response = await __privateMethod2(this, _StorageNodeClient_instances, request_fn).call(this, `/v1/blobs/${blobId}/slivers/${sliverPairIndex}/${sliverType}`, {
      ...options,
      headers: mergeHeaders({ Accept: "application/octet-stream" }, options.headers)
    });
    const bcsBytes = await response.arrayBuffer();
    return SliverData.parse(new Uint8Array(bcsBytes));
  }
  /**
   * Stores a primary or secondary blob sliver at the storage node.
   */
  async storeSliver({ blobId, sliverPairIndex, sliverType, sliver }, options) {
    const isBcsInput = typeof sliver === "object" && "symbols" in sliver;
    const body = isBcsInput ? SliverData.serialize(sliver).toBytes() : sliver;
    const response = await __privateMethod2(this, _StorageNodeClient_instances, request_fn).call(this, `/v1/blobs/${blobId}/slivers/${sliverPairIndex}/${sliverType}`, {
      ...options,
      method: "PUT",
      body,
      headers: mergeHeaders({ "Content-Type": "application/octet-stream" }, options.headers)
    });
    const json = await response.json();
    return json;
  }
  /**
   * Gets a signed storage confirmation from this storage node, indicating that all shards
   * assigned to this storage node for the current epoch have stored their respective slivers.
   */
  async getDeletableBlobConfirmation({ blobId, objectId }, options) {
    const response = await __privateMethod2(this, _StorageNodeClient_instances, request_fn).call(this, `/v1/blobs/${blobId}/confirmation/deletable/${objectId}`, options);
    const json = await response.json();
    return json;
  }
  /**
   * Gets a signed storage confirmation from this storage node, indicating that all shards
   * assigned to this storage node for the current epoch have stored their respective slivers.
   */
  async getPermanentBlobConfirmation({ blobId }, options) {
    const response = await __privateMethod2(this, _StorageNodeClient_instances, request_fn).call(this, `/v1/blobs/${blobId}/confirmation/permanent`, options);
    const json = await response.json();
    return json;
  }
};
_fetch = /* @__PURE__ */ new WeakMap();
_timeout = /* @__PURE__ */ new WeakMap();
_onError = /* @__PURE__ */ new WeakMap();
_StorageNodeClient_instances = /* @__PURE__ */ new WeakSet();
request_fn = async function(path, options) {
  var _a, _b, _c;
  const { nodeUrl, signal, timeout, ...init } = options;
  if (signal?.aborted) {
    throw new UserAbortError();
  }
  const timeoutSignal = AbortSignal.timeout(timeout ?? __privateGet2(this, _timeout));
  let response;
  try {
    response = await (0, __privateGet2(this, _fetch))(`${nodeUrl}${path}`, {
      ...init,
      signal: signal ? AbortSignal.any([timeoutSignal, signal]) : timeoutSignal
    });
  } catch (error) {
    if (signal?.aborted) {
      throw new UserAbortError();
    }
    if (error instanceof Error && error.name === "AbortError") {
      const error2 = new ConnectionTimeoutError();
      (_a = __privateGet2(this, _onError)) == null ? void 0 : _a.call(this, error2);
      throw error2;
    }
    (_b = __privateGet2(this, _onError)) == null ? void 0 : _b.call(this, error);
    throw error;
  }
  if (!response.ok) {
    const errorText = await response.text().catch((reason) => reason);
    const errorJSON = safeParseJSON(errorText);
    const errorMessage = errorJSON ? void 0 : errorText;
    const error = StorageNodeAPIError.generate(response.status, errorJSON, errorMessage);
    (_c = __privateGet2(this, _onError)) == null ? void 0 : _c.call(this, error);
    throw error;
  }
  return response;
};
function safeParseJSON(value) {
  try {
    return JSON.parse(value);
  } catch {
    return void 0;
  }
}

// node_modules/@mysten/walrus/dist/esm/utils/index.js
var DIGEST_LEN = 32;
var BLOB_ID_LEN = 32;
var REQUIRED_ALIGNMENT_BY_ENCODING_TYPE = {
  RS2: 2,
  RedStuff: 2
};
var MAX_SYMBOL_SIZE_BY_ENCODING_TYPE = {
  RS2: 2 ** 16 - 1,
  RedStuff: 2 ** 16 - 1
};
function encodedBlobLength(unencodedLength, nShards, encodingType = "RS2") {
  const sliverSize = encodedSliverSize(unencodedLength, nShards, encodingType);
  const metadata = nShards * DIGEST_LEN * 2 + BLOB_ID_LEN;
  return nShards * metadata + sliverSize;
}
function encodedSliverSize(unencodedLength, nShards, encodingType = "RS2") {
  const { primarySymbols, secondarySymbols } = getSourceSymbols(nShards, encodingType);
  let symbolSize = Math.floor((Math.max(unencodedLength, 1) - 1) / (primarySymbols * secondarySymbols)) + 1;
  if (encodingType === "RS2" && symbolSize % 2 === 1) {
    symbolSize = symbolSize + 1;
  }
  const singleShardSize = (primarySymbols + secondarySymbols) * symbolSize;
  return singleShardSize * nShards;
}
function getSourceSymbols(nShards, encodingType = "RS2") {
  const safetyLimit = decodingSafetyLimit(nShards, encodingType);
  const maxFaulty = getMaxFaultyNodes(nShards);
  const minCorrect = nShards - maxFaulty;
  return {
    primarySymbols: minCorrect - maxFaulty - safetyLimit,
    secondarySymbols: minCorrect - safetyLimit
  };
}
function isQuorum(size, nShards) {
  const maxFaulty = getMaxFaultyNodes(nShards);
  return size > 2 * maxFaulty;
}
function isAboveValidity(size, nShards) {
  const maxFaulty = getMaxFaultyNodes(nShards);
  return size > maxFaulty;
}
function getMaxFaultyNodes(nShards) {
  return Math.floor((nShards - 1) / 3);
}
function decodingSafetyLimit(nShards, encodingType) {
  switch (encodingType) {
    case "RedStuff":
      return Math.min(5, Math.floor(getMaxFaultyNodes(nShards) / 5));
    case "RS2":
      return 0;
    default:
      throw new Error(`Encountered unknown encoding type of ${encodingType}`);
  }
}
var BYTES_PER_UNIT_SIZE = 1024 * 1024;
function storageUnitsFromSize(size) {
  return Math.ceil(size / BYTES_PER_UNIT_SIZE);
}
function rotationOffset(bytes, modulus) {
  return bytes.reduce((acc, byte) => (acc * 256 + byte) % modulus, 0);
}
function toShardIndex(sliverPairIndex, blobId, numShards) {
  const offset = rotationOffset(BlobId.serialize(blobId).toBytes(), numShards);
  return (sliverPairIndex + offset) % numShards;
}
function sliverPairIndexFromSecondarySliverIndex(sliverIndex, numShards) {
  return numShards - sliverIndex - 1;
}
function toPairIndex(shardIndex, blobId, numShards) {
  const offset = rotationOffset(BlobId.serialize(blobId).toBytes(), numShards);
  return (numShards + shardIndex - offset) % numShards;
}
function signersToBitmap(signers, committeeSize) {
  const bitmapSize = Math.ceil(committeeSize / 8);
  const bitmap = new Uint8Array(bitmapSize);
  for (const signer of signers) {
    const byteIndex = Math.floor(signer / 8);
    const bitIndex = signer % 8;
    bitmap[byteIndex] |= 1 << bitIndex;
  }
  return bitmap;
}
function getShardIndicesByNodeId(committee) {
  const shardIndicesByNodeId = /* @__PURE__ */ new Map();
  for (const node of committee[0].contents) {
    if (!shardIndicesByNodeId.has(node.key)) {
      shardIndicesByNodeId.set(node.key, []);
    }
    shardIndicesByNodeId.get(node.key).push(...node.value);
  }
  return shardIndicesByNodeId;
}
function toTypeString(type) {
  if (typeof type === "string") {
    switch (type) {
      case "Address":
        return "address";
      case "Bool":
        return "bool";
      case "U8":
        return "u8";
      case "U16":
        return "u16";
      case "U32":
        return "u32";
      case "U64":
        return "u64";
      case "U128":
        return "u128";
      case "U256":
        return "u256";
      default:
        throw new Error(`Unexpected type ${type}`);
    }
  }
  if ("Vector" in type) {
    return `vector<${toTypeString(type.Vector)}>`;
  }
  if ("Struct" in type) {
    if (type.Struct.typeArguments.length > 0) {
      return `${type.Struct.address}::${type.Struct.module}::${type.Struct.name}<${type.Struct.typeArguments.map(toTypeString).join(",")}>`;
    } else {
      return `${type.Struct.address}::${type.Struct.module}::${type.Struct.name}`;
    }
  }
  if ("TypeParameter" in type) {
    throw new Error(`Type parameters can't be converted to type strings`);
  }
  if ("Reference" in type) {
    return toTypeString(type.Reference);
  }
  if ("MutableReference" in type) {
    return toTypeString(type.MutableReference);
  }
  throw new Error(`Unexpected type ${JSON.stringify(type)}`);
}
function urlSafeBase64(bytes) {
  return toBase64(bytes).replace(/=*$/, "").replaceAll("+", "-").replaceAll("/", "_");
}
function fromUrlSafeBase64(base64) {
  return fromBase64(base64.replaceAll("-", "+").replaceAll("_", "/"));
}
function getSizes(blobSize, numShards) {
  const encodedBlobSize = encodedSliverSize(blobSize, numShards);
  const { primarySymbols, secondarySymbols } = getSourceSymbols(numShards);
  const totalSymbols = (primarySymbols + secondarySymbols) * numShards;
  if (encodedBlobSize % totalSymbols !== 0) {
    throw new Error("encoded blob size should be divisible by total symbols");
  }
  const symbolSize = encodedBlobSize / totalSymbols;
  if (encodedBlobSize % totalSymbols !== 0) {
    throw new Error("blob length should be divisible by total symbols");
  }
  const rowSize = symbolSize * secondarySymbols;
  const columnSize = symbolSize * primarySymbols;
  return {
    symbolSize,
    rowSize,
    columnSize,
    blobSize
  };
}

// node_modules/@mysten/walrus/dist/esm/utils/object-loader.js
var import_dataloader = __toESM(require_dataloader(), 1);
var __typeError4 = (msg) => {
  throw TypeError(msg);
};
var __accessCheck4 = (obj, member, msg) => member.has(obj) || __typeError4("Cannot " + msg);
var __privateGet3 = (obj, member, getter) => (__accessCheck4(obj, member, "read from private field"), getter ? getter.call(obj) : member.get(obj));
var __privateAdd4 = (obj, member, value) => member.has(obj) ? __typeError4("Cannot add the same private member more than once") : member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
var _dynamicFieldCache;
var SuiObjectDataLoader = class extends import_dataloader.default {
  constructor(suiClient) {
    super(async (ids) => {
      const { objects } = await suiClient.core.getObjects({
        objectIds: ids
      });
      return objects;
    });
    __privateAdd4(this, _dynamicFieldCache, /* @__PURE__ */ new Map());
  }
  async load(id, schema) {
    const data = await super.load(id);
    if (schema) {
      return schema.parse(await data.content);
    }
    return data;
  }
  async loadMany(ids, schema) {
    const data = await super.loadMany(ids);
    if (!schema) {
      return data;
    }
    return Promise.all(
      data.map(async (d) => {
        if (d instanceof Error) {
          return d;
        }
        return schema.parse(await d.content);
      })
    );
  }
  async loadManyOrThrow(ids, schema) {
    const data = await this.loadMany(ids, schema);
    for (const d of data) {
      if (d instanceof Error) {
        throw d;
      }
    }
    return data;
  }
  clearAll() {
    __privateGet3(this, _dynamicFieldCache).clear();
    return super.clearAll();
  }
  clear(key) {
    __privateGet3(this, _dynamicFieldCache).delete(key);
    return super.clear(key);
  }
  async loadFieldObject(parent, name2, type) {
    const schema = pureBcsSchemaFromTypeName(name2.type);
    const id = deriveDynamicFieldID(parent, "u64", schema.serialize(name2.value).toBytes());
    return (await this.load(id, Field(schema, type))).value;
  }
};
_dynamicFieldCache = /* @__PURE__ */ new WeakMap();

// node_modules/@mysten/walrus/dist/esm/utils/randomness.js
function weightedShuffle(arr) {
  return arr.map(({ value, weight }) => ({
    value,
    weight: Math.pow(Math.random(), 1 / weight)
  })).sort((a, b) => b.weight - a.weight).map((item) => item.value);
}
function shuffle(arr) {
  const result = [...arr];
  for (let i = result.length - 1; i > 0; i -= 1) {
    const j = Math.floor(Math.random() * (i + 1));
    [result[i], result[j]] = [result[j], result[i]];
  }
  return result;
}

// node_modules/@mysten/walrus-wasm/web/walrus_wasm.js
var wasm;
var WASM_VECTOR_LEN = 0;
var cachedUint8ArrayMemory0 = null;
function getUint8ArrayMemory0() {
  if (cachedUint8ArrayMemory0 === null || cachedUint8ArrayMemory0.byteLength === 0) {
    cachedUint8ArrayMemory0 = new Uint8Array(wasm.memory.buffer);
  }
  return cachedUint8ArrayMemory0;
}
var cachedTextEncoder = typeof TextEncoder !== "undefined" ? new TextEncoder("utf-8") : { encode: () => {
  throw Error("TextEncoder not available");
} };
var encodeString = typeof cachedTextEncoder.encodeInto === "function" ? function(arg, view) {
  return cachedTextEncoder.encodeInto(arg, view);
} : function(arg, view) {
  const buf = cachedTextEncoder.encode(arg);
  view.set(buf);
  return {
    read: arg.length,
    written: buf.length
  };
};
function passStringToWasm0(arg, malloc, realloc) {
  if (realloc === void 0) {
    const buf = cachedTextEncoder.encode(arg);
    const ptr2 = malloc(buf.length, 1) >>> 0;
    getUint8ArrayMemory0().subarray(ptr2, ptr2 + buf.length).set(buf);
    WASM_VECTOR_LEN = buf.length;
    return ptr2;
  }
  let len = arg.length;
  let ptr = malloc(len, 1) >>> 0;
  const mem = getUint8ArrayMemory0();
  let offset = 0;
  for (; offset < len; offset++) {
    const code = arg.charCodeAt(offset);
    if (code > 127) break;
    mem[ptr + offset] = code;
  }
  if (offset !== len) {
    if (offset !== 0) {
      arg = arg.slice(offset);
    }
    ptr = realloc(ptr, len, len = offset + arg.length * 3, 1) >>> 0;
    const view = getUint8ArrayMemory0().subarray(ptr + offset, ptr + len);
    const ret = encodeString(arg, view);
    offset += ret.written;
    ptr = realloc(ptr, len, offset, 1) >>> 0;
  }
  WASM_VECTOR_LEN = offset;
  return ptr;
}
var cachedDataViewMemory0 = null;
function getDataViewMemory0() {
  if (cachedDataViewMemory0 === null || cachedDataViewMemory0.buffer.detached === true || cachedDataViewMemory0.buffer.detached === void 0 && cachedDataViewMemory0.buffer !== wasm.memory.buffer) {
    cachedDataViewMemory0 = new DataView(wasm.memory.buffer);
  }
  return cachedDataViewMemory0;
}
function addToExternrefTable0(obj) {
  const idx = wasm.__externref_table_alloc();
  wasm.__wbindgen_export_4.set(idx, obj);
  return idx;
}
function handleError(f, args) {
  try {
    return f.apply(this, args);
  } catch (e) {
    const idx = addToExternrefTable0(e);
    wasm.__wbindgen_exn_store(idx);
  }
}
function debugString(val) {
  const type = typeof val;
  if (type == "number" || type == "boolean" || val == null) {
    return `${val}`;
  }
  if (type == "string") {
    return `"${val}"`;
  }
  if (type == "symbol") {
    const description = val.description;
    if (description == null) {
      return "Symbol";
    } else {
      return `Symbol(${description})`;
    }
  }
  if (type == "function") {
    const name2 = val.name;
    if (typeof name2 == "string" && name2.length > 0) {
      return `Function(${name2})`;
    } else {
      return "Function";
    }
  }
  if (Array.isArray(val)) {
    const length = val.length;
    let debug = "[";
    if (length > 0) {
      debug += debugString(val[0]);
    }
    for (let i = 1; i < length; i++) {
      debug += ", " + debugString(val[i]);
    }
    debug += "]";
    return debug;
  }
  const builtInMatches = /\[object ([^\]]+)\]/.exec(toString.call(val));
  let className;
  if (builtInMatches && builtInMatches.length > 1) {
    className = builtInMatches[1];
  } else {
    return toString.call(val);
  }
  if (className == "Object") {
    try {
      return "Object(" + JSON.stringify(val) + ")";
    } catch (_) {
      return "Object";
    }
  }
  if (val instanceof Error) {
    return `${val.name}: ${val.message}
${val.stack}`;
  }
  return className;
}
var cachedTextDecoder = typeof TextDecoder !== "undefined" ? new TextDecoder("utf-8", { ignoreBOM: true, fatal: true }) : { decode: () => {
  throw Error("TextDecoder not available");
} };
if (typeof TextDecoder !== "undefined") {
  cachedTextDecoder.decode();
}
function getStringFromWasm0(ptr, len) {
  ptr = ptr >>> 0;
  return cachedTextDecoder.decode(getUint8ArrayMemory0().subarray(ptr, ptr + len));
}
function isLikeNone(x) {
  return x === void 0 || x === null;
}
function passArray8ToWasm0(arg, malloc) {
  const ptr = malloc(arg.length * 1, 1) >>> 0;
  getUint8ArrayMemory0().set(arg, ptr / 1);
  WASM_VECTOR_LEN = arg.length;
  return ptr;
}
function takeFromExternrefTable0(idx) {
  const value = wasm.__wbindgen_export_4.get(idx);
  wasm.__externref_table_dealloc(idx);
  return value;
}
function bls12381_min_pk_verify(signature, public_key, msg) {
  const ptr0 = passArray8ToWasm0(signature, wasm.__wbindgen_malloc);
  const len0 = WASM_VECTOR_LEN;
  const ptr1 = passArray8ToWasm0(public_key, wasm.__wbindgen_malloc);
  const len1 = WASM_VECTOR_LEN;
  const ptr2 = passArray8ToWasm0(msg, wasm.__wbindgen_malloc);
  const len2 = WASM_VECTOR_LEN;
  const ret = wasm.bls12381_min_pk_verify(ptr0, len0, ptr1, len1, ptr2, len2);
  if (ret[2]) {
    throw takeFromExternrefTable0(ret[1]);
  }
  return ret[0] !== 0;
}
function getArrayU8FromWasm0(ptr, len) {
  ptr = ptr >>> 0;
  return getUint8ArrayMemory0().subarray(ptr / 1, ptr / 1 + len);
}
function bls12381_min_pk_aggregate(signatures) {
  const ret = wasm.bls12381_min_pk_aggregate(signatures);
  if (ret[3]) {
    throw takeFromExternrefTable0(ret[2]);
  }
  var v1 = getArrayU8FromWasm0(ret[0], ret[1]).slice();
  wasm.__wbindgen_free(ret[0], ret[1] * 1, 1);
  return v1;
}
var BlobEncoderFinalization = typeof FinalizationRegistry === "undefined" ? { register: () => {
}, unregister: () => {
} } : new FinalizationRegistry((ptr) => wasm.__wbg_blobencoder_free(ptr >>> 0, 1));
var BlobEncoder = class {
  __destroy_into_raw() {
    const ptr = this.__wbg_ptr;
    this.__wbg_ptr = 0;
    BlobEncoderFinalization.unregister(this);
    return ptr;
  }
  free() {
    const ptr = this.__destroy_into_raw();
    wasm.__wbg_blobencoder_free(ptr, 0);
  }
  /**
   * @param {number} n_shards
   */
  constructor(n_shards) {
    const ret = wasm.blobencoder_new(n_shards);
    if (ret[2]) {
      throw takeFromExternrefTable0(ret[1]);
    }
    this.__wbg_ptr = ret[0] >>> 0;
    BlobEncoderFinalization.register(this, this.__wbg_ptr, this);
    return this;
  }
  /**
   * WASM wrapper for [walrus_core::encoding::blob_encoding::BlobEncoder::encode_with_metadata].
   * Returns a tuple with a vector of [walrus_core::encoding::slivers::SliverPair]´s and a [walrus_core::metadata::VerifiedBlobMetadataWithId]`.
   * @param {Uint8Array} data
   * @returns {any}
   */
  encode_with_metadata(data) {
    const ptr0 = passArray8ToWasm0(data, wasm.__wbindgen_malloc);
    const len0 = WASM_VECTOR_LEN;
    const ret = wasm.blobencoder_encode_with_metadata(this.__wbg_ptr, ptr0, len0);
    if (ret[2]) {
      throw takeFromExternrefTable0(ret[1]);
    }
    return takeFromExternrefTable0(ret[0]);
  }
  /**
   * WASM wrapper for [walrus_core::encoding::blob_encoding::BlobEncoder::compute_metadata].
   * Returns [walrus_core::metadata::VerifiedBlobMetadataWithId].
   * @param {Uint8Array} data
   * @returns {any}
   */
  compute_metadata(data) {
    const ptr0 = passArray8ToWasm0(data, wasm.__wbindgen_malloc);
    const len0 = WASM_VECTOR_LEN;
    const ret = wasm.blobencoder_compute_metadata(this.__wbg_ptr, ptr0, len0);
    if (ret[2]) {
      throw takeFromExternrefTable0(ret[1]);
    }
    return takeFromExternrefTable0(ret[0]);
  }
  /**
   * WASM wrapper for [walrus_core::encoding::blob_encoding::BlobEncoder::decode].
   * The input `slivers` is expected to be a `Vec<SliverData<Primary>>`.
   * Returns `Vec<u8>`.
   * @param {any} blob_id
   * @param {bigint} blob_size
   * @param {any} slivers
   * @returns {any}
   */
  decode(blob_id, blob_size, slivers) {
    const ret = wasm.blobencoder_decode(this.__wbg_ptr, blob_id, blob_size, slivers);
    if (ret[2]) {
      throw takeFromExternrefTable0(ret[1]);
    }
    return takeFromExternrefTable0(ret[0]);
  }
};
async function __wbg_load(module, imports) {
  if (typeof Response === "function" && module instanceof Response) {
    if (typeof WebAssembly.instantiateStreaming === "function") {
      try {
        return await WebAssembly.instantiateStreaming(module, imports);
      } catch (e) {
        if (module.headers.get("Content-Type") != "application/wasm") {
          console.warn("`WebAssembly.instantiateStreaming` failed because your server does not serve Wasm with `application/wasm` MIME type. Falling back to `WebAssembly.instantiate` which is slower. Original error:\n", e);
        } else {
          throw e;
        }
      }
    }
    const bytes = await module.arrayBuffer();
    return await WebAssembly.instantiate(bytes, imports);
  } else {
    const instance = await WebAssembly.instantiate(module, imports);
    if (instance instanceof WebAssembly.Instance) {
      return { instance, module };
    } else {
      return instance;
    }
  }
}
function __wbg_get_imports() {
  const imports = {};
  imports.wbg = {};
  imports.wbg.__wbg_String_fed4d24b68977888 = function(arg0, arg1) {
    const ret = String(arg1);
    const ptr1 = passStringToWasm0(ret, wasm.__wbindgen_malloc, wasm.__wbindgen_realloc);
    const len1 = WASM_VECTOR_LEN;
    getDataViewMemory0().setInt32(arg0 + 4 * 1, len1, true);
    getDataViewMemory0().setInt32(arg0 + 4 * 0, ptr1, true);
  };
  imports.wbg.__wbg_buffer_609cc3eee51ed158 = function(arg0) {
    const ret = arg0.buffer;
    return ret;
  };
  imports.wbg.__wbg_call_672a4d21634d4a24 = function() {
    return handleError(function(arg0, arg1) {
      const ret = arg0.call(arg1);
      return ret;
    }, arguments);
  };
  imports.wbg.__wbg_done_769e5ede4b31c67b = function(arg0) {
    const ret = arg0.done;
    return ret;
  };
  imports.wbg.__wbg_get_67b2ba62fc30de12 = function() {
    return handleError(function(arg0, arg1) {
      const ret = Reflect.get(arg0, arg1);
      return ret;
    }, arguments);
  };
  imports.wbg.__wbg_get_b9b93047fe3cf45b = function(arg0, arg1) {
    const ret = arg0[arg1 >>> 0];
    return ret;
  };
  imports.wbg.__wbg_getwithrefkey_bb8f74a92cb2e784 = function(arg0, arg1) {
    const ret = arg0[arg1];
    return ret;
  };
  imports.wbg.__wbg_instanceof_ArrayBuffer_e14585432e3737fc = function(arg0) {
    let result;
    try {
      result = arg0 instanceof ArrayBuffer;
    } catch (_) {
      result = false;
    }
    const ret = result;
    return ret;
  };
  imports.wbg.__wbg_instanceof_Uint8Array_17156bcf118086a9 = function(arg0) {
    let result;
    try {
      result = arg0 instanceof Uint8Array;
    } catch (_) {
      result = false;
    }
    const ret = result;
    return ret;
  };
  imports.wbg.__wbg_isArray_a1eab7e0d067391b = function(arg0) {
    const ret = Array.isArray(arg0);
    return ret;
  };
  imports.wbg.__wbg_isSafeInteger_343e2beeeece1bb0 = function(arg0) {
    const ret = Number.isSafeInteger(arg0);
    return ret;
  };
  imports.wbg.__wbg_iterator_9a24c88df860dc65 = function() {
    const ret = Symbol.iterator;
    return ret;
  };
  imports.wbg.__wbg_length_a446193dc22c12f8 = function(arg0) {
    const ret = arg0.length;
    return ret;
  };
  imports.wbg.__wbg_length_e2d2a49132c1b256 = function(arg0) {
    const ret = arg0.length;
    return ret;
  };
  imports.wbg.__wbg_new_405e22f390576ce2 = function() {
    const ret = new Object();
    return ret;
  };
  imports.wbg.__wbg_new_78feb108b6472713 = function() {
    const ret = new Array();
    return ret;
  };
  imports.wbg.__wbg_new_a12002a7f91c75be = function(arg0) {
    const ret = new Uint8Array(arg0);
    return ret;
  };
  imports.wbg.__wbg_next_25feadfc0913fea9 = function(arg0) {
    const ret = arg0.next;
    return ret;
  };
  imports.wbg.__wbg_next_6574e1a8a62d1055 = function() {
    return handleError(function(arg0) {
      const ret = arg0.next();
      return ret;
    }, arguments);
  };
  imports.wbg.__wbg_set_37837023f3d740e8 = function(arg0, arg1, arg2) {
    arg0[arg1 >>> 0] = arg2;
  };
  imports.wbg.__wbg_set_3fda3bac07393de4 = function(arg0, arg1, arg2) {
    arg0[arg1] = arg2;
  };
  imports.wbg.__wbg_set_65595bdd868b3009 = function(arg0, arg1, arg2) {
    arg0.set(arg1, arg2 >>> 0);
  };
  imports.wbg.__wbg_value_cd1ffa7b1ab794f1 = function(arg0) {
    const ret = arg0.value;
    return ret;
  };
  imports.wbg.__wbindgen_bigint_from_u64 = function(arg0) {
    const ret = BigInt.asUintN(64, arg0);
    return ret;
  };
  imports.wbg.__wbindgen_boolean_get = function(arg0) {
    const v = arg0;
    const ret = typeof v === "boolean" ? v ? 1 : 0 : 2;
    return ret;
  };
  imports.wbg.__wbindgen_debug_string = function(arg0, arg1) {
    const ret = debugString(arg1);
    const ptr1 = passStringToWasm0(ret, wasm.__wbindgen_malloc, wasm.__wbindgen_realloc);
    const len1 = WASM_VECTOR_LEN;
    getDataViewMemory0().setInt32(arg0 + 4 * 1, len1, true);
    getDataViewMemory0().setInt32(arg0 + 4 * 0, ptr1, true);
  };
  imports.wbg.__wbindgen_error_new = function(arg0, arg1) {
    const ret = new Error(getStringFromWasm0(arg0, arg1));
    return ret;
  };
  imports.wbg.__wbindgen_in = function(arg0, arg1) {
    const ret = arg0 in arg1;
    return ret;
  };
  imports.wbg.__wbindgen_init_externref_table = function() {
    const table = wasm.__wbindgen_export_4;
    const offset = table.grow(4);
    table.set(0, void 0);
    table.set(offset + 0, void 0);
    table.set(offset + 1, null);
    table.set(offset + 2, true);
    table.set(offset + 3, false);
    ;
  };
  imports.wbg.__wbindgen_is_function = function(arg0) {
    const ret = typeof arg0 === "function";
    return ret;
  };
  imports.wbg.__wbindgen_is_object = function(arg0) {
    const val = arg0;
    const ret = typeof val === "object" && val !== null;
    return ret;
  };
  imports.wbg.__wbindgen_is_undefined = function(arg0) {
    const ret = arg0 === void 0;
    return ret;
  };
  imports.wbg.__wbindgen_jsval_loose_eq = function(arg0, arg1) {
    const ret = arg0 == arg1;
    return ret;
  };
  imports.wbg.__wbindgen_memory = function() {
    const ret = wasm.memory;
    return ret;
  };
  imports.wbg.__wbindgen_number_get = function(arg0, arg1) {
    const obj = arg1;
    const ret = typeof obj === "number" ? obj : void 0;
    getDataViewMemory0().setFloat64(arg0 + 8 * 1, isLikeNone(ret) ? 0 : ret, true);
    getDataViewMemory0().setInt32(arg0 + 4 * 0, !isLikeNone(ret), true);
  };
  imports.wbg.__wbindgen_number_new = function(arg0) {
    const ret = arg0;
    return ret;
  };
  imports.wbg.__wbindgen_string_get = function(arg0, arg1) {
    const obj = arg1;
    const ret = typeof obj === "string" ? obj : void 0;
    var ptr1 = isLikeNone(ret) ? 0 : passStringToWasm0(ret, wasm.__wbindgen_malloc, wasm.__wbindgen_realloc);
    var len1 = WASM_VECTOR_LEN;
    getDataViewMemory0().setInt32(arg0 + 4 * 1, len1, true);
    getDataViewMemory0().setInt32(arg0 + 4 * 0, ptr1, true);
  };
  imports.wbg.__wbindgen_string_new = function(arg0, arg1) {
    const ret = getStringFromWasm0(arg0, arg1);
    return ret;
  };
  imports.wbg.__wbindgen_throw = function(arg0, arg1) {
    throw new Error(getStringFromWasm0(arg0, arg1));
  };
  return imports;
}
function __wbg_init_memory(imports, memory) {
}
function __wbg_finalize_init(instance, module) {
  wasm = instance.exports;
  __wbg_init.__wbindgen_wasm_module = module;
  cachedDataViewMemory0 = null;
  cachedUint8ArrayMemory0 = null;
  wasm.__wbindgen_start();
  return wasm;
}
async function __wbg_init(module_or_path) {
  if (wasm !== void 0) return wasm;
  if (typeof module_or_path !== "undefined") {
    if (Object.getPrototypeOf(module_or_path) === Object.prototype) {
      ({ module_or_path } = module_or_path);
    } else {
      console.warn("using deprecated parameters for the initialization function; pass a single object instead");
    }
  }
  if (typeof module_or_path === "undefined") {
    module_or_path = new URL("walrus_wasm_bg.wasm", import.meta.url);
  }
  const imports = __wbg_get_imports();
  if (typeof module_or_path === "string" || typeof Request === "function" && module_or_path instanceof Request || typeof URL === "function" && module_or_path instanceof URL) {
    module_or_path = fetch(module_or_path);
  }
  __wbg_init_memory(imports);
  const { instance, module } = await __wbg_load(await module_or_path, imports);
  return __wbg_finalize_init(instance, module);
}
var walrus_wasm_default = __wbg_init;

// node_modules/@mysten/walrus/dist/esm/wasm.js
async function getWasmBindings(url) {
  await walrus_wasm_default({ module_or_path: url });
  function encodeBlob(nShards, bytes, encodingType = "RS2") {
    const encoder = new BlobEncoder(nShards);
    if (encodingType !== "RS2") {
      throw new Error(`Unsupported encoding type: ${encodingType}`);
    }
    const [sliverPairs, metadata, rootHash] = encoder.encode_with_metadata(bytes);
    return {
      sliverPairs,
      blobId: blobIdFromBytes(new Uint8Array(metadata.blob_id)),
      metadata: metadata.metadata,
      rootHash: new Uint8Array(rootHash.Digest)
    };
  }
  function combineSignatures(confirmations, signerIndices) {
    const signature = bls12381_min_pk_aggregate(
      confirmations.map((confirmation) => fromBase64(confirmation.signature))
    );
    return {
      signers: signerIndices,
      serializedMessage: fromBase64(confirmations[0].serializedMessage),
      signature
    };
  }
  function decodePrimarySlivers(blobId, nShards, size, slivers, encodingType = "RS2") {
    const encoder = new BlobEncoder(nShards);
    if (encodingType !== "RS2") {
      throw new Error(`Unsupported encoding type: ${encodingType}`);
    }
    const [bytes] = encoder.decode(
      BlobId.serialize(blobId).toBytes(),
      BigInt(size),
      slivers.map((sliver) => ({
        ...sliver,
        _sliver_type: void 0
      }))
    );
    return new Uint8Array(bytes);
  }
  function getVerifySignature() {
    return (confirmation, publicKey) => bls12381_min_pk_verify(
      fromBase64(confirmation.signature),
      publicKey,
      fromBase64(confirmation.serializedMessage)
    );
  }
  function computeMetadata(nShards, bytes, encodingType = "RS2") {
    const encoder = new BlobEncoder(nShards);
    const [metadata, rootHash] = encoder.compute_metadata(bytes);
    if (encodingType !== "RS2") {
      throw new Error(`Unsupported encoding type: ${encodingType}`);
    }
    return {
      ...metadata,
      blobId: blobIdFromBytes(new Uint8Array(metadata.blob_id)),
      rootHash: new Uint8Array(rootHash.Digest)
    };
  }
  return {
    encodeBlob,
    combineSignatures,
    decodePrimarySlivers,
    getVerifySignature,
    computeMetadata
  };
}

// node_modules/@mysten/walrus/dist/esm/upload-relay/client.js
var __typeError5 = (msg) => {
  throw TypeError(msg);
};
var __accessCheck5 = (obj, member, msg) => member.has(obj) || __typeError5("Cannot " + msg);
var __privateGet4 = (obj, member, getter) => (__accessCheck5(obj, member, "read from private field"), getter ? getter.call(obj) : member.get(obj));
var __privateAdd5 = (obj, member, value) => member.has(obj) ? __typeError5("Cannot add the same private member more than once") : member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
var __privateSet3 = (obj, member, value, setter) => (__accessCheck5(obj, member, "write to private field"), setter ? setter.call(obj, value) : member.set(obj, value), value);
var __privateMethod3 = (obj, member, method) => (__accessCheck5(obj, member, "access private method"), method);
var _fetch2;
var _timeout2;
var _onError2;
var _UploadRelayClient_instances;
var request_fn2;
var UploadRelayClient = class {
  constructor({ host, fetch: overriddenFetch, timeout, onError }) {
    __privateAdd5(this, _UploadRelayClient_instances);
    __privateAdd5(this, _fetch2);
    __privateAdd5(this, _timeout2);
    __privateAdd5(this, _onError2);
    this.host = host;
    __privateSet3(this, _fetch2, overriddenFetch ?? globalThis.fetch);
    __privateSet3(this, _timeout2, timeout ?? 3e4);
    __privateSet3(this, _onError2, onError);
  }
  async tipConfig() {
    const response = await __privateMethod3(this, _UploadRelayClient_instances, request_fn2).call(this, {
      method: "GET",
      path: "/v1/tip-config"
    });
    const data = await response.json();
    if (typeof data === "string") {
      return null;
    }
    if ("const" in data.send_tip.kind) {
      return {
        address: data.send_tip.address,
        kind: {
          const: data.send_tip.kind.const
        }
      };
    }
    return {
      address: data.send_tip.address,
      kind: {
        linear: {
          base: data.send_tip.kind.linear.base,
          perEncodedKib: data.send_tip.kind.linear.encoded_size_mul_per_kib
        }
      }
    };
  }
  async writeBlob({
    blobId,
    nonce,
    txDigest,
    blob,
    deletable,
    blobObjectId,
    requiresTip,
    encodingType,
    ...options
  }) {
    const query = new URLSearchParams({
      blob_id: blobId
    });
    if (requiresTip) {
      query.set("nonce", urlSafeBase64(nonce));
      query.set("tx_id", txDigest);
    }
    if (deletable) {
      query.set("deletable_blob_object", blobObjectId);
    }
    if (encodingType) {
      query.set("encoding_type", encodingType);
    }
    const response = await __privateMethod3(this, _UploadRelayClient_instances, request_fn2).call(this, {
      method: "POST",
      path: `/v1/blob-upload-relay?${query.toString()}`,
      body: blob,
      ...options
    });
    const data = await response.json();
    return {
      blobId,
      certificate: {
        signers: data.confirmation_certificate.signers,
        serializedMessage: new Uint8Array(data.confirmation_certificate.serialized_message),
        signature: fromUrlSafeBase64(data.confirmation_certificate.signature)
      }
    };
  }
};
_fetch2 = /* @__PURE__ */ new WeakMap();
_timeout2 = /* @__PURE__ */ new WeakMap();
_onError2 = /* @__PURE__ */ new WeakMap();
_UploadRelayClient_instances = /* @__PURE__ */ new WeakSet();
request_fn2 = async function(options) {
  var _a, _b, _c;
  const { signal, timeout, ...init } = options;
  if (signal?.aborted) {
    throw new UserAbortError();
  }
  const timeoutSignal = AbortSignal.timeout(timeout ?? __privateGet4(this, _timeout2));
  let response;
  try {
    response = await (0, __privateGet4(this, _fetch2))(`${this.host}${options.path}`, {
      ...init,
      signal: signal ? AbortSignal.any([timeoutSignal, signal]) : timeoutSignal
    });
  } catch (error) {
    if (signal?.aborted) {
      throw new UserAbortError();
    }
    if (error instanceof Error && error.name === "AbortError") {
      const error2 = new ConnectionTimeoutError();
      (_a = __privateGet4(this, _onError2)) == null ? void 0 : _a.call(this, error2);
      throw error2;
    }
    (_b = __privateGet4(this, _onError2)) == null ? void 0 : _b.call(this, error);
    throw error;
  }
  if (!response.ok) {
    const errorText = await response.text().catch((reason) => reason);
    const errorJSON = safeParseJSON2(errorText);
    const errorMessage = errorJSON ? void 0 : errorText;
    const error = StorageNodeAPIError.generate(response.status, errorJSON, errorMessage);
    (_c = __privateGet4(this, _onError2)) == null ? void 0 : _c.call(this, error);
    throw error;
  }
  return response;
};
function safeParseJSON2(value) {
  try {
    return JSON.parse(value);
  } catch {
    return void 0;
  }
}

// node_modules/@mysten/walrus/dist/esm/utils/quilts.js
var QUILT_INDEX_SIZE_BYTES_LENGTH = 4;
var QUILT_VERSION_BYTES_LENGTH = 1;
var QUILT_INDEX_PREFIX_SIZE = QUILT_VERSION_BYTES_LENGTH + QUILT_INDEX_SIZE_BYTES_LENGTH;
var QUILT_PATCH_BLOB_HEADER_SIZE = 1 + 4 + 1;
var BLOB_IDENTIFIER_SIZE_BYTES_LENGTH = 2;
var TAGS_SIZE_BYTES_LENGTH = 2;
var MAX_BLOB_IDENTIFIER_BYTES_LENGTH = (1 << 8 * BLOB_IDENTIFIER_SIZE_BYTES_LENGTH) - 1;
var MAX_NUM_SLIVERS_FOR_QUILT_INDEX = 10;
var HAS_TAGS_FLAG = 1 << 0;
function computeSymbolSize(blobsSizes, nColumns, nRows, maxNumColumnsForQuiltIndex, encodingType = "RS2") {
  if (blobsSizes.length > nColumns) {
    throw new Error("Too many blobs, the number of blobs must be less than the number of columns");
  }
  if (blobsSizes.length === 0) {
    throw new Error("No blobs provided");
  }
  let minVal = Math.max(
    blobsSizes.reduce((acc, size) => acc + size, 0) / (nColumns * nRows),
    blobsSizes[0] / (nRows * maxNumColumnsForQuiltIndex),
    Math.ceil(QUILT_INDEX_PREFIX_SIZE / nRows)
  );
  let maxVal = Math.ceil(Math.max(...blobsSizes) / (nColumns / blobsSizes.length) * nRows);
  while (minVal < maxVal) {
    const mid = (minVal + maxVal) / 2;
    if (canBlobsFitIntoMatrix(blobsSizes, nColumns, mid * nRows)) {
      maxVal = mid;
    } else {
      minVal = mid + 1;
    }
  }
  const symbolSize = Math.ceil(minVal / REQUIRED_ALIGNMENT_BY_ENCODING_TYPE[encodingType]) * REQUIRED_ALIGNMENT_BY_ENCODING_TYPE[encodingType];
  if (!canBlobsFitIntoMatrix(blobsSizes, nColumns, symbolSize * nRows)) {
    throw new Error("Quilt oversize");
  }
  if (symbolSize > MAX_SYMBOL_SIZE_BY_ENCODING_TYPE[encodingType]) {
    throw new Error(
      `Quilt oversize: the resulting symbol size ${symbolSize} is larger than the maximum symbol size ${MAX_SYMBOL_SIZE_BY_ENCODING_TYPE[encodingType]}; remove some blobs`
    );
  }
  return symbolSize;
}
function canBlobsFitIntoMatrix(blobsSizes, nColumns, columnSize) {
  return blobsSizes.reduce((acc, size) => acc + Math.ceil(size / columnSize), 0) <= nColumns;
}
function parseQuiltPatchId(id) {
  return QuiltPatchId.parse(fromUrlSafeBase64(id));
}
function encodeQuiltPatchId(id) {
  return urlSafeBase64(QuiltPatchId.serialize(id).toBytes());
}
function parseWalrusId(id) {
  const bytes = fromUrlSafeBase64(id);
  if (bytes.length === 32) {
    return {
      kind: "blob",
      id
    };
  }
  return {
    kind: "quiltPatch",
    id: parseQuiltPatchId(id)
  };
}
function encodeQuilt({ blobs, numShards, encodingType }) {
  const { primarySymbols: nRows, secondarySymbols: nCols } = getSourceSymbols(
    numShards,
    encodingType
  );
  const sortedBlobs = blobs.sort((a, b) => a.identifier < b.identifier ? -1 : 1);
  const identifiers = /* @__PURE__ */ new Set();
  const index = {
    patches: []
  };
  const tags = sortedBlobs.map(
    (blob) => blob.tags && Object.keys(blob.tags).length > 0 ? QuiltPatchTags.serialize(blob.tags).toBytes() : null
  );
  for (const blob of sortedBlobs) {
    if (identifiers.has(blob.identifier)) {
      throw new Error(`Duplicate blob identifier: ${blob.identifier}`);
    }
    identifiers.add(blob.identifier);
    index.patches.push({
      startIndex: 0,
      endIndex: 0,
      identifier: blob.identifier,
      tags: blob.tags ?? {}
    });
  }
  const indexSize = QUILT_INDEX_PREFIX_SIZE + QuiltIndexV1.serialize(index).toBytes().length;
  const blobMetadata = sortedBlobs.map((blob, i) => {
    const identifierBytes = bcs.string().serialize(blob.identifier).toBytes();
    let metadataSize = QUILT_PATCH_BLOB_HEADER_SIZE + BLOB_IDENTIFIER_SIZE_BYTES_LENGTH + identifierBytes.length;
    let mask = 0;
    let offset = 0;
    if (tags[i]) {
      metadataSize += TAGS_SIZE_BYTES_LENGTH + tags[i].length;
      mask |= HAS_TAGS_FLAG << 0;
    }
    const metadata = new Uint8Array(metadataSize);
    const metadataView = new DataView(metadata.buffer);
    const header = QuiltPatchBlobHeader.serialize({
      version: 1,
      length: metadataSize - QUILT_PATCH_BLOB_HEADER_SIZE + blob.contents.length,
      mask
    }).toBytes();
    metadata.set(header, offset);
    offset += header.length;
    metadataView.setUint16(offset, identifierBytes.length, true);
    offset += BLOB_IDENTIFIER_SIZE_BYTES_LENGTH;
    metadata.set(identifierBytes, offset);
    offset += identifierBytes.length;
    if (tags[i]) {
      metadataView.setUint16(offset, tags[i].length, true);
      offset += TAGS_SIZE_BYTES_LENGTH;
      metadata.set(tags[i], offset);
      offset += tags[i].length;
    }
    return metadata;
  });
  const blobSizes = [
    indexSize,
    ...sortedBlobs.map((blob, i) => {
      if (blob.identifier.length > MAX_BLOB_IDENTIFIER_BYTES_LENGTH) {
        throw new Error(`Blob identifier too long: ${blob.identifier}`);
      }
      return blobMetadata[i].length + blob.contents.length;
    })
  ];
  const symbolSize = computeSymbolSize(
    blobSizes,
    nCols,
    nRows,
    MAX_NUM_SLIVERS_FOR_QUILT_INDEX,
    encodingType
  );
  const rowSize = symbolSize * nCols;
  const columnSize = symbolSize * nRows;
  const indexColumnsNeeded = Math.ceil(indexSize / columnSize);
  if (indexColumnsNeeded > MAX_NUM_SLIVERS_FOR_QUILT_INDEX) {
    throw new Error("Index too large");
  }
  const quilt = new Uint8Array(rowSize * nRows);
  let currentColumn = indexColumnsNeeded;
  for (let i = 0; i < sortedBlobs.length; i++) {
    const blob = sortedBlobs[i];
    index.patches[i].startIndex = currentColumn;
    currentColumn += writeBlobToQuilt(
      quilt,
      blob.contents,
      rowSize,
      columnSize,
      symbolSize,
      currentColumn,
      blobMetadata[i]
    );
    index.patches[i].endIndex = currentColumn;
  }
  const indexBytes = QuiltIndexV1.serialize(index).toBytes();
  const quiltIndex = new Uint8Array(QUILT_INDEX_PREFIX_SIZE + indexBytes.length);
  quiltIndex.set([1], 0);
  quiltIndex.set(new Uint32Array([indexBytes.length]), 1);
  quiltIndex.set(indexBytes, QUILT_INDEX_PREFIX_SIZE);
  writeBlobToQuilt(quilt, quiltIndex, rowSize, columnSize, symbolSize, 0);
  return { quilt, index };
}
function writeBlobToQuilt(quilt, blob, rowSize, columnSize, symbolSize, startColumn, prefix) {
  const nRows = columnSize / symbolSize;
  let bytesWritten = 0;
  if (rowSize % symbolSize !== 0) {
    throw new Error("Row size must be divisible by symbol size");
  }
  if (columnSize % symbolSize !== 0) {
    throw new Error("Column size must be divisible by symbol size");
  }
  if (prefix) {
    writeBytes(prefix);
  }
  writeBytes(blob);
  return Math.ceil(bytesWritten / columnSize);
  function writeBytes(bytes) {
    const offset = bytesWritten;
    const symbolsToSkip = Math.floor(offset / symbolSize);
    let remainingOffset = offset % symbolSize;
    let currentCol = startColumn + Math.floor(symbolsToSkip / nRows);
    let currentRow = symbolsToSkip % nRows;
    let index = 0;
    while (index < bytes.length) {
      const baseIndex = currentRow * rowSize + currentCol * symbolSize;
      const startIndex = baseIndex + remainingOffset;
      const len = Math.min(symbolSize - remainingOffset, bytes.length - index);
      for (let i = 0; i < len; i++) {
        quilt[startIndex + i] = bytes[index + i];
      }
      index += len;
      remainingOffset = 0;
      currentRow = (currentRow + 1) % nRows;
      if (currentRow === 0) {
        currentCol++;
      }
    }
    bytesWritten += bytes.length;
  }
}

// node_modules/@mysten/walrus/dist/esm/files/readers/quilt-file.js
var __typeError6 = (msg) => {
  throw TypeError(msg);
};
var __accessCheck6 = (obj, member, msg) => member.has(obj) || __typeError6("Cannot " + msg);
var __privateGet5 = (obj, member, getter) => (__accessCheck6(obj, member, "read from private field"), getter ? getter.call(obj) : member.get(obj));
var __privateAdd6 = (obj, member, value) => member.has(obj) ? __typeError6("Cannot add the same private member more than once") : member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
var __privateSet4 = (obj, member, value, setter) => (__accessCheck6(obj, member, "write to private field"), setter ? setter.call(obj, value) : member.set(obj, value), value);
var _quilt;
var _sliverIndex;
var _identifier;
var _tags;
var QuiltFileReader = class {
  constructor({
    quilt,
    sliverIndex,
    identifier,
    tags
  }) {
    __privateAdd6(this, _quilt);
    __privateAdd6(this, _sliverIndex);
    __privateAdd6(this, _identifier);
    __privateAdd6(this, _tags);
    __privateSet4(this, _quilt, quilt);
    __privateSet4(this, _sliverIndex, sliverIndex);
    __privateSet4(this, _identifier, identifier ?? null);
    __privateSet4(this, _tags, tags);
  }
  async getBytes() {
    const { blobContents, identifier, tags } = await __privateGet5(this, _quilt).readBlob(__privateGet5(this, _sliverIndex));
    __privateSet4(this, _identifier, identifier);
    __privateSet4(this, _tags, tags ?? {});
    return blobContents;
  }
  async getIdentifier() {
    if (__privateGet5(this, _identifier) !== null) {
      return __privateGet5(this, _identifier);
    }
    const header = await __privateGet5(this, _quilt).getBlobHeader(__privateGet5(this, _sliverIndex));
    __privateSet4(this, _identifier, header.identifier);
    return __privateGet5(this, _identifier);
  }
  async getTags() {
    if (__privateGet5(this, _tags) !== void 0) {
      return __privateGet5(this, _tags);
    }
    const header = await __privateGet5(this, _quilt).getBlobHeader(__privateGet5(this, _sliverIndex));
    __privateSet4(this, _tags, header.tags ?? {});
    return __privateGet5(this, _tags);
  }
};
_quilt = /* @__PURE__ */ new WeakMap();
_sliverIndex = /* @__PURE__ */ new WeakMap();
_identifier = /* @__PURE__ */ new WeakMap();
_tags = /* @__PURE__ */ new WeakMap();

// node_modules/@mysten/walrus/dist/esm/files/readers/quilt.js
var __typeError7 = (msg) => {
  throw TypeError(msg);
};
var __accessCheck7 = (obj, member, msg) => member.has(obj) || __typeError7("Cannot " + msg);
var __privateGet6 = (obj, member, getter) => (__accessCheck7(obj, member, "read from private field"), getter ? getter.call(obj) : member.get(obj));
var __privateAdd7 = (obj, member, value) => member.has(obj) ? __typeError7("Cannot add the same private member more than once") : member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
var __privateSet5 = (obj, member, value, setter) => (__accessCheck7(obj, member, "write to private field"), setter ? setter.call(obj, value) : member.set(obj, value), value);
var __privateMethod4 = (obj, member, method) => (__accessCheck7(obj, member, "access private method"), method);
var _blob;
var _cache;
var _QuiltReader_instances;
var readBytesFromSlivers_fn;
var readBytesFromBlob_fn;
var readBytes_fn;
var QuiltReader = class {
  constructor({ blob }) {
    __privateAdd7(this, _QuiltReader_instances);
    __privateAdd7(this, _blob);
    __privateAdd7(this, _cache, new ClientCache());
    __privateSet5(this, _blob, blob);
  }
  async getBlobHeader(sliverIndex) {
    return __privateGet6(this, _cache).read(["getBlobHeader", sliverIndex.toString()], async () => {
      const blobHeader = QuiltPatchBlobHeader.parse(
        await __privateMethod4(this, _QuiltReader_instances, readBytes_fn).call(this, sliverIndex, QUILT_PATCH_BLOB_HEADER_SIZE)
      );
      let offset = QUILT_PATCH_BLOB_HEADER_SIZE;
      let blobSize = blobHeader.length;
      const identifierLength = new DataView(
        (await __privateMethod4(this, _QuiltReader_instances, readBytes_fn).call(this, sliverIndex, 2, offset)).buffer
      ).getUint16(0, true);
      blobSize -= 2 + identifierLength;
      offset += 2;
      const identifier = bcs.string().parse(await __privateMethod4(this, _QuiltReader_instances, readBytes_fn).call(this, sliverIndex, identifierLength, offset));
      offset += identifierLength;
      let tags = null;
      if (blobHeader.mask & HAS_TAGS_FLAG) {
        const tagsSize = new DataView(
          (await __privateMethod4(this, _QuiltReader_instances, readBytes_fn).call(this, sliverIndex, 2, offset)).buffer
        ).getUint16(0, true);
        offset += 2;
        tags = QuiltPatchTags.parse(await __privateMethod4(this, _QuiltReader_instances, readBytes_fn).call(this, sliverIndex, tagsSize, offset));
        blobSize -= tagsSize + 2;
        offset += tagsSize;
      }
      return {
        identifier,
        tags,
        blobSize,
        contentOffset: offset
      };
    });
  }
  async readBlob(sliverIndex) {
    const { identifier, tags, blobSize, contentOffset } = await this.getBlobHeader(sliverIndex);
    const blobContents = await __privateMethod4(this, _QuiltReader_instances, readBytes_fn).call(this, sliverIndex, blobSize, contentOffset);
    return {
      identifier,
      tags,
      blobContents
    };
  }
  readerForPatchId(id) {
    const { quiltId, patchId } = parseQuiltPatchId(id);
    if (quiltId !== __privateGet6(this, _blob).blobId) {
      throw new Error(
        `The requested patch ${patchId} is not part of the quilt ${__privateGet6(this, _blob).blobId}`
      );
    }
    return new QuiltFileReader({ quilt: this, sliverIndex: patchId.startIndex });
  }
  async readIndex() {
    const header = new DataView((await __privateMethod4(this, _QuiltReader_instances, readBytes_fn).call(this, 0, 5)).buffer);
    const version = header.getUint8(0);
    if (version !== 1) {
      throw new Error(`Unsupported quilt version ${version}`);
    }
    const indexSize = header.getUint32(1, true);
    const indexBytes = await __privateMethod4(this, _QuiltReader_instances, readBytes_fn).call(this, 0, indexSize, 5);
    const columnSize = await __privateGet6(this, _blob).getColumnSize();
    const indexSlivers = Math.ceil(indexSize / columnSize);
    const index = QuiltIndexV1.parse(indexBytes);
    return index.patches.map((patch, i) => {
      const startIndex = i === 0 ? indexSlivers : index.patches[i - 1].endIndex;
      const reader = new QuiltFileReader({
        quilt: this,
        sliverIndex: startIndex,
        identifier: patch.identifier,
        tags: patch.tags
      });
      return {
        identifier: patch.identifier,
        patchId: urlSafeBase64(
          QuiltPatchId.serialize({
            quiltId: __privateGet6(this, _blob).blobId,
            patchId: {
              version: 1,
              startIndex,
              endIndex: patch.endIndex
            }
          }).toBytes()
        ),
        tags: patch.tags,
        reader
      };
    });
  }
};
_blob = /* @__PURE__ */ new WeakMap();
_cache = /* @__PURE__ */ new WeakMap();
_QuiltReader_instances = /* @__PURE__ */ new WeakSet();
readBytesFromSlivers_fn = async function(sliver, length, offset = 0, columnSize) {
  if (!length) {
    return new Uint8Array(0);
  }
  __privateGet6(this, _blob).getSecondarySliver({ sliverIndex: sliver }).catch(() => {
  });
  columnSize = columnSize ?? await __privateGet6(this, _blob).getColumnSize();
  const columnOffset = Math.floor(offset / columnSize);
  let remainingOffset = offset % columnSize;
  const bytes = new Uint8Array(length);
  let bytesRead = 0;
  const nSlivers = Math.ceil(length / columnSize);
  const slivers = new Array(nSlivers).fill(0).map((_, i) => __privateGet6(this, _blob).getSecondarySliver({ sliverIndex: sliver + columnOffset + i }));
  slivers.forEach((p) => p.catch(() => {
  }));
  for (const sliverPromise of slivers) {
    const sliver2 = await sliverPromise;
    let chunk2 = remainingOffset > 0 ? sliver2.subarray(remainingOffset) : sliver2;
    remainingOffset -= chunk2.length;
    if (chunk2.length > length - bytesRead) {
      chunk2 = chunk2.subarray(0, length - bytesRead);
    }
    bytes.set(chunk2, bytesRead);
    bytesRead += chunk2.length;
    if (bytesRead >= length) {
      break;
    }
  }
  return bytes;
};
readBytesFromBlob_fn = async function(startColumn, length, offset = 0) {
  const result = new Uint8Array(length);
  if (!length) {
    return result;
  }
  const blob = await __privateGet6(this, _blob).getBytes();
  const [rowSize, symbolSize] = await Promise.all([
    __privateGet6(this, _blob).getRowSize(),
    __privateGet6(this, _blob).getSymbolSize()
  ]);
  const nRows = blob.length / rowSize;
  const symbolsToSkip = Math.floor(offset / symbolSize);
  let remainingOffset = offset % symbolSize;
  let currentCol = startColumn + Math.floor(symbolsToSkip / nRows);
  let currentRow = symbolsToSkip % nRows;
  let bytesRead = 0;
  while (bytesRead < length) {
    const baseIndex = currentRow * rowSize + currentCol * symbolSize;
    const startIndex = baseIndex + remainingOffset;
    const endIndex = Math.min(
      baseIndex + symbolSize,
      startIndex + length - bytesRead,
      blob.length
    );
    if (startIndex >= blob.length) {
      throw new Error("Index out of bounds");
    }
    const size = endIndex - startIndex;
    for (let i = 0; i < size; i++) {
      result[bytesRead + i] = blob[startIndex + i];
    }
    bytesRead += size;
    remainingOffset = 0;
    currentRow = (currentRow + 1) % nRows;
    if (currentRow === 0) {
      currentCol += 1;
    }
  }
  return result;
};
readBytes_fn = async function(sliver, length, offset = 0, columnSize) {
  if (__privateGet6(this, _blob).hasStartedLoadingFullBlob) {
    return __privateMethod4(this, _QuiltReader_instances, readBytesFromBlob_fn).call(this, sliver, length, offset);
  }
  try {
    const bytes = await __privateMethod4(this, _QuiltReader_instances, readBytesFromSlivers_fn).call(this, sliver, length, offset, columnSize);
    return bytes;
  } catch (_error) {
    return __privateMethod4(this, _QuiltReader_instances, readBytesFromBlob_fn).call(this, sliver, length, offset);
  }
};

// node_modules/@mysten/walrus/dist/esm/files/readers/blob.js
var __typeError8 = (msg) => {
  throw TypeError(msg);
};
var __accessCheck8 = (obj, member, msg) => member.has(obj) || __typeError8("Cannot " + msg);
var __privateGet7 = (obj, member, getter) => (__accessCheck8(obj, member, "read from private field"), getter ? getter.call(obj) : member.get(obj));
var __privateAdd8 = (obj, member, value) => member.has(obj) ? __typeError8("Cannot add the same private member more than once") : member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
var __privateSet6 = (obj, member, value, setter) => (__accessCheck8(obj, member, "write to private field"), setter ? setter.call(obj, value) : member.set(obj, value), value);
var _cache2;
var _client;
var _secondarySlivers;
var _numShards;
var BlobReader = class {
  constructor({ client, blobId, numShards }) {
    __privateAdd8(this, _cache2, new ClientCache());
    __privateAdd8(this, _client);
    __privateAdd8(this, _secondarySlivers, /* @__PURE__ */ new Map());
    this.hasStartedLoadingFullBlob = false;
    __privateAdd8(this, _numShards);
    __privateSet6(this, _client, client);
    this.blobId = blobId;
    __privateSet6(this, _numShards, numShards);
  }
  async getIdentifier() {
    return null;
  }
  async getTags() {
    return {};
  }
  getQuiltReader() {
    return new QuiltReader({ blob: this });
  }
  async getBytes() {
    return __privateGet7(this, _cache2).read(["getBytes"], async () => {
      this.hasStartedLoadingFullBlob = true;
      try {
        const blob = await __privateGet7(this, _client).readBlob({ blobId: this.blobId });
        return blob;
      } catch (error) {
        this.hasStartedLoadingFullBlob = false;
        throw error;
      }
    });
  }
  getMetadata() {
    return __privateGet7(this, _cache2).read(
      ["getMetadata"],
      () => __privateGet7(this, _client).getBlobMetadata({ blobId: this.blobId })
    );
  }
  async getColumnSize() {
    return __privateGet7(this, _cache2).read(["getColumnSize"], async () => {
      const loadingSlivers = [...__privateGet7(this, _secondarySlivers).values()];
      if (loadingSlivers.length > 0) {
        const sliver = await Promise.any(loadingSlivers).catch(() => null);
        if (sliver) {
          return sliver.length;
        }
      }
      if (this.hasStartedLoadingFullBlob) {
        const blob = await this.getBytes();
        const { columnSize: columnSize2 } = getSizes(blob.length, __privateGet7(this, _numShards));
        return columnSize2;
      }
      const metadata = await this.getMetadata();
      const { columnSize } = getSizes(
        Number(metadata.metadata.V1.unencoded_length),
        __privateGet7(this, _numShards)
      );
      return columnSize;
    });
  }
  async getSymbolSize() {
    const columnSize = await this.getColumnSize();
    const { primarySymbols } = getSourceSymbols(__privateGet7(this, _numShards));
    if (columnSize % primarySymbols !== 0) {
      throw new Error("column size should be divisible by primary symbols");
    }
    return columnSize / primarySymbols;
  }
  async getRowSize() {
    const symbolSize = await this.getSymbolSize();
    const { secondarySymbols } = getSourceSymbols(__privateGet7(this, _numShards));
    return symbolSize * secondarySymbols;
  }
  async getSecondarySliver({ sliverIndex, signal }) {
    if (__privateGet7(this, _secondarySlivers).has(sliverIndex)) {
      return __privateGet7(this, _secondarySlivers).get(sliverIndex);
    }
    const sliverPromise = __privateGet7(this, _client).getSecondarySliver({
      blobId: this.blobId,
      index: sliverIndex,
      signal
    }).then((sliver) => new Uint8Array(sliver.symbols.data));
    __privateGet7(this, _secondarySlivers).set(sliverIndex, sliverPromise);
    try {
      const sliver = await sliverPromise;
      __privateGet7(this, _secondarySlivers).set(sliverIndex, sliver);
      return sliver;
    } catch (error) {
      __privateGet7(this, _secondarySlivers).delete(sliverIndex);
      throw error;
    }
  }
};
_cache2 = /* @__PURE__ */ new WeakMap();
_client = /* @__PURE__ */ new WeakMap();
_secondarySlivers = /* @__PURE__ */ new WeakMap();
_numShards = /* @__PURE__ */ new WeakMap();

// node_modules/@mysten/walrus/dist/esm/files/readers/local.js
var __typeError9 = (msg) => {
  throw TypeError(msg);
};
var __accessCheck9 = (obj, member, msg) => member.has(obj) || __typeError9("Cannot " + msg);
var __privateGet8 = (obj, member, getter) => (__accessCheck9(obj, member, "read from private field"), getter ? getter.call(obj) : member.get(obj));
var __privateAdd9 = (obj, member, value) => member.has(obj) ? __typeError9("Cannot add the same private member more than once") : member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
var __privateSet7 = (obj, member, value, setter) => (__accessCheck9(obj, member, "write to private field"), setter ? setter.call(obj, value) : member.set(obj, value), value);
var _contents;
var _identifier2;
var _tags2;
var LocalReader = class {
  constructor({
    contents,
    identifier,
    tags
  }) {
    __privateAdd9(this, _contents);
    __privateAdd9(this, _identifier2);
    __privateAdd9(this, _tags2);
    __privateSet7(this, _contents, contents);
    __privateSet7(this, _identifier2, identifier ?? null);
    __privateSet7(this, _tags2, tags ?? {});
  }
  async getBytes() {
    if ("arrayBuffer" in __privateGet8(this, _contents)) {
      return new Uint8Array(await __privateGet8(this, _contents).arrayBuffer());
    }
    return __privateGet8(this, _contents);
  }
  async getIdentifier() {
    return __privateGet8(this, _identifier2);
  }
  async getTags() {
    return __privateGet8(this, _tags2);
  }
};
_contents = /* @__PURE__ */ new WeakMap();
_identifier2 = /* @__PURE__ */ new WeakMap();
_tags2 = /* @__PURE__ */ new WeakMap();

// node_modules/@mysten/walrus/dist/esm/files/file.js
var __typeError10 = (msg) => {
  throw TypeError(msg);
};
var __accessCheck10 = (obj, member, msg) => member.has(obj) || __typeError10("Cannot " + msg);
var __privateGet9 = (obj, member, getter) => (__accessCheck10(obj, member, "read from private field"), getter ? getter.call(obj) : member.get(obj));
var __privateAdd10 = (obj, member, value) => member.has(obj) ? __typeError10("Cannot add the same private member more than once") : member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
var __privateSet8 = (obj, member, value, setter) => (__accessCheck10(obj, member, "write to private field"), setter ? setter.call(obj, value) : member.set(obj, value), value);
var _reader;
var _WalrusFile = class _WalrusFile2 {
  constructor({ reader }) {
    __privateAdd10(this, _reader);
    __privateSet8(this, _reader, reader);
  }
  static from(options) {
    return new _WalrusFile2({
      reader: new LocalReader(options)
    });
  }
  getIdentifier() {
    return __privateGet9(this, _reader).getIdentifier();
  }
  getTags() {
    return __privateGet9(this, _reader).getTags();
  }
  bytes() {
    return __privateGet9(this, _reader).getBytes();
  }
  async text() {
    const bytes = await this.bytes();
    return new TextDecoder().decode(bytes);
  }
  async json() {
    return JSON.parse(await this.text());
  }
};
_reader = /* @__PURE__ */ new WeakMap();
var WalrusFile = _WalrusFile;

// node_modules/@mysten/walrus/dist/esm/files/blob.js
var __typeError11 = (msg) => {
  throw TypeError(msg);
};
var __accessCheck11 = (obj, member, msg) => member.has(obj) || __typeError11("Cannot " + msg);
var __privateGet10 = (obj, member, getter) => (__accessCheck11(obj, member, "read from private field"), getter ? getter.call(obj) : member.get(obj));
var __privateAdd11 = (obj, member, value) => member.has(obj) ? __typeError11("Cannot add the same private member more than once") : member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
var __privateSet9 = (obj, member, value, setter) => (__accessCheck11(obj, member, "write to private field"), setter ? setter.call(obj, value) : member.set(obj, value), value);
var __privateMethod5 = (obj, member, method) => (__accessCheck11(obj, member, "access private method"), method);
var _reader2;
var _client2;
var _cache3;
var _WalrusBlob_instances;
var blobStatus_fn;
var WalrusBlob = class {
  constructor({ reader, client }) {
    __privateAdd11(this, _WalrusBlob_instances);
    __privateAdd11(this, _reader2);
    __privateAdd11(this, _client2);
    __privateAdd11(this, _cache3, new ClientCache());
    __privateSet9(this, _reader2, reader);
    __privateSet9(this, _client2, client);
  }
  // Get the blob as a file (i.e. do not use Quilt encoding)
  asFile() {
    return new WalrusFile({ reader: __privateGet10(this, _reader2) });
  }
  async blobId() {
    return __privateGet10(this, _reader2).blobId;
  }
  // Gets quilt-based files associated with this blob.
  async files(filters = {}) {
    const quiltReader = await __privateGet10(this, _reader2).getQuiltReader();
    const index = await quiltReader.readIndex();
    const files = [];
    for (const patch of index) {
      if (filters.ids && !filters.ids.includes(patch.patchId)) {
        continue;
      }
      if (filters.identifiers && !filters.identifiers.includes(patch.identifier)) {
        continue;
      }
      if (filters.tags && !filters.tags.some(
        (tags) => Object.entries(tags).every(([tagName, tagValue]) => patch.tags[tagName] === tagValue)
      )) {
        continue;
      }
      files.push(new WalrusFile({ reader: quiltReader.readerForPatchId(patch.patchId) }));
    }
    return files;
  }
  async exists() {
    const status = await __privateMethod5(this, _WalrusBlob_instances, blobStatus_fn).call(this);
    return status.type === "permanent" || status.type === "deletable";
  }
  async storedUntil() {
    const status = await __privateMethod5(this, _WalrusBlob_instances, blobStatus_fn).call(this);
    if (status.type === "permanent") {
      return status.endEpoch;
    }
    return null;
  }
};
_reader2 = /* @__PURE__ */ new WeakMap();
_client2 = /* @__PURE__ */ new WeakMap();
_cache3 = /* @__PURE__ */ new WeakMap();
_WalrusBlob_instances = /* @__PURE__ */ new WeakSet();
blobStatus_fn = async function() {
  return __privateGet10(this, _cache3).read(
    ["blobStatus", __privateGet10(this, _reader2).blobId],
    () => __privateGet10(this, _client2).getVerifiedBlobStatus({ blobId: __privateGet10(this, _reader2).blobId })
  );
};

// node_modules/@mysten/walrus/dist/esm/utils/retry.js
async function retry(fn, options) {
  let remaining = options.count ?? 3;
  while (remaining > 0) {
    try {
      remaining -= 1;
      return await fn();
    } catch (error) {
      if (remaining <= 0 || options.condition && !options.condition(error)) {
        throw error;
      }
      if (options.delay) {
        await new Promise(
          (resolve) => setTimeout(
            resolve,
            (options.delay ?? 1e3) + (options.jitter ? Math.random() * options.jitter : 0)
          )
        );
      }
    }
  }
  throw new Error("Retry count exceeded");
}

// node_modules/@mysten/walrus/dist/esm/client.js
var __typeError12 = (msg) => {
  throw TypeError(msg);
};
var __accessCheck12 = (obj, member, msg) => member.has(obj) || __typeError12("Cannot " + msg);
var __privateGet11 = (obj, member, getter) => (__accessCheck12(obj, member, "read from private field"), getter ? getter.call(obj) : member.get(obj));
var __privateAdd12 = (obj, member, value) => member.has(obj) ? __typeError12("Cannot add the same private member more than once") : member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
var __privateSet10 = (obj, member, value, setter) => (__accessCheck12(obj, member, "write to private field"), setter ? setter.call(obj, value) : member.set(obj, value), value);
var __privateMethod6 = (obj, member, method) => (__accessCheck12(obj, member, "access private method"), method);
var _storageNodeClient;
var _wasmUrl;
var _packageConfig;
var _suiClient;
var _objectLoader;
var _blobMetadataConcurrencyLimit;
var _readCommittee;
var _cache4;
var _uploadRelayConfig;
var _uploadRelayClient;
var _WalrusClient_instances;
var walType_fn;
var getPackageId_fn;
var getWalrusPackageId_fn;
var wasmBindings_fn;
var internalReadBlob_fn;
var getCertificationEpoch_fn;
var getReadCommittee_fn;
var forceGetReadCommittee_fn;
var withWal_fn;
var loadTipConfig_fn;
var getCreatedBlob_fn;
var writeBlobAttributesForRef_fn;
var executeTransaction_fn;
var getCommittee_fn;
var getActiveCommittee_fn;
var stakingPool_fn;
var getNodeByShardIndex_fn;
var retryOnPossibleEpochChange_fn;
var _WalrusClient = class _WalrusClient2 {
  constructor(config) {
    __privateAdd12(this, _WalrusClient_instances);
    __privateAdd12(this, _storageNodeClient);
    __privateAdd12(this, _wasmUrl);
    __privateAdd12(this, _packageConfig);
    __privateAdd12(this, _suiClient);
    __privateAdd12(this, _objectLoader);
    __privateAdd12(this, _blobMetadataConcurrencyLimit, 10);
    __privateAdd12(this, _readCommittee);
    __privateAdd12(this, _cache4);
    __privateAdd12(this, _uploadRelayConfig, null);
    __privateAdd12(this, _uploadRelayClient, null);
    this.readBlob = __privateMethod6(this, _WalrusClient_instances, retryOnPossibleEpochChange_fn).call(this, __privateMethod6(this, _WalrusClient_instances, internalReadBlob_fn));
    this.getSecondarySliver = __privateMethod6(this, _WalrusClient_instances, retryOnPossibleEpochChange_fn).call(this, this.internalGetSecondarySliver);
    if (config.network && !config.packageConfig) {
      const network = config.network;
      switch (network) {
        case "testnet":
          __privateSet10(this, _packageConfig, TESTNET_WALRUS_PACKAGE_CONFIG);
          break;
        case "mainnet":
          __privateSet10(this, _packageConfig, MAINNET_WALRUS_PACKAGE_CONFIG);
          break;
        default:
          throw new WalrusClientError(`Unsupported network: ${network}`);
      }
    } else {
      __privateSet10(this, _packageConfig, config.packageConfig);
    }
    __privateSet10(this, _wasmUrl, config.wasmUrl);
    __privateSet10(this, _uploadRelayConfig, config.uploadRelay ?? null);
    if (__privateGet11(this, _uploadRelayConfig)) {
      __privateSet10(this, _uploadRelayClient, new UploadRelayClient(__privateGet11(this, _uploadRelayConfig)));
    }
    __privateSet10(this, _suiClient, config.suiClient ?? new SuiClient({
      url: config.suiRpcUrl
    }));
    __privateSet10(this, _storageNodeClient, new StorageNodeClient(config.storageNodeClientOptions));
    __privateSet10(this, _objectLoader, new SuiObjectDataLoader(__privateGet11(this, _suiClient)));
    __privateSet10(this, _cache4, __privateGet11(this, _suiClient).cache.scope("@mysten/walrus"));
  }
  static experimental_asClientExtension({
    packageConfig,
    network,
    ...options
  } = {}) {
    return {
      name: "walrus",
      register: (client) => {
        const walrusNetwork = network || client.network;
        if (walrusNetwork !== "mainnet" && walrusNetwork !== "testnet") {
          throw new WalrusClientError("Walrus client only supports mainnet and testnet");
        }
        return new _WalrusClient2(
          packageConfig ? {
            packageConfig,
            suiClient: client,
            ...options
          } : {
            network: walrusNetwork,
            suiClient: client,
            ...options
          }
        );
      }
    };
  }
  /** The Move type for a Blob object */
  getBlobType() {
    return __privateGet11(this, _cache4).read(["getBlobType"], async () => {
      return `${await __privateMethod6(this, _WalrusClient_instances, getPackageId_fn).call(this)}::blob::Blob`;
    });
  }
  /** The cached system object for the walrus package */
  systemObject() {
    return __privateGet11(this, _objectLoader).load(__privateGet11(this, _packageConfig).systemObjectId, System);
  }
  /** The cached staking pool object for the walrus package */
  stakingObject() {
    return __privateGet11(this, _objectLoader).load(__privateGet11(this, _packageConfig).stakingPoolId, Staking);
  }
  /** The system state for the current version of walrus contract  */
  async systemState() {
    const systemState = await __privateGet11(this, _objectLoader).loadFieldObject(
      __privateGet11(this, _packageConfig).systemObjectId,
      { type: "u64", value: (await this.systemObject()).version },
      SystemStateInnerV1
    );
    return systemState;
  }
  /** The staking state for the current version of walrus contract */
  async stakingState() {
    return __privateGet11(this, _objectLoader).loadFieldObject(
      __privateGet11(this, _packageConfig).stakingPoolId,
      {
        type: "u64",
        value: (await this.stakingObject()).version
      },
      StakingInnerV1
    );
  }
  async computeBlobMetadata({ bytes, numShards }) {
    let shardCount;
    if (typeof numShards === "number") {
      shardCount = numShards;
    } else {
      const systemState = await this.systemState();
      shardCount = systemState.committee.n_shards;
    }
    const bindings = await __privateMethod6(this, _WalrusClient_instances, wasmBindings_fn).call(this);
    const { blobId, metadata: metadata2, rootHash } = bindings.computeMetadata(shardCount, bytes);
    let sha256Hash;
    const nonce = crypto.getRandomValues(new Uint8Array(32));
    return {
      rootHash,
      blobId,
      metadata: {
        encodingType: metadata2.V1.encoding_type,
        hashes: Array.from(metadata2.V1.hashes).map((hashes) => ({
          primaryHash: hashes.primary_hash,
          secondaryHash: hashes.secondary_hash
        })),
        unencodedLength: metadata2.V1.unencoded_length
      },
      nonce,
      blobDigest: () => {
        if (!sha256Hash) {
          sha256Hash = crypto.subtle.digest("SHA-256", bytes).then((hash) => new Uint8Array(hash));
        }
        return sha256Hash;
      }
    };
  }
  async getBlobMetadata({ blobId, signal }) {
    const committee = await __privateMethod6(this, _WalrusClient_instances, getReadCommittee_fn).call(this, { blobId, signal });
    const randomizedNodes = shuffle(committee.nodes);
    const stakingState = await this.stakingState();
    const numShards = stakingState.n_shards;
    let numNotFoundWeight = 0;
    let numBlockedWeight = 0;
    let totalErrorCount = 0;
    const controller = new AbortController();
    const metadataExecutors = randomizedNodes.map((node) => async () => {
      try {
        return await __privateGet11(this, _storageNodeClient).getBlobMetadata(
          { blobId },
          {
            nodeUrl: node.networkUrl,
            signal: signal ? AbortSignal.any([controller.signal, signal]) : controller.signal
          }
        );
      } catch (error) {
        if (error instanceof NotFoundError) {
          numNotFoundWeight += node.shardIndices.length;
        } else if (error instanceof LegallyUnavailableError) {
          numBlockedWeight += node.shardIndices.length;
        }
        totalErrorCount += 1;
        throw error;
      }
    });
    try {
      const attemptGetMetadata = metadataExecutors.shift();
      return await attemptGetMetadata();
    } catch (error) {
      const chunkSize = Math.floor(metadataExecutors.length / __privateGet11(this, _blobMetadataConcurrencyLimit));
      const chunkedExecutors = chunk(metadataExecutors, chunkSize);
      return await new Promise((resolve, reject) => {
        chunkedExecutors.forEach(async (executors) => {
          for (const executor of executors) {
            try {
              const result = await executor();
              controller.abort("Blob metadata successfully retrieved.");
              resolve(result);
            } catch (error2) {
              if (error2 instanceof UserAbortError) {
                reject(error2);
                return;
              } else if (isQuorum(numBlockedWeight + numNotFoundWeight, numShards)) {
                const abortError = numNotFoundWeight > numBlockedWeight ? new BlobNotCertifiedError(`The specified blob ${blobId} is not certified.`) : new BlobBlockedError(`The specified blob ${blobId} is blocked.`);
                controller.abort(abortError);
                reject(abortError);
                return;
              }
              if (totalErrorCount === metadataExecutors.length) {
                reject(
                  new NoBlobMetadataReceivedError(
                    "No valid blob metadata could be retrieved from any storage node."
                  )
                );
              }
            }
          }
        });
      });
    }
  }
  async internalGetSecondarySliver({ blobId, index, signal }) {
    const committee = await __privateMethod6(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
    const stakingState = await this.stakingState();
    const numShards = stakingState.n_shards;
    const sliverPairIndex = sliverPairIndexFromSecondarySliverIndex(index, numShards);
    const shardIndex = toShardIndex(sliverPairIndex, blobId, numShards);
    const node = await __privateMethod6(this, _WalrusClient_instances, getNodeByShardIndex_fn).call(this, committee, shardIndex);
    if (!node) {
      throw new Error(`No node found for shard index ${shardIndex}`);
    }
    const sliver = await __privateGet11(this, _storageNodeClient).getSliver(
      { blobId, sliverPairIndex, sliverType: "secondary" },
      {
        nodeUrl: node.networkUrl,
        signal
      }
    );
    return sliver;
  }
  async getSlivers({ blobId, signal }) {
    const committee = await __privateMethod6(this, _WalrusClient_instances, getReadCommittee_fn).call(this, { blobId, signal });
    const randomizedNodes = weightedShuffle(
      committee.nodes.map((node) => ({
        value: node,
        weight: node.shardIndices.length
      }))
    );
    const stakingState = await this.stakingState();
    const numShards = stakingState.n_shards;
    const { primarySymbols: minSymbols } = getSourceSymbols(numShards);
    const sliverPairIndices = randomizedNodes.flatMap(
      (node) => node.shardIndices.map((shardIndex) => ({
        url: node.networkUrl,
        sliverPairIndex: toPairIndex(shardIndex, blobId, numShards)
      }))
    );
    const controller = new AbortController();
    const chunkedSliverPairIndices = chunk(sliverPairIndices, minSymbols);
    const slivers = [];
    const failedNodes = /* @__PURE__ */ new Set();
    let numNotFoundWeight = 0;
    let numBlockedWeight = 0;
    let totalErrorCount = 0;
    return new Promise((resolve, reject) => {
      chunkedSliverPairIndices[0].forEach(async (_, colIndex) => {
        for (let rowIndex = 0; rowIndex < chunkedSliverPairIndices.length; rowIndex += 1) {
          const value = chunkedSliverPairIndices.at(rowIndex)?.at(colIndex);
          if (!value) break;
          const { url, sliverPairIndex } = value;
          try {
            if (failedNodes.has(url)) {
              throw new Error(`Skipping node at ${url} due to previous failure.`);
            }
            const sliver = await __privateGet11(this, _storageNodeClient).getSliver(
              { blobId, sliverPairIndex, sliverType: "primary" },
              {
                nodeUrl: url,
                signal: signal ? AbortSignal.any([controller.signal, signal]) : controller.signal
              }
            );
            if (slivers.length === minSymbols) {
              controller.abort("Enough slivers successfully retrieved.");
              resolve(slivers);
              return;
            }
            slivers.push(sliver);
          } catch (error) {
            if (error instanceof NotFoundError) {
              numNotFoundWeight += 1;
            } else if (error instanceof LegallyUnavailableError) {
              numBlockedWeight += 1;
            } else if (error instanceof UserAbortError) {
              reject(error);
              return;
            }
            if (isQuorum(numBlockedWeight + numNotFoundWeight, numShards)) {
              const abortError = numNotFoundWeight > numBlockedWeight ? new BlobNotCertifiedError(`The specified blob ${blobId} is not certified.`) : new BlobBlockedError(`The specified blob ${blobId} is blocked.`);
              controller.abort(abortError);
              reject(abortError);
              return;
            }
            failedNodes.add(url);
            totalErrorCount += 1;
            const remainingTasks = sliverPairIndices.length - (slivers.length + totalErrorCount);
            const tooManyFailures = slivers.length + remainingTasks < minSymbols;
            if (tooManyFailures) {
              const abortError = new NotEnoughSliversReceivedError(
                `Unable to retrieve enough slivers to decode blob ${blobId}.`
              );
              controller.abort(abortError);
              reject(abortError);
            }
          }
        }
      });
    });
  }
  /**
   * Gets the blob status from multiple storage nodes and returns the latest status that can be verified.
   */
  async getVerifiedBlobStatus({ blobId, signal }) {
    const committee = await __privateMethod6(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
    const stakingState = await this.stakingState();
    const numShards = stakingState.n_shards;
    const controller = new AbortController();
    const statuses = await new Promise(
      (resolve, reject) => {
        const results = [];
        let successWeight = 0;
        let numNotFoundWeight = 0;
        let settledCount = 0;
        committee.nodes.forEach(async (node) => {
          const weight = node.shardIndices.length;
          try {
            const status = await __privateGet11(this, _storageNodeClient).getBlobStatus(
              { blobId },
              {
                nodeUrl: node.networkUrl,
                signal: signal ? AbortSignal.any([controller.signal, signal]) : controller.signal
              }
            );
            if (isQuorum(successWeight, numShards)) {
              controller.abort("Quorum of blob statuses retrieved successfully.");
              resolve(results);
            } else {
              successWeight += weight;
              results.push({ status, weight });
            }
          } catch (error) {
            if (error instanceof NotFoundError) {
              numNotFoundWeight += weight;
            } else if (error instanceof UserAbortError) {
              reject(error);
            }
            if (isQuorum(numNotFoundWeight, numShards)) {
              const abortError = new BlobNotCertifiedError("The blob does not exist.");
              controller.abort(abortError);
              reject(abortError);
            }
          } finally {
            settledCount += 1;
            if (settledCount === committee.nodes.length) {
              reject(
                new NoBlobStatusReceivedError(
                  "Not enough statuses were retrieved to achieve quorum."
                )
              );
            }
          }
        });
      }
    );
    const aggregatedStatuses = statuses.reduce((accumulator, value) => {
      const { status, weight } = value;
      const key = JSON.stringify(status);
      const existing = accumulator.get(key);
      if (existing) {
        existing.totalWeight += weight;
      } else {
        accumulator.set(key, { status, totalWeight: weight });
      }
      return accumulator;
    }, /* @__PURE__ */ new Map());
    const uniqueStatuses = [...aggregatedStatuses.values()];
    const sortedStatuses = uniqueStatuses.toSorted(
      (a, b) => statusLifecycleRank[b.status.type] - statusLifecycleRank[a.status.type]
    );
    for (const value of sortedStatuses) {
      if (isAboveValidity(value.totalWeight, numShards)) {
        return value.status;
      }
    }
    throw new NoVerifiedBlobStatusReceivedError(
      `The blob status could not be verified for blob ${blobId},`
    );
  }
  /**
   * Calculate the cost of storing a blob for a given a size and number of epochs.
   */
  async storageCost(size, epochs) {
    const systemState = await this.systemState();
    const encodedSize = encodedBlobLength(size, systemState.committee.n_shards);
    const storageUnits = storageUnitsFromSize(encodedSize);
    const storageCost = BigInt(storageUnits) * BigInt(systemState.storage_price_per_unit_size) * BigInt(epochs);
    BigInt(epochs);
    const writeCost = BigInt(storageUnits) * BigInt(systemState.write_price_per_unit_size);
    return { storageCost, writeCost, totalCost: storageCost + writeCost };
  }
  /**
   * A utility for creating a storage object in a transaction.
   *
   * @usage
   * ```ts
   * tx.transferObjects([client.createStorage({ size: 1000, epochs: 3 })], owner);
   * ```
   */
  createStorage({ size, epochs, walCoin }) {
    return async (tx) => {
      const systemObject = await this.systemObject();
      const systemState = await this.systemState();
      const encodedSize = encodedBlobLength(size, systemState.committee.n_shards);
      const [{ storageCost }, walrusPackageId] = await Promise.all([
        this.storageCost(size, epochs),
        __privateMethod6(this, _WalrusClient_instances, getWalrusPackageId_fn).call(this)
      ]);
      return tx.add(
        __privateMethod6(this, _WalrusClient_instances, withWal_fn).call(this, storageCost, walCoin ?? null, (coin, tx2) => {
          return tx2.add(
            reserveSpace({
              package: walrusPackageId,
              arguments: {
                self: systemObject.id.id,
                storageAmount: encodedSize,
                epochsAhead: epochs,
                payment: coin
              }
            })
          );
        })
      );
    };
  }
  /**
   * Create a transaction that creates a storage object
   *
   * @usage
   * ```ts
   * const tx = client.createStorageTransaction({ size: 1000, epochs: 3, owner: signer.toSuiAddress() });
   * ```
   */
  createStorageTransaction({
    transaction = new Transaction(),
    size,
    epochs,
    owner
  }) {
    transaction.transferObjects([this.createStorage({ size, epochs })], owner);
    return transaction;
  }
  /**
   * Execute a transaction that creates a storage object
   *
   * @usage
   * ```ts
   * const { digest, storage } = await client.executeCreateStorageTransaction({ size: 1000, epochs: 3, signer });
   * ```
   */
  async executeCreateStorageTransaction({
    signer,
    ...options
  }) {
    const transaction = this.createStorageTransaction({
      ...options,
      owner: options.transaction?.getData().sender ?? signer.toSuiAddress()
    });
    const blobType = await this.getBlobType();
    const { digest, effects } = await __privateMethod6(this, _WalrusClient_instances, executeTransaction_fn).call(this, transaction, signer, "create storage");
    const createdObjectIds = effects?.changedObjects.filter((object) => object.idOperation === "Created").map((object) => object.id);
    const createdObjects = await __privateGet11(this, _suiClient).core.getObjects({
      objectIds: createdObjectIds
    });
    const suiBlobObject = createdObjects.objects.find(
      (object) => !(object instanceof Error) && object.type === blobType
    );
    if (suiBlobObject instanceof Error || !suiBlobObject) {
      throw new WalrusClientError(
        `Storage object not found in transaction effects for transaction (${digest})`
      );
    }
    return {
      digest,
      storage: Storage.parse(await suiBlobObject.content)
    };
  }
  /**
   * Register a blob in a transaction
   *
   * @usage
   * ```ts
   * tx.transferObjects([client.registerBlob({ size: 1000, epochs: 3, blobId, rootHash, deletable: true })], owner);
   * ```
   */
  registerBlob({
    size,
    epochs,
    blobId,
    rootHash,
    deletable,
    walCoin,
    attributes
  }) {
    return async (tx) => {
      const { writeCost } = await this.storageCost(size, epochs);
      const walrusPackageId = await __privateMethod6(this, _WalrusClient_instances, getWalrusPackageId_fn).call(this);
      return tx.add(
        __privateMethod6(this, _WalrusClient_instances, withWal_fn).call(this, writeCost, walCoin ?? null, async (writeCoin, tx2) => {
          const blob = tx2.add(
            registerBlob({
              package: walrusPackageId,
              arguments: {
                self: tx2.object(__privateGet11(this, _packageConfig).systemObjectId),
                storage: this.createStorage({ size, epochs, walCoin }),
                blobId: blobIdToInt(blobId),
                rootHash: BigInt(bcs.u256().parse(rootHash)),
                size,
                encodingType: 1,
                deletable,
                writePayment: writeCoin
              }
            })
          );
          if (attributes) {
            tx2.add(
              __privateMethod6(this, _WalrusClient_instances, writeBlobAttributesForRef_fn).call(this, {
                attributes,
                existingAttributes: null,
                blob
              })
            );
          }
          return blob;
        })
      );
    };
  }
  addAuthPayload({
    size,
    blobDigest,
    nonce
  }) {
    return async (transaction) => {
      const nonceDigest = await crypto.subtle.digest("SHA-256", nonce);
      const lengthBytes = bcs.u64().serialize(size).toBytes();
      const digest = typeof blobDigest === "function" ? await blobDigest() : blobDigest;
      const authPayload = new Uint8Array(
        nonceDigest.byteLength + digest.byteLength + lengthBytes.byteLength
      );
      authPayload.set(digest, 0);
      authPayload.set(new Uint8Array(nonceDigest), digest.byteLength);
      authPayload.set(lengthBytes, nonceDigest.byteLength + digest.byteLength);
      transaction.pure(authPayload);
    };
  }
  async calculateUploadRelayTip(options) {
    const systemState = await this.systemState();
    const encodedSize = encodedBlobLength(options.size, systemState.committee.n_shards);
    const tipConfig = await __privateMethod6(this, _WalrusClient_instances, loadTipConfig_fn).call(this);
    if (!tipConfig) {
      return 0n;
    }
    const { max, kind } = tipConfig;
    const amount = "const" in kind ? kind.const : BigInt(kind.linear.base) + BigInt(kind.linear.perEncodedKib) * ((BigInt(encodedSize) + 1023n) / 1024n);
    if (max != null && amount > max) {
      throw new WalrusClientError(
        `Tip amount (${amount}) exceeds the maximum allowed tip (${max})`
      );
    }
    return amount;
  }
  sendUploadRelayTip({
    size,
    blobDigest,
    nonce
  }) {
    return async (transaction) => {
      const tipConfig = await __privateMethod6(this, _WalrusClient_instances, loadTipConfig_fn).call(this);
      if (tipConfig) {
        transaction.add(this.addAuthPayload({ size, blobDigest, nonce }));
        const amount = await this.calculateUploadRelayTip({ size });
        const { address } = tipConfig;
        transaction.transferObjects(
          [
            coinWithBalance({
              balance: amount
            })
          ],
          address
        );
      }
    };
  }
  /**
   * Create a transaction that registers a blob
   *
   * @usage
   * ```ts
   * const tx = client.registerBlobTransaction({ size: 1000, epochs: 3, blobId, rootHash, deletable: true });
   * ```
   */
  registerBlobTransaction({
    transaction = new Transaction(),
    ...options
  }) {
    const registration = transaction.add(this.registerBlob(options));
    transaction.transferObjects([registration], options.owner);
    return transaction;
  }
  /**
   * Execute a transaction that registers a blob
   *
   * @usage
   * ```ts
   * const { digest, blob } = await client.executeRegisterBlobTransaction({ size: 1000, epochs: 3, signer });
   * ```
   */
  async executeRegisterBlobTransaction({
    signer,
    ...options
  }) {
    const transaction = this.registerBlobTransaction({
      ...options,
      owner: options.owner ?? options.transaction?.getData().sender ?? signer.toSuiAddress()
    });
    const blobType = await this.getBlobType();
    const { digest, effects } = await __privateMethod6(this, _WalrusClient_instances, executeTransaction_fn).call(this, transaction, signer, "register blob");
    const createdObjectIds = effects?.changedObjects.filter((object) => object.idOperation === "Created").map((object) => object.id);
    const createdObjects = await __privateGet11(this, _suiClient).core.getObjects({
      objectIds: createdObjectIds
    });
    const suiBlobObject = createdObjects.objects.find(
      (object) => !(object instanceof Error) && object.type === blobType
    );
    if (suiBlobObject instanceof Error || !suiBlobObject) {
      throw new WalrusClientError(
        `Blob object not found in transaction effects for transaction (${digest})`
      );
    }
    return {
      digest,
      blob: Blob.parse(await suiBlobObject.content)
    };
  }
  async certificateFromConfirmations({
    confirmations,
    blobId,
    deletable,
    blobObjectId
  }) {
    const systemState = await this.systemState();
    const committee = await __privateMethod6(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
    if (confirmations.length !== systemState.committee.members.length) {
      throw new WalrusClientError(
        "Invalid number of confirmations. Confirmations array must contain an entry for each node"
      );
    }
    const confirmationMessage = StorageConfirmation.serialize({
      intent: IntentType.BLOB_CERT_MSG,
      epoch: systemState.committee.epoch,
      messageContents: {
        blobId,
        blobType: deletable ? {
          Deletable: {
            objectId: blobObjectId
          }
        } : {
          Permanent: null
        }
      }
    }).toBase64();
    const bindings = await __privateMethod6(this, _WalrusClient_instances, wasmBindings_fn).call(this);
    const verifySignature = bindings.getVerifySignature();
    const filteredConfirmations = confirmations.map((confirmation, index) => {
      const isValid = confirmation?.serializedMessage === confirmationMessage && verifySignature(
        confirmation,
        new Uint8Array(committee.nodes[index].info.public_key.bytes)
      );
      return isValid ? {
        index,
        ...confirmation
      } : null;
    }).filter((confirmation) => confirmation !== null);
    if (!isQuorum(filteredConfirmations.length, systemState.committee.members.length)) {
      throw new NotEnoughBlobConfirmationsError(
        `Too many invalid confirmations received for blob (${filteredConfirmations.length} of ${systemState.committee.members.length})`
      );
    }
    return bindings.combineSignatures(
      filteredConfirmations,
      filteredConfirmations.map(({ index }) => index)
    );
  }
  /**
   * Certify a blob in a transaction
   *
   * @usage
   * ```ts
   * tx.add(client.certifyBlob({ blobId, blobObjectId, confirmations }));
   * ```
   */
  certifyBlob({ blobId, blobObjectId, confirmations, certificate, deletable }) {
    return async (tx) => {
      const systemState = await this.systemState();
      const combinedSignature = certificate ?? await this.certificateFromConfirmations({
        confirmations,
        blobId,
        deletable,
        blobObjectId
      });
      const walrusPackageId = await __privateMethod6(this, _WalrusClient_instances, getWalrusPackageId_fn).call(this);
      tx.add(
        certifyBlob({
          package: walrusPackageId,
          arguments: {
            self: __privateGet11(this, _packageConfig).systemObjectId,
            blob: blobObjectId,
            signature: tx.pure.vector("u8", combinedSignature.signature),
            signersBitmap: tx.pure.vector(
              "u8",
              signersToBitmap(combinedSignature.signers, systemState.committee.members.length)
            ),
            message: tx.pure.vector("u8", combinedSignature.serializedMessage)
          }
        })
      );
    };
  }
  /**
   * Create a transaction that certifies a blob
   *
   * @usage
   * ```ts
   * const tx = client.certifyBlobTransaction({ blobId, blobObjectId, confirmations });
   * ```
   */
  certifyBlobTransaction({
    transaction = new Transaction(),
    ...options
  }) {
    transaction.add(this.certifyBlob(options));
    return transaction;
  }
  /**
   * Execute a transaction that certifies a blob
   *
   * @usage
   * ```ts
   * const { digest } = await client.executeCertifyBlobTransaction({ blobId, blobObjectId, confirmations, signer });
   * ```
   */
  async executeCertifyBlobTransaction({
    signer,
    ...options
  }) {
    const transaction = this.certifyBlobTransaction(options);
    const { digest } = await __privateMethod6(this, _WalrusClient_instances, executeTransaction_fn).call(this, transaction, signer, "certify blob");
    return { digest };
  }
  /**
   * Delete a blob in a transaction
   *
   * @usage
   * ```ts
   * const storage = await client.deleteBlob({ blobObjectId });
   * tx.transferObjects([storage], owner);
   * ```
   */
  deleteBlob({ blobObjectId }) {
    return async (tx) => {
      const walrusPackageId = await __privateMethod6(this, _WalrusClient_instances, getWalrusPackageId_fn).call(this);
      const storage = tx.add(
        deleteBlob({
          package: walrusPackageId,
          arguments: {
            self: __privateGet11(this, _packageConfig).systemObjectId,
            blob: blobObjectId
          }
        })
      );
      return storage;
    };
  }
  /**
   * Create a transaction that deletes a blob
   *
   * @usage
   * ```ts
   * const tx = client.deleteBlobTransaction({ blobObjectId, owner });
   * ```
   */
  deleteBlobTransaction({
    owner,
    blobObjectId,
    transaction = new Transaction()
  }) {
    const storage = transaction.add(this.deleteBlob({ blobObjectId }));
    transaction.transferObjects([storage], owner);
    return transaction;
  }
  /**
   * Execute a transaction that deletes a blob
   *
   * @usage
   * ```ts
   * const { digest } = await client.executeDeleteBlobTransaction({ blobObjectId, signer });
   * ```
   */
  async executeDeleteBlobTransaction({
    signer,
    transaction = new Transaction(),
    blobObjectId
  }) {
    const { digest } = await __privateMethod6(this, _WalrusClient_instances, executeTransaction_fn).call(this, this.deleteBlobTransaction({
      blobObjectId,
      transaction,
      owner: transaction.getData().sender ?? signer.toSuiAddress()
    }), signer, "delete blob");
    return { digest };
  }
  /**
   * Extend a blob in a transaction
   *
   * @usage
   * ```ts
   * const tx = client.extendBlobTransaction({ blobObjectId, epochs });
   * ```
   */
  extendBlob({ blobObjectId, epochs, endEpoch, walCoin }) {
    return async (tx) => {
      const blob = await __privateGet11(this, _objectLoader).load(blobObjectId, Blob);
      const numEpochs = typeof epochs === "number" ? epochs : endEpoch - blob.storage.end_epoch;
      if (numEpochs <= 0) {
        return;
      }
      const { storageCost } = await this.storageCost(Number(blob.storage.storage_size), numEpochs);
      const walrusPackageId = await __privateMethod6(this, _WalrusClient_instances, getWalrusPackageId_fn).call(this);
      return tx.add(
        __privateMethod6(this, _WalrusClient_instances, withWal_fn).call(this, storageCost, walCoin ?? null, async (coin, tx2) => {
          tx2.add(
            extendBlob({
              package: walrusPackageId,
              arguments: {
                self: __privateGet11(this, _packageConfig).systemObjectId,
                blob: blobObjectId,
                extendedEpochs: numEpochs,
                payment: coin
              }
            })
          );
        })
      );
    };
  }
  /**
   * Create a transaction that extends a blob
   *
   * @usage
   * ```ts
   * const tx = client.extendBlobTransaction({ blobObjectId, epochs });
   * ```
   */
  async extendBlobTransaction({
    transaction = new Transaction(),
    ...options
  }) {
    transaction.add(this.extendBlob(options));
    return transaction;
  }
  /**
   * Execute a transaction that extends a blob
   *
   * @usage
   * ```ts
   * const { digest } = await client.executeExtendBlobTransaction({ blobObjectId, signer });
   * ```
   */
  async executeExtendBlobTransaction({
    signer,
    ...options
  }) {
    const { digest } = await __privateMethod6(this, _WalrusClient_instances, executeTransaction_fn).call(this, await this.extendBlobTransaction(options), signer, "extend blob");
    return { digest };
  }
  async readBlobAttributes({
    blobObjectId
  }) {
    const response = await __privateGet11(this, _suiClient).core.getDynamicField({
      parentId: blobObjectId,
      name: {
        type: "vector<u8>",
        bcs: bcs.string().serialize("metadata").toBytes()
      }
    });
    const parsedMetadata = Metadata.parse(response.dynamicField.value.bcs);
    return Object.fromEntries(
      parsedMetadata.metadata.contents.map(({ key, value }) => [key, value])
    );
  }
  /**
   * Write attributes to a blob
   *
   * If attributes already exists, their previous values will be overwritten
   * If an attribute is set to `null`, it will be removed from the blob
   *
   * @usage
   * ```ts
   * tx.add(client.writeBlobAttributes({ blobObjectId, attributes: { key: 'value', keyToRemove: null } }));
   * ```
   */
  writeBlobAttributes({ blobObject, blobObjectId, attributes }) {
    return async (tx) => {
      const existingAttributes = blobObjectId ? await this.readBlobAttributes({ blobObjectId }) : null;
      const blob = blobObject ?? tx.object(blobObjectId);
      tx.add(
        __privateMethod6(this, _WalrusClient_instances, writeBlobAttributesForRef_fn).call(this, {
          attributes,
          existingAttributes,
          blob
        })
      );
    };
  }
  /**
   * Create a transaction that writes attributes to a blob
   *
   * If attributes already exists, their previous values will be overwritten
   * If an attribute is set to `null`, it will be removed from the blob
   *
   * @usage
   * ```ts
   * const tx = client.writeBlobAttributesTransaction({ blobObjectId, attributes: { key: 'value', keyToRemove: null } });
   * ```
   */
  async writeBlobAttributesTransaction({
    transaction = new Transaction(),
    ...options
  }) {
    transaction.add(await this.writeBlobAttributes(options));
    return transaction;
  }
  /**
   * Execute a transaction that writes attributes to a blob
   *
   * If attributes already exists, their previous values will be overwritten
   * If an attribute is set to `null`, it will be removed from the blob
   *
   * @usage
   * ```ts
   * const { digest } = await client.executeWriteBlobAttributesTransaction({ blobObjectId, signer });
   * ```
   */
  async executeWriteBlobAttributesTransaction({
    signer,
    ...options
  }) {
    const { digest } = await __privateMethod6(this, _WalrusClient_instances, executeTransaction_fn).call(this, await this.writeBlobAttributesTransaction(options), signer, "write blob attributes");
    return { digest };
  }
  /**
   * Write a sliver to a storage node
   *
   * @usage
   * ```ts
   * const res = await client.writeSliver({ blobId, sliverPairIndex, sliverType, sliver });
   * ```
   */
  async writeSliver({ blobId, sliverPairIndex, sliverType, sliver, signal }) {
    const systemState = await this.systemState();
    const committee = await __privateMethod6(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
    const shardIndex = toShardIndex(sliverPairIndex, blobId, systemState.committee.n_shards);
    const node = await __privateMethod6(this, _WalrusClient_instances, getNodeByShardIndex_fn).call(this, committee, shardIndex);
    return __privateGet11(this, _storageNodeClient).storeSliver(
      { blobId, sliverPairIndex, sliverType, sliver },
      { nodeUrl: node.networkUrl, signal }
    );
  }
  /**
   * Write metadata to a storage node
   *
   * @usage
   * ```ts
   * const res = await client.writeMetadataToNode({ nodeIndex, blobId, metadata });
   * ```
   */
  async writeMetadataToNode({ nodeIndex, blobId, metadata: metadata2, signal }) {
    const committee = await __privateMethod6(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
    const node = committee.nodes[nodeIndex];
    return retry(
      () => __privateGet11(this, _storageNodeClient).storeBlobMetadata(
        { blobId, metadata: metadata2 },
        { nodeUrl: node.networkUrl, signal }
      ),
      {
        count: 3,
        delay: 1e3,
        condition: (error) => error instanceof BlobNotRegisteredError
      }
    );
  }
  /**
   * Get a storage confirmation from a storage node
   *
   * @usage
   * ```ts
   * const confirmation = await client.getStorageConfirmationFromNode({ nodeIndex, blobId, deletable, objectId });
   * ```
   */
  async getStorageConfirmationFromNode({
    nodeIndex,
    blobId,
    deletable,
    objectId,
    signal
  }) {
    const committee = await __privateMethod6(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
    const node = committee.nodes[nodeIndex];
    const result = deletable ? await __privateGet11(this, _storageNodeClient).getDeletableBlobConfirmation(
      { blobId, objectId },
      { nodeUrl: node.networkUrl, signal }
    ) : await __privateGet11(this, _storageNodeClient).getPermanentBlobConfirmation(
      { blobId },
      { nodeUrl: node.networkUrl, signal }
    );
    return result?.success?.data?.signed ?? null;
  }
  /**
   * Encode a blob into slivers for each node
   *
   * @usage
   * ```ts
   * const { blobId, metadata, sliversByNode, rootHash } = await client.encodeBlob(blob);
   * ```
   */
  async encodeBlob(blob) {
    const systemState = await this.systemState();
    const committee = await __privateMethod6(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
    const numShards = systemState.committee.n_shards;
    const bindings = await __privateMethod6(this, _WalrusClient_instances, wasmBindings_fn).call(this);
    const { blobId, metadata: metadata2, sliverPairs, rootHash } = bindings.encodeBlob(numShards, blob);
    const sliversByNodeMap = /* @__PURE__ */ new Map();
    while (sliverPairs.length > 0) {
      const { primary, secondary } = sliverPairs.pop();
      const sliverPairIndex = primary.index;
      const shardIndex = toShardIndex(sliverPairIndex, blobId, numShards);
      const node = await __privateMethod6(this, _WalrusClient_instances, getNodeByShardIndex_fn).call(this, committee, shardIndex);
      if (!sliversByNodeMap.has(node.nodeIndex)) {
        sliversByNodeMap.set(node.nodeIndex, { primary: [], secondary: [] });
      }
      sliversByNodeMap.get(node.nodeIndex).primary.push({
        sliverIndex: primary.index,
        sliverPairIndex,
        shardIndex,
        sliver: SliverData.serialize(primary).toBytes()
      });
      sliversByNodeMap.get(node.nodeIndex).secondary.push({
        sliverIndex: secondary.index,
        sliverPairIndex,
        shardIndex,
        sliver: SliverData.serialize(secondary).toBytes()
      });
    }
    const sliversByNode = new Array();
    for (let i = 0; i < systemState.committee.members.length; i++) {
      sliversByNode.push(sliversByNodeMap.get(i) ?? { primary: [], secondary: [] });
    }
    return { blobId, metadata: metadata2, rootHash, sliversByNode };
  }
  /**
   * Write slivers to a storage node
   *
   * @usage
   * ```ts
   * await client.writeSliversToNode({ blobId, slivers, signal });
   * ```
   */
  async writeSliversToNode({ blobId, slivers, signal }) {
    const controller = new AbortController();
    const combinedSignal = signal ? AbortSignal.any([controller.signal, signal]) : controller.signal;
    const primarySliverWrites = slivers.primary.map(({ sliverPairIndex, sliver }) => {
      return this.writeSliver({
        blobId,
        sliverPairIndex,
        sliverType: "primary",
        sliver,
        signal: combinedSignal
      });
    });
    const secondarySliverWrites = slivers.secondary.map(({ sliverPairIndex, sliver }) => {
      return this.writeSliver({
        blobId,
        sliverPairIndex,
        sliverType: "secondary",
        sliver,
        signal: combinedSignal
      });
    });
    await Promise.all([...primarySliverWrites, ...secondarySliverWrites]).catch((error) => {
      controller.abort(error);
      throw error;
    });
  }
  /**
   * Write a blob to all storage nodes
   *
   * @usage
   * ```ts
   * await client.writeEncodedBlobToNodes({ blob, deletable, epochs, signer });
   * ```
   */
  async writeEncodedBlobToNodes({
    blobId,
    metadata: metadata2,
    sliversByNode,
    signal,
    ...options
  }) {
    const systemState = await this.systemState();
    const committee = await __privateMethod6(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
    const controller = new AbortController();
    let failures = 0;
    const confirmations = await Promise.all(
      sliversByNode.map((slivers, nodeIndex) => {
        return this.writeEncodedBlobToNode({
          blobId,
          nodeIndex,
          metadata: metadata2,
          slivers,
          signal: signal ? AbortSignal.any([controller.signal, signal]) : controller.signal,
          ...options
        }).catch(() => {
          failures += committee.nodes[nodeIndex].shardIndices.length;
          if (isAboveValidity(failures, systemState.committee.n_shards)) {
            const error = new NotEnoughBlobConfirmationsError(
              `Too many failures while writing blob ${blobId} to nodes`
            );
            controller.abort(error);
            throw error;
          }
          return null;
        });
      })
    );
    return confirmations;
  }
  /**
   * Writes a blob to to an upload relay
   *
   * @usage
   * ```ts
   * await client.writeBlobToUploadRelay({ blob, deletable, epochs, signer });
   * ```
   */
  async writeBlobToUploadRelay(options) {
    if (!__privateGet11(this, _uploadRelayClient)) {
      throw new WalrusClientError("Upload relay not configured");
    }
    return __privateGet11(this, _uploadRelayClient).writeBlob({
      ...options,
      requiresTip: !!__privateGet11(this, _uploadRelayConfig)?.sendTip
    });
  }
  /**
   * Write encoded blob to a storage node
   *
   * @usage
   * ```ts
   * const res = await client.writeEncodedBlobToNode({ nodeIndex, blobId, metadata, slivers });
   * ```
   */
  async writeEncodedBlobToNode({
    nodeIndex,
    blobId,
    metadata: metadata2,
    slivers,
    signal,
    ...options
  }) {
    await this.writeMetadataToNode({
      nodeIndex,
      blobId,
      metadata: metadata2,
      signal
    });
    await this.writeSliversToNode({ blobId, slivers, signal, nodeIndex });
    return this.getStorageConfirmationFromNode({
      nodeIndex,
      blobId,
      ...options
    });
  }
  /**
   * Write a blob to all storage nodes
   *
   * @usage
   * ```ts
   * const { blobId, blobObject } = await client.writeBlob({ blob, deletable, epochs, signer });
   * ```
   */
  async writeBlob({
    blob,
    deletable,
    epochs,
    signer,
    signal,
    owner,
    attributes
  }) {
    if (!__privateGet11(this, _uploadRelayConfig)) {
      const encoded = await this.encodeBlob(blob);
      const blobId = encoded.blobId;
      const { sliversByNode, metadata: metadata2, rootHash } = encoded;
      const suiBlobObject = await this.executeRegisterBlobTransaction({
        signer,
        size: blob.length,
        epochs,
        blobId,
        rootHash,
        deletable,
        owner: owner ?? signer.toSuiAddress(),
        attributes
      });
      const blobObjectId = suiBlobObject.blob.id.id;
      const confirmations = await this.writeEncodedBlobToNodes({
        blobId,
        metadata: metadata2,
        sliversByNode,
        deletable,
        objectId: blobObjectId,
        signal
      });
      await this.executeCertifyBlobTransaction({
        signer,
        blobId,
        blobObjectId,
        confirmations,
        deletable
      });
      return {
        blobId,
        blobObject: await __privateGet11(this, _objectLoader).load(blobObjectId, Blob)
      };
    } else {
      const metadata2 = await this.computeBlobMetadata({
        bytes: blob
      });
      const blobId = metadata2.blobId;
      const transaction = new Transaction();
      transaction.add(
        this.sendUploadRelayTip({
          size: blob.length,
          blobDigest: metadata2.blobDigest,
          nonce: metadata2.nonce
        })
      );
      const registerResult = await this.executeRegisterBlobTransaction({
        signer,
        transaction,
        size: blob.length,
        epochs,
        blobId: metadata2.blobId,
        rootHash: metadata2.rootHash,
        deletable,
        owner: owner ?? signer.toSuiAddress(),
        attributes
      });
      await __privateGet11(this, _suiClient).core.waitForTransaction({
        digest: registerResult.digest
      });
      const result = await this.writeBlobToUploadRelay({
        blobId,
        blob,
        nonce: metadata2.nonce,
        txDigest: registerResult.digest,
        signal,
        deletable,
        blobObjectId: registerResult.blob.id.id,
        encodingType: metadata2.metadata.encodingType
      });
      const certificate = result.certificate;
      const blobObjectId = registerResult.blob.id.id;
      await this.executeCertifyBlobTransaction({
        signer,
        blobId,
        blobObjectId,
        certificate,
        deletable
      });
      return {
        blobId,
        blobObject: await __privateGet11(this, _objectLoader).load(blobObjectId, Blob)
      };
    }
  }
  async writeQuilt({ blobs, ...options }) {
    const encoded = await this.encodeQuilt({ blobs });
    const result = await this.writeBlob({
      blob: encoded.quilt,
      ...options
    });
    return {
      ...result,
      index: {
        ...encoded.index,
        patches: encoded.index.patches.map((patch) => ({
          ...patch,
          patchId: encodeQuiltPatchId({
            quiltId: result.blobId,
            patchId: {
              version: 1,
              startIndex: patch.startIndex,
              endIndex: patch.endIndex
            }
          })
        }))
      }
    };
  }
  async encodeQuilt({
    blobs
  }) {
    const systemState = await this.systemState();
    const encoded = encodeQuilt({
      blobs,
      numShards: systemState.committee.n_shards
    });
    return encoded;
  }
  /**
   * Reset cached data in the client
   *
   * @usage
   * ```ts
   * client.reset();
   * ```
   */
  reset() {
    __privateGet11(this, _objectLoader).clearAll();
    __privateGet11(this, _cache4).clear();
  }
  async getBlob({ blobId }) {
    return new WalrusBlob({
      reader: new BlobReader({
        client: this,
        blobId,
        numShards: (await this.systemState()).committee.n_shards
      }),
      client: this
    });
  }
  async getFiles({ ids }) {
    const readersByBlobId = /* @__PURE__ */ new Map();
    const quiltReadersByBlobId = /* @__PURE__ */ new Map();
    const parsedIds = ids.map((id) => parseWalrusId(id));
    const numShards = (await this.systemState()).committee.n_shards;
    for (const id of parsedIds) {
      const blobId = id.kind === "blob" ? id.id : id.id.quiltId;
      if (!readersByBlobId.has(blobId)) {
        readersByBlobId.set(
          blobId,
          new BlobReader({
            client: this,
            blobId,
            numShards
          })
        );
      }
      if (id.kind === "quiltPatch") {
        if (!quiltReadersByBlobId.has(blobId)) {
          quiltReadersByBlobId.set(
            blobId,
            new QuiltReader({
              blob: readersByBlobId.get(blobId)
            })
          );
        }
      }
    }
    return parsedIds.map((id) => {
      if (id.kind === "blob") {
        return new WalrusFile({
          reader: readersByBlobId.get(id.id)
        });
      }
      return new WalrusFile({
        reader: new QuiltFileReader({
          quilt: quiltReadersByBlobId.get(id.id.quiltId),
          sliverIndex: id.id.patchId.startIndex
        })
      });
    });
  }
  async writeFiles({ files, ...options }) {
    const { blobId, index, blobObject } = await this.writeQuilt({
      ...options,
      blobs: await Promise.all(
        files.map(async (file, i) => ({
          contents: await file.bytes(),
          identifier: await file.getIdentifier() ?? `file-${i}`,
          tags: await file.getTags() ?? {}
        }))
      )
    });
    return index.patches.map((patch) => ({
      id: patch.patchId,
      blobId,
      blobObject
    }));
  }
  writeFilesFlow({ files }) {
    const encode = async () => {
      const { quilt, index } = await this.encodeQuilt({
        blobs: await Promise.all(
          files.map(async (file, i) => ({
            contents: await file.bytes(),
            identifier: await file.getIdentifier() ?? `file-${i}`,
            tags: await file.getTags() ?? {}
          }))
        )
      });
      const metadata2 = __privateGet11(this, _uploadRelayClient) ? await this.computeBlobMetadata({
        bytes: quilt
      }) : await this.encodeBlob(quilt);
      return {
        metadata: metadata2,
        size: quilt.length,
        data: __privateGet11(this, _uploadRelayClient) ? quilt : void 0,
        index
      };
    };
    const register = ({ data, metadata: metadata2, index, size }, { epochs, deletable, owner, attributes }) => {
      const transaction = new Transaction();
      transaction.setSenderIfNotSet(owner);
      if (__privateGet11(this, _uploadRelayClient)) {
        const meta = metadata2;
        transaction.add(
          this.sendUploadRelayTip({
            size,
            blobDigest: meta.blobDigest,
            nonce: meta.nonce
          })
        );
      }
      transaction.transferObjects(
        [
          this.registerBlob({
            size,
            epochs,
            blobId: metadata2.blobId,
            rootHash: metadata2.rootHash,
            deletable,
            attributes
          })
        ],
        owner
      );
      return {
        registerTransaction: transaction,
        index,
        data,
        metadata: metadata2,
        deletable
      };
    };
    const upload = async ({ index, data, metadata: metadata2, deletable }, { digest }) => {
      const blobObject = await __privateMethod6(this, _WalrusClient_instances, getCreatedBlob_fn).call(this, digest);
      if (__privateGet11(this, _uploadRelayClient)) {
        const meta2 = metadata2;
        return {
          index,
          blobObject,
          metadata: metadata2,
          deletable,
          certificate: (await this.writeBlobToUploadRelay({
            blobId: metadata2.blobId,
            blob: data,
            nonce: meta2.nonce,
            txDigest: digest,
            blobObjectId: blobObject.id.id,
            deletable,
            encodingType: meta2.metadata.encodingType
          })).certificate
        };
      }
      const meta = metadata2;
      return {
        index,
        blobObject,
        metadata: metadata2,
        deletable,
        confirmations: await this.writeEncodedBlobToNodes({
          blobId: metadata2.blobId,
          objectId: blobObject.id.id,
          metadata: meta.metadata,
          sliversByNode: meta.sliversByNode,
          deletable
        })
      };
    };
    const certify = ({
      index,
      metadata: metadata2,
      confirmations,
      certificate,
      blobObject,
      deletable
    }) => {
      return {
        index,
        blobObject,
        metadata: metadata2,
        transaction: confirmations ? this.certifyBlobTransaction({
          blobId: metadata2.blobId,
          blobObjectId: blobObject.id.id,
          confirmations,
          deletable
        }) : this.certifyBlobTransaction({
          certificate,
          blobId: metadata2.blobId,
          blobObjectId: blobObject.id.id,
          deletable
        })
      };
    };
    async function listFiles({ index, blobObject, metadata: metadata2 }) {
      return index.patches.map((patch) => ({
        id: encodeQuiltPatchId({
          quiltId: metadata2.blobId,
          patchId: {
            version: 1,
            startIndex: patch.startIndex,
            endIndex: patch.endIndex
          }
        }),
        blobId: metadata2.blobId,
        blobObject
      }));
    }
    const stepResults = {};
    function getResults(step, current) {
      if (!stepResults[step]) {
        throw new Error(`${step} must be executed before calling ${current}`);
      }
      return stepResults[step];
    }
    return {
      encode: async () => {
        if (!stepResults.encode) {
          stepResults.encode = await encode();
        }
      },
      register: (options) => {
        stepResults.register = register(getResults("encode", "register"), options);
        return stepResults.register.registerTransaction;
      },
      upload: async (options) => {
        stepResults.upload = await upload(getResults("register", "upload"), options);
      },
      certify: () => {
        stepResults.certify = certify(getResults("upload", "certify"));
        return stepResults.certify.transaction;
      },
      listFiles: async () => {
        return listFiles(getResults("certify", "listFiles"));
      }
    };
  }
  writeBlobFlow({ blob }) {
    const encode = async () => {
      const metadata2 = __privateGet11(this, _uploadRelayClient) ? await this.computeBlobMetadata({
        bytes: blob
      }) : await this.encodeBlob(blob);
      return {
        metadata: metadata2,
        size: blob.length,
        data: __privateGet11(this, _uploadRelayClient) ? blob : void 0
      };
    };
    const register = ({ data, metadata: metadata2, size }, { epochs, deletable, owner, attributes }) => {
      const transaction = new Transaction();
      transaction.setSenderIfNotSet(owner);
      if (__privateGet11(this, _uploadRelayClient)) {
        const meta = metadata2;
        transaction.add(
          this.sendUploadRelayTip({
            size,
            blobDigest: meta.blobDigest,
            nonce: meta.nonce
          })
        );
      }
      transaction.transferObjects(
        [
          this.registerBlob({
            size,
            epochs,
            blobId: metadata2.blobId,
            rootHash: metadata2.rootHash,
            deletable,
            attributes
          })
        ],
        owner
      );
      return {
        registerTransaction: transaction,
        data,
        metadata: metadata2,
        deletable
      };
    };
    const upload = async ({ data, metadata: metadata2, deletable }, { digest }) => {
      const blobObject = await __privateMethod6(this, _WalrusClient_instances, getCreatedBlob_fn).call(this, digest);
      if (__privateGet11(this, _uploadRelayClient)) {
        const meta2 = metadata2;
        return {
          blobObject,
          metadata: metadata2,
          deletable,
          certificate: (await this.writeBlobToUploadRelay({
            blobId: metadata2.blobId,
            blob: data,
            nonce: meta2.nonce,
            txDigest: digest,
            blobObjectId: blobObject.id.id,
            deletable,
            encodingType: meta2.metadata.encodingType
          })).certificate
        };
      }
      const meta = metadata2;
      return {
        blobObject,
        metadata: metadata2,
        deletable,
        confirmations: await this.writeEncodedBlobToNodes({
          blobId: metadata2.blobId,
          objectId: blobObject.id.id,
          metadata: meta.metadata,
          sliversByNode: meta.sliversByNode,
          deletable
        })
      };
    };
    const certify = ({
      metadata: metadata2,
      confirmations,
      certificate,
      blobObject,
      deletable
    }) => {
      return {
        blobObject,
        metadata: metadata2,
        transaction: confirmations ? this.certifyBlobTransaction({
          blobId: metadata2.blobId,
          blobObjectId: blobObject.id.id,
          confirmations,
          deletable
        }) : this.certifyBlobTransaction({
          certificate,
          blobId: metadata2.blobId,
          blobObjectId: blobObject.id.id,
          deletable
        })
      };
    };
    async function getBlob({ blobObject, metadata: metadata2 }) {
      return {
        blobId: metadata2.blobId,
        blobObject
      };
    }
    const stepResults = {};
    function getResults(step, current) {
      if (!stepResults[step]) {
        throw new Error(`${step} must be executed before calling ${current}`);
      }
      return stepResults[step];
    }
    return {
      encode: async () => {
        if (!stepResults.encode) {
          stepResults.encode = await encode();
        }
      },
      register: (options) => {
        stepResults.register = register(getResults("encode", "register"), options);
        return stepResults.register.registerTransaction;
      },
      upload: async (options) => {
        stepResults.upload = await upload(getResults("register", "upload"), options);
      },
      certify: () => {
        stepResults.certify = certify(getResults("upload", "certify"));
        return stepResults.certify.transaction;
      },
      getBlob: async () => {
        return getBlob(getResults("certify", "getBlob"));
      }
    };
  }
};
_storageNodeClient = /* @__PURE__ */ new WeakMap();
_wasmUrl = /* @__PURE__ */ new WeakMap();
_packageConfig = /* @__PURE__ */ new WeakMap();
_suiClient = /* @__PURE__ */ new WeakMap();
_objectLoader = /* @__PURE__ */ new WeakMap();
_blobMetadataConcurrencyLimit = /* @__PURE__ */ new WeakMap();
_readCommittee = /* @__PURE__ */ new WeakMap();
_cache4 = /* @__PURE__ */ new WeakMap();
_uploadRelayConfig = /* @__PURE__ */ new WeakMap();
_uploadRelayClient = /* @__PURE__ */ new WeakMap();
_WalrusClient_instances = /* @__PURE__ */ new WeakSet();
walType_fn = function() {
  return __privateGet11(this, _cache4).read(["walType"], async () => {
    const stakedWal = await __privateGet11(this, _suiClient).jsonRpc.getNormalizedMoveStruct({
      package: await __privateMethod6(this, _WalrusClient_instances, getPackageId_fn).call(this),
      module: "staked_wal",
      struct: "StakedWal"
    });
    const balanceType = stakedWal.fields.find((field) => field.name === "principal")?.type;
    if (!balanceType) {
      throw new WalrusClientError("WAL type not found");
    }
    const parsed = parseStructTag(toTypeString(balanceType));
    const coinType = parsed.typeParams[0];
    if (!coinType) {
      throw new WalrusClientError("WAL type not found");
    }
    return normalizeStructTag(coinType);
  });
};
getPackageId_fn = function() {
  return __privateGet11(this, _cache4).read(["getPackageId"], async () => {
    const system = await __privateGet11(this, _objectLoader).load(__privateGet11(this, _packageConfig).systemObjectId);
    return parseStructTag(system.type).address;
  });
};
getWalrusPackageId_fn = function() {
  return __privateGet11(this, _cache4).read(["getSystemPackageId"], async () => {
    const { package_id } = await this.systemObject();
    return package_id;
  });
};
wasmBindings_fn = function() {
  return __privateGet11(this, _cache4).read(["wasmBindings"], async () => {
    return getWasmBindings(__privateGet11(this, _wasmUrl));
  });
};
internalReadBlob_fn = async function({ blobId, signal }) {
  const systemState = await this.systemState();
  const numShards = systemState.committee.n_shards;
  const blobMetadata = await this.getBlobMetadata({ blobId, signal });
  const slivers = await this.getSlivers({ blobId, signal });
  const bindings = await __privateMethod6(this, _WalrusClient_instances, wasmBindings_fn).call(this);
  const blobBytes = bindings.decodePrimarySlivers(
    blobId,
    numShards,
    blobMetadata.metadata.V1.unencoded_length,
    slivers
  );
  const reconstructedBlobMetadata = bindings.computeMetadata(
    systemState.committee.n_shards,
    blobBytes
  );
  if (reconstructedBlobMetadata.blobId !== blobId) {
    throw new InconsistentBlobError("The specified blob was encoded incorrectly.");
  }
  return blobBytes;
};
getCertificationEpoch_fn = async function({ blobId, signal }) {
  const stakingState = await this.stakingState();
  const currentEpoch = stakingState.epoch;
  if (stakingState.epoch_state.$kind === "EpochChangeSync") {
    const status = await this.getVerifiedBlobStatus({ blobId, signal });
    if (status.type === "nonexistent" || status.type === "invalid") {
      throw new BlobNotCertifiedError(`The specified blob ${blobId} is ${status.type}.`);
    }
    if (typeof status.initialCertifiedEpoch !== "number") {
      throw new BlobNotCertifiedError(`The specified blob ${blobId} is not certified.`);
    }
    if (status.initialCertifiedEpoch > currentEpoch) {
      throw new BehindCurrentEpochError(
        `The client is at epoch ${currentEpoch} while the specified blob was certified at epoch ${status.initialCertifiedEpoch}.`
      );
    }
    return status.initialCertifiedEpoch;
  }
  return currentEpoch;
};
getReadCommittee_fn = async function(options) {
  if (!__privateGet11(this, _readCommittee)) {
    __privateSet10(this, _readCommittee, __privateMethod6(this, _WalrusClient_instances, forceGetReadCommittee_fn).call(this, options));
  }
  return __privateGet11(this, _readCommittee);
};
forceGetReadCommittee_fn = async function({ blobId, signal }) {
  const stakingState = await this.stakingState();
  const isTransitioning = stakingState.epoch_state.$kind === "EpochChangeSync";
  const certificationEpoch = await __privateMethod6(this, _WalrusClient_instances, getCertificationEpoch_fn).call(this, { blobId, signal });
  if (isTransitioning && certificationEpoch < stakingState.epoch) {
    return await __privateMethod6(this, _WalrusClient_instances, getCommittee_fn).call(this, stakingState.previous_committee);
  }
  return await __privateMethod6(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
};
withWal_fn = function(amount, source, fn) {
  return async (tx) => {
    const walType = await __privateMethod6(this, _WalrusClient_instances, walType_fn).call(this);
    const coin = source ? tx.splitCoins(source, [amount])[0] : tx.add(
      coinWithBalance({
        balance: amount,
        type: walType
      })
    );
    const result = await fn(coin, tx);
    tx.moveCall({
      target: "0x2::coin::destroy_zero",
      typeArguments: [walType],
      arguments: [coin]
    });
    return result;
  };
};
loadTipConfig_fn = function() {
  return __privateGet11(this, _cache4).read(["upload-relay-tip-config"], async () => {
    if (!__privateGet11(this, _uploadRelayConfig)?.sendTip || !__privateGet11(this, _uploadRelayClient)) {
      return null;
    }
    if ("kind" in __privateGet11(this, _uploadRelayConfig).sendTip) {
      return __privateGet11(this, _uploadRelayConfig).sendTip;
    }
    const tipConfig = await __privateGet11(this, _uploadRelayClient).tipConfig();
    if (!tipConfig) {
      return null;
    }
    return {
      ...tipConfig,
      max: __privateGet11(this, _uploadRelayConfig).sendTip.max
    };
  });
};
getCreatedBlob_fn = async function(digest) {
  const blobType = await this.getBlobType();
  const {
    transaction: { effects }
  } = await __privateGet11(this, _suiClient).core.waitForTransaction({
    digest
  });
  const createdObjectIds = effects?.changedObjects.filter((object) => object.idOperation === "Created").map((object) => object.id);
  const createdObjects = await __privateGet11(this, _suiClient).core.getObjects({
    objectIds: createdObjectIds
  });
  const suiBlobObject = createdObjects.objects.find(
    (object) => !(object instanceof Error) && object.type === blobType
  );
  if (suiBlobObject instanceof Error || !suiBlobObject) {
    throw new WalrusClientError(
      `Blob object not found in transaction effects for transaction (${digest})`
    );
  }
  return Blob.parse(await suiBlobObject.content);
};
writeBlobAttributesForRef_fn = function({
  attributes,
  existingAttributes,
  blob
}) {
  return async (tx) => {
    const walrusPackageId = await __privateMethod6(this, _WalrusClient_instances, getWalrusPackageId_fn).call(this);
    if (!existingAttributes) {
      tx.add(
        addMetadata({
          package: walrusPackageId,
          arguments: {
            self: blob,
            metadata: _new({
              package: walrusPackageId
            })
          }
        })
      );
    }
    Object.keys(attributes).forEach((key) => {
      const value = attributes[key];
      if (value === null) {
        if (existingAttributes && key in existingAttributes) {
          tx.add(
            removeMetadataPair({
              package: walrusPackageId,
              arguments: {
                self: blob,
                key
              }
            })
          );
        }
      } else {
        tx.add(
          insertOrUpdateMetadataPair({
            package: walrusPackageId,
            arguments: {
              self: blob,
              key,
              value
            }
          })
        );
      }
    });
  };
};
executeTransaction_fn = async function(transaction, signer, action) {
  transaction.setSenderIfNotSet(signer.toSuiAddress());
  const { digest, effects } = await signer.signAndExecuteTransaction({
    transaction,
    client: __privateGet11(this, _suiClient)
  });
  if (effects?.status.error) {
    throw new WalrusClientError(`Failed to ${action} (${digest}): ${effects?.status.error}`);
  }
  await __privateGet11(this, _suiClient).core.waitForTransaction({
    digest
  });
  return { digest, effects };
};
getCommittee_fn = async function(committee) {
  const stakingPool = await __privateMethod6(this, _WalrusClient_instances, stakingPool_fn).call(this, committee);
  const shardIndicesByNodeId = getShardIndicesByNodeId(committee);
  const byShardIndex = /* @__PURE__ */ new Map();
  const nodes = stakingPool.map(({ node_info }, nodeIndex) => {
    const shardIndices = shardIndicesByNodeId.get(node_info.node_id) ?? [];
    const node = {
      id: node_info.node_id,
      info: node_info,
      networkUrl: `https://${node_info.network_address}`,
      shardIndices,
      nodeIndex
    };
    for (const shardIndex of shardIndices) {
      byShardIndex.set(shardIndex, node);
    }
    return node;
  });
  return {
    byShardIndex,
    nodes
  };
};
getActiveCommittee_fn = function() {
  return __privateGet11(this, _cache4).read(["getActiveCommittee"], async () => {
    const stakingState = await this.stakingState();
    return __privateMethod6(this, _WalrusClient_instances, getCommittee_fn).call(this, stakingState.committee);
  });
};
stakingPool_fn = async function(committee) {
  const nodeIds = committee[0].contents.map((node) => node.key);
  return __privateGet11(this, _objectLoader).loadManyOrThrow(nodeIds, StakingPool);
};
getNodeByShardIndex_fn = async function(committeeInfo, index) {
  const node = committeeInfo.byShardIndex.get(index);
  if (!node) {
    throw new WalrusClientError(`Node for shard index ${index} not found`);
  }
  return node;
};
retryOnPossibleEpochChange_fn = function(fn) {
  return async (...args) => {
    try {
      return await fn.apply(this, args);
    } catch (error) {
      if (error instanceof RetryableWalrusClientError) {
        this.reset();
        return await fn.apply(this, args);
      }
      throw error;
    }
  };
};
var WalrusClient = _WalrusClient;
export {
  AuthenticationError,
  BadRequestError,
  BehindCurrentEpochError,
  BlobBlockedError,
  BlobNotCertifiedError,
  BlobNotRegisteredError,
  ConflictError,
  ConnectionError,
  ConnectionTimeoutError,
  InconsistentBlobError,
  InternalServerError,
  LegallyUnavailableError,
  MAINNET_WALRUS_PACKAGE_CONFIG,
  NoBlobMetadataReceivedError,
  NoBlobStatusReceivedError,
  NoVerifiedBlobStatusReceivedError,
  NotEnoughBlobConfirmationsError,
  NotEnoughSliversReceivedError,
  NotFoundError,
  PermissionDeniedError,
  RateLimitError,
  RetryableWalrusClientError,
  StorageNodeAPIError,
  StorageNodeError,
  TESTNET_WALRUS_PACKAGE_CONFIG,
  UnprocessableEntityError,
  UserAbortError,
  WalrusBlob,
  WalrusClient,
  WalrusClientError,
  WalrusFile,
  blobIdFromInt,
  blobIdToInt,
  encodeQuilt
};
//# sourceMappingURL=@mysten_walrus.js.map
